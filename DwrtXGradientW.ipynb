{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCrA7x0jAtN3r16ztILcPR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zw2788/LocalMinimaConstruction/blob/main/DwrtXGradientW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from IPython.display import Image\n",
        "from torch.autograd import grad\n"
      ],
      "metadata": {
        "id": "6IhL4Cbb1mfH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, custom_W_0, custom_b, custom_V_0, custom_c):\n",
        "        super(SimpleNN, self).__init__()\n",
        "\n",
        "        # Ensure that the custom weights are tensors\n",
        "        custom_W_0 = torch.tensor(custom_W_0, dtype=torch.float64)\n",
        "        custom_b = torch.tensor(custom_b, dtype=torch.float64)\n",
        "        custom_V_0 = torch.tensor(custom_V_0, dtype=torch.float64)\n",
        "        custom_c = torch.tensor(custom_c, dtype=torch.float64)\n",
        "\n",
        "        # Set the custom weights and biases\n",
        "        self.W_0 = nn.Parameter(custom_W_0)\n",
        "        self.b = nn.Parameter(custom_b)\n",
        "        self.V_0 = nn.Parameter(custom_V_0)\n",
        "        self.c = nn.Parameter(custom_c)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.sigmoid(torch.add(torch.matmul(x, self.W_0), self.b))\n",
        "        x = F.sigmoid(torch.add(torch.matmul(x, self.V_0), self.c))\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "#custom_W_0 = [[0.1, 0.2], [0.3, 0.4]]  # Replace with your own initial values\n",
        "#custom_b = [0.1, 0.2]  # Replace with your own initial values\n",
        "#custom_V_0 = [[0.1], [0.2]]  # Replace with your own initial values\n",
        "#custom_c = [0.1]  # Replace with your own initial values\n",
        "\n",
        "\n",
        "def calculate_second_order_grad(model, X_raw_torch, Y_torch):\n",
        "    # Forward pass\n",
        "    output = model(X_raw_torch)\n",
        "    # Compute loss\n",
        "    loss = -torch.mean(Y_torch * torch.log(output) + (1 - Y_torch) * torch.log(1 - output))\n",
        "    # Compute gradients of the loss w.r.t. weights\n",
        "    loss.backward(create_graph=True)\n",
        "    # Combine and compute the norm of all gradients\n",
        "    all_grads = torch.cat([param.grad.flatten() for param in model.parameters()])\n",
        "    grad_norm = torch.norm(all_grads)\n",
        "    #print(all_grads)\n",
        "    # Compute the derivative of the grad_norm with respect to X\n",
        "    second_order_grad = torch.autograd.grad(grad_norm, X_raw_torch, retain_graph=True)[0]\n",
        "    return second_order_grad\n",
        "\n",
        "def calculate_second_order_grad_trap(model, X_raw_torch, Y_torch):\n",
        "    # Forward pass\n",
        "    output = model(X_raw_torch)\n",
        "    # Compute loss\n",
        "    loss = -torch.mean(Y_torch * torch.log(output) + (1 - Y_torch) * torch.log(1 - output))\n",
        "    # Compute gradients of the loss w.r.t. weights\n",
        "    loss.backward(create_graph=True)\n",
        "    # Combine and compute the norm of all gradients\n",
        "    all_grads = torch.cat([param.grad.flatten() for param in model.parameters()])\n",
        "    grad_norm = torch.norm(all_grads)\n",
        "    #print(all_grads)\n",
        "    # Compute the derivative of the grad_norm with respect to X\n",
        "    second_order_grad = torch.autograd.grad(grad_norm, X_raw_torch, retain_graph=True)[0]\n",
        "    return second_order_grad\n"
      ],
      "metadata": {
        "id": "vBoW060Y1pZB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perturb_weights_normal(model, max_deviation=0.01):\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            std_dev = param.abs().mean() * max_deviation\n",
        "            noise = torch.randn(param.size()) * std_dev\n",
        "            param[:] = param + noise\n",
        "\n",
        "def perturb_weights_uniform(model, max_deviation=0.01):\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            scale_factor = param.abs().mean() * max_deviation\n",
        "            # Generate uniform noise in the range [-scale_factor, scale_factor]\n",
        "            noise = (torch.rand(param.size()) * 2 - 1) * scale_factor\n",
        "            param[:] = param + noise\n",
        "def perturb_weights_uniform_fixed_range(model, scale):\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            # Generate uniform noise in the range [-0.1, 0.1]\n",
        "            noise = (torch.rand(param.size()) * 2 - 1) * scale\n",
        "            param[:] = param + noise\n",
        "\n",
        "def restore_weights(model, saved_state):\n",
        "    with torch.no_grad():\n",
        "        for name, param in model.named_parameters():\n",
        "            param[:] = saved_state[name]\n",
        "\n",
        "def perturb_data(X, max_deviation=0.01):\n",
        "    \"\"\"Perturb the data tensor X.\"\"\"\n",
        "    with torch.no_grad():\n",
        "        std_dev = X.abs().mean() * max_deviation\n",
        "        noise = torch.randn(X.size()) * std_dev\n",
        "        X.add_(noise)"
      ],
      "metadata": {
        "id": "iuOrsYOiJo91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-executing the code to define the function for computing the Hessian matrix and its eigenvalues\n",
        "\n",
        "def compute_hessian_and_eigenvalues(model, data, target):\n",
        "    \"\"\"\n",
        "    Compute the Hessian matrix and its eigenvalues for the weights of a neural network model.\n",
        "\n",
        "    :param model: The neural network model.\n",
        "    :param data: Input data (X).\n",
        "    :param target: Target data (Y).\n",
        "    :return: Hessian matrix and its eigenvalues.\n",
        "    \"\"\"\n",
        "    # Forward pass\n",
        "    output = model(data)\n",
        "    # Compute loss\n",
        "    loss = -torch.mean(target * torch.log(output) + (1 - target) * torch.log(1 - output))\n",
        "\n",
        "    # First-order gradients (w.r.t weights)\n",
        "    first_order_grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
        "\n",
        "    # Flatten the first-order gradients\n",
        "    grads_flatten = torch.cat([g.contiguous().view(-1) for g in first_order_grads])\n",
        "\n",
        "    # Hessian computation\n",
        "    hessian = []\n",
        "    for grad in grads_flatten:\n",
        "        # Compute second-order gradients (w.r.t each element in the first-order gradients)\n",
        "        second_order_grads = torch.autograd.grad(grad, model.parameters(), retain_graph=True)\n",
        "\n",
        "        # Flatten and collect the second-order gradients\n",
        "        hessian_row = torch.cat([g.contiguous().view(-1) for g in second_order_grads])\n",
        "        hessian.append(hessian_row)\n",
        "\n",
        "    # Stack to form the Hessian matrix\n",
        "    hessian_matrix = torch.stack(hessian)\n",
        "\n",
        "    # Compute eigenvalues\n",
        "    eigenvalues, _ = torch.linalg.eig(hessian_matrix)\n",
        "\n",
        "    return hessian_matrix, eigenvalues\n",
        "\n",
        "# Note: To use this function, you'll need to provide your neural network model, the input data (X), and the target data (Y).\n",
        "\n",
        "\n",
        "def check_local_minimum(eigenvalues):\n",
        "    # Check if all eigenvalues have a positive real part\n",
        "    if all(eig.real > 0 for eig in eigenvalues):\n",
        "        print(\"This is a local minimum.\")\n",
        "    else:\n",
        "        print(\"This is not a local minimum.\")\n"
      ],
      "metadata": {
        "id": "DG4bccfJA4Jk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot a single tensor\n",
        "def plot_tensor(tensor_data, label='Data', marker='o', color='blue'):\n",
        "    plt.figure(figsize=(6, 4))\n",
        "\n",
        "    # Plotting the tensor\n",
        "    plt.scatter(tensor_data[:, 0].detach().numpy(), tensor_data[:, 1].detach().numpy(), label=label, marker=marker, color=color)\n",
        "\n",
        "    plt.xlabel('X Axis')\n",
        "    plt.ylabel('Y Axis')\n",
        "    plt.title(f'{label} Plot')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "tq4AJolQU59J"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/zw2788/LocalMinimaConstruction/main/output(49830_100000).csv\")\n",
        "\n",
        "data.head()\n",
        "\n",
        "# data , drop NaN values\n",
        "X_raw,  Y, W_0, b, V_0, c = data[['x_2dvec']].dropna().values, data['y'].dropna().values, data[['W_0']].dropna().values, data[['b']].dropna().values, data[['V_0']].dropna().values, data[['c']].dropna().values\n",
        "\n",
        "#convert string to array\n",
        "\n",
        "X_raw = np.array([eval(s[0]) for s in X_raw])\n",
        "\n",
        "W_0 = np.array([eval(s[0]) for s in W_0])\n",
        "\n",
        "b = np.array([eval(s[0]) for s in b])\n",
        "\n",
        "V_0 = np.array([eval(s[0]) for s in V_0])\n",
        "\n",
        "c = np.array([eval(s[0]) for s in c])\n",
        "\n",
        "# Standardize the input\n",
        "# Leave blank to match the example in paper\n",
        "\n",
        "# formatting\n",
        "Y = Y.reshape((-1, 1))\n",
        "print(X_raw)\n",
        "print(Y)\n",
        "print(W_0)\n",
        "#print(X_raw.shape[0])\n",
        "X_raw = torch.tensor(X_raw, requires_grad=True)\n",
        "Y = torch.tensor(Y)\n",
        "print(W_0, b, V_0, c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0h9evkU59mR",
        "outputId": "cfce883c-93de-4def-8fb2-bf06ffeb7ced"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-4.05673409 -1.57919633]\n",
            " [-4.08621693 -7.32655954]\n",
            " [ 5.7382369   6.51035595]\n",
            " [-3.54674959 -9.48523903]\n",
            " [-5.44635487 -1.49153161]\n",
            " [-3.05762291  7.25649118]\n",
            " [-9.07657528  3.435395  ]\n",
            " [-3.56827617 -2.80349135]\n",
            " [ 4.2420435   2.56337643]\n",
            " [-8.37438869  4.51332331]]\n",
            "[[1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "[[ 3.37760234 -8.4564867 ]\n",
            " [ 0.92768544  2.91912866]]\n",
            "[[ 3.37760234 -8.4564867 ]\n",
            " [ 0.92768544  2.91912866]] [[ 4.70377207 -0.07312825]] [[ 4.8233037 ]\n",
            " [-4.45070505]] [[-4.8279748]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model = SimpleNN(W_0, b, V_0, c)\n",
        "hessian_matrix_initial, eigenvalues_initial = compute_hessian_and_eigenvalues(nn_model, X_raw, Y)\n",
        "\n",
        "print(eigenvalues_initial)\n",
        "check_local_minimum(eigenvalues_initial)"
      ],
      "metadata": {
        "id": "zkVm-srfFTQZ",
        "outputId": "a2d49b15-9c17-4476-da3d-53d41e65d787",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-3.2549e+00+0.j,  1.0070e-01+0.j,  8.7098e-03+0.j,  1.8168e-03+0.j,\n",
            "        -2.7687e-04+0.j,  4.1569e-05+0.j, -6.5372e-09+0.j,  1.3711e-10+0.j,\n",
            "        -4.7058e-13+0.j], dtype=torch.complex128)\n",
            "This is not a local minimum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable anomaly detection\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "def make_model_copy(original_model):\n",
        "    # Create a new instance of the model\n",
        "    model_copy = SimpleNN(W_0, b, V_0, c)  # Use the same parameters as used to create the original model\n",
        "    # Copy the initial weights from the original model\n",
        "    model_copy.load_state_dict(original_model.state_dict())\n",
        "    return model_copy\n",
        "\n",
        "def trap_model(original_model, X, Y, max_iterations, number_of_x_iterations, weightlr=0.01, xlr=0.01):\n",
        "    X_modifiable = X.clone().detach().requires_grad_(True)\n",
        "\n",
        "    for current_iteration in range(max_iterations):\n",
        "        # Use a fresh copy of the model\n",
        "        model = make_model_copy(original_model)\n",
        "\n",
        "        optimizer_weights = optim.SGD(model.parameters(), lr=weightlr)\n",
        "\n",
        "    # Optimizer for the weights\n",
        "    #optimizer_weights = optim.SGD(model.parameters(), lr=weightlr)\n",
        "\n",
        "        # Save initial state of the model\n",
        "        initial_state_dict = model.state_dict()\n",
        "\n",
        "        # Load initial weights using the deep copied state\n",
        "        model.load_state_dict(copy.deepcopy(initial_state_dict))\n",
        "\n",
        "        # Reset the optimizer state\n",
        "        optimizer_weights = optim.SGD(model.parameters(), lr=weightlr)\n",
        "\n",
        "        # Forward pass with current X_modifiable and initial weights\n",
        "        model_output = model(X_modifiable)\n",
        "\n",
        "        old_loss = -torch.mean(Y * torch.log(model_output) + (1 - Y) * torch.log(1 - model_output))\n",
        "\n",
        "        # Gradient descent step for weights\n",
        "        optimizer_weights.zero_grad()\n",
        "        old_loss.backward()\n",
        "        optimizer_weights.step()\n",
        "        # Gather all gradients into a list after flattening\n",
        "        gradients = [param.grad.view(-1) for param in model.parameters() if param.grad is not None]\n",
        "\n",
        "        # Concatenate all gradients to form a single vector and calculate its norm\n",
        "        total_gradient = torch.cat(gradients)\n",
        "        total_gradient_norm = total_gradient.norm()\n",
        "\n",
        "        # Check if the combined gradient norm is below the threshold\n",
        "        if total_gradient_norm < 1e-8:\n",
        "            print(\"Combined gradient norm below threshold, stopping optimization.\")\n",
        "            break\n",
        "\n",
        "        # Save new weights and create a copy of X_modifiable for the inner loop\n",
        "        new_state_dict = model.state_dict()\n",
        "        X_inner = X_modifiable.clone().detach().requires_grad_(True)\n",
        "        optimizer_x = optim.SGD([X_inner], lr=xlr)\n",
        "\n",
        "        for _ in range(number_of_x_iterations):\n",
        "            # Load new weights\n",
        "            model.load_state_dict(new_state_dict)\n",
        "            print(\"before {}\".format(X_inner))\n",
        "            output_new = model(X_inner)\n",
        "            new_loss = -torch.mean(Y * torch.log(output_new) + (1 - Y) * torch.log(1 - output_new))\n",
        "\n",
        "            # Calculate combined loss\n",
        "            combined_loss = old_loss.detach() - new_loss\n",
        "            print(combined_loss)\n",
        "\n",
        "\n",
        "            # Check condition\n",
        "            if combined_loss <= 0:\n",
        "                print(\"acheive! at:{}\".format(current_iteration))\n",
        "                print(X_inner)\n",
        "                break\n",
        "            else:\n",
        "                optimizer_x.zero_grad()\n",
        "                combined_loss.backward()\n",
        "                optimizer_x.step()\n",
        "        #print(X_inner.data)\n",
        "        # Update X_modifiable with changes from the inner loop\n",
        "        # Calculate the difference between X_modifiable and X_inner\n",
        "        difference = (X_modifiable - X_inner).norm()\n",
        "\n",
        "        # Check if the difference is below a certain threshold\n",
        "        if difference < 1e-8:  # You can adjust this threshold as needed\n",
        "          print(\"X_modifiable did not change significantly, stopping early.\")\n",
        "          break\n",
        "        else:\n",
        "\n",
        "          # Update X_modifiable with changes from the inner loop\n",
        "          X_modifiable.data = X_inner.data\n",
        "\n",
        "\n",
        "    # After completing all iterations, load initial weights\n",
        "    model.load_state_dict(initial_state_dict)\n",
        "\n",
        "    # Forward pass with the final X_modifiable and initial weights\n",
        "    final_output = model(X_modifiable)\n",
        "    final_loss = -torch.mean(Y * torch.log(final_output) + (1 - Y) * torch.log(1 - final_output))\n",
        "\n",
        "    # Calculate gradients with respect to the initial weights\n",
        "    optimizer_weights.zero_grad()\n",
        "    final_loss.backward()\n",
        "\n",
        "    # Calculate and print the norm of the gradients for each parameter\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"Gradient norm for {name}: {param.grad.norm().item()}\")\n",
        "\n",
        "    # Return the modified X\n",
        "    return X_modifiable\n",
        "\n",
        "# Initialize your model, X, Y, etc. outside the function\n",
        "# ... [Your initialization code here] ...\n",
        "\n",
        "# Call the function\n",
        "# ... [Call to train_model function here] ...\n",
        "#Example\n",
        "# Initialize your model, X, Y, etc. outside the function\n",
        "#custom_W_0 = [...]  # Replace [...] with your initial weights\n",
        "#custom_b = [...]   # Replace [...] with your initial bias\n",
        "#custom_V_0 = [...]  # Replace [...] with your next layer weights\n",
        "#custom_c = [...]   # Replace [...] with your next layer bias\n",
        "#model = SimpleNN(custom_W_0, custom_b, custom_V_0, custom_c)\n",
        "#X = torch.tensor([...], dtype=torch.float64, requires_grad=True)  # Replace [...] with your initial data\n",
        "#Y = torch.tensor([...], dtype=torch.float64)  # Replace [...] with target data\n",
        "\n",
        "# Call the function\n",
        "nn_model_trap = SimpleNN(W_0, b, V_0, c)\n",
        "trap_X = trap_model(nn_model_trap, X_raw, Y, max_iterations=10, number_of_x_iterations=10, weightlr= 0.005, xlr= 1)\n",
        "plot_tensor(X_raw, label='X_raw', marker='o', color='blue')\n",
        "plot_tensor(trap_X, label='trap_X', marker='o', color='blue')"
      ],
      "metadata": {
        "id": "szMjSQUcynkl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "605d0914-84c6-4295-e619-e94ec7c7b53b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5467, -9.4852],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0576,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0011, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.8816, -9.3696],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0566,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0408, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:0\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.8816, -9.3696],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0566,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.8816, -9.3696],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0566,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.8984, -9.3638],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0555,  7.2571],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(5.0802e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0569, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9128, -9.3588],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0544,  7.2574],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:1\n",
            "tensor([[-4.0569, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9128, -9.3588],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0544,  7.2574],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0569, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9128, -9.3588],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0544,  7.2574],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0569, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9254, -9.3545],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0534,  7.2577],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0570, -1.5793],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9366, -9.3506],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0523,  7.2580],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-1.9478e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:2\n",
            "tensor([[-4.0570, -1.5793],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9366, -9.3506],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0523,  7.2580],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0570, -1.5793],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9366, -9.3506],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0523,  7.2580],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0570, -1.5793],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9466, -9.3471],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0512,  7.2583],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0571, -1.5793],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9557, -9.3440],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0501,  7.2585],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(9.9323e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0571, -1.5793],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9641, -9.3411],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0491,  7.2588],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(2.2383e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0572, -1.5793],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9719, -9.3384],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0480,  7.2591],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-4.3685e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:3\n",
            "tensor([[-4.0572, -1.5793],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9719, -9.3384],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0480,  7.2591],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0572, -1.5793],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9719, -9.3384],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0480,  7.2591],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0572, -1.5793],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9791, -9.3359],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0469,  7.2594],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0572, -1.5793],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9858, -9.3336],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0458,  7.2597],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0573, -1.5793],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9921, -9.3314],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0448,  7.2600],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0573, -1.5794],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.9981, -9.3294],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0437,  7.2603],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0574, -1.5794],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0037, -9.3274],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0426,  7.2606],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(7.1110e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0574, -1.5794],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0090, -9.3256],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0415,  7.2609],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(3.8777e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0575, -1.5794],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0141, -9.3238],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0404,  7.2612],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(9.3822e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0575, -1.5794],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0189, -9.3222],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0393,  7.2615],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-1.7477e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:4\n",
            "tensor([[-4.0575, -1.5794],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0189, -9.3222],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0393,  7.2615],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0575, -1.5794],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0189, -9.3222],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0393,  7.2615],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0576, -1.5794],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0236, -9.3206],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0382,  7.2618],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0576, -1.5794],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0280, -9.3190],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0371,  7.2621],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0577, -1.5795],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0322, -9.3176],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0361,  7.2624],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0577, -1.5795],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0363, -9.3162],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0350,  7.2627],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0578, -1.5795],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0402, -9.3148],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0339,  7.2630],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0578, -1.5795],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0440, -9.3135],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0328,  7.2633],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0578, -1.5795],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0476, -9.3122],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0317,  7.2636],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0579, -1.5795],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0512, -9.3110],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0306,  7.2639],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0579, -1.5795],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0546, -9.3099],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0295,  7.2642],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0580, -1.5795],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0579, -9.3087],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0284,  7.2645],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0580, -1.5796],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0611, -9.3076],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0273,  7.2648],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0581, -1.5796],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0642, -9.3065],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0262,  7.2651],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0581, -1.5796],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0672, -9.3055],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0250,  7.2654],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0582, -1.5796],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0701, -9.3045],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0239,  7.2657],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0582, -1.5796],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0730, -9.3035],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0228,  7.2660],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0583, -1.5796],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0757, -9.3026],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0217,  7.2664],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0583, -1.5796],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0784, -9.3016],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0206,  7.2667],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0584, -1.5796],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0811, -9.3007],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0195,  7.2670],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0584, -1.5797],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0836, -9.2998],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0184,  7.2673],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0585, -1.5797],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0861, -9.2990],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0173,  7.2676],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0585, -1.5797],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0886, -9.2981],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0161,  7.2679],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0585, -1.5797],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0910, -9.2973],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0150,  7.2682],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0586, -1.5797],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0933, -9.2965],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0139,  7.2685],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0586, -1.5797],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0956, -9.2957],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0128,  7.2688],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0587, -1.5797],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.0979, -9.2949],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0117,  7.2691],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0587, -1.5797],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1000, -9.2942],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0105,  7.2694],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0588, -1.5798],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1022, -9.2934],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0094,  7.2697],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0588, -1.5798],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1043, -9.2927],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0083,  7.2700],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0589, -1.5798],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1064, -9.2920],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0072,  7.2704],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0589, -1.5798],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1084, -9.2913],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0060,  7.2707],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0590, -1.5798],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1104, -9.2906],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0049,  7.2710],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0590, -1.5798],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1123, -9.2899],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0038,  7.2713],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0591, -1.5798],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1142, -9.2893],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0026,  7.2716],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0591, -1.5798],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1161, -9.2886],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0015,  7.2719],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0591, -1.5799],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1179, -9.2880],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0004,  7.2722],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0592, -1.5799],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1198, -9.2874],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-2.9992,  7.2725],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0592, -1.5799],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1215, -9.2867],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-2.9981,  7.2728],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0593, -1.5799],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1233, -9.2861],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-2.9970,  7.2731],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0593, -1.5799],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1250, -9.2855],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-2.9958,  7.2735],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0594, -1.5799],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1267, -9.2850],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-2.9947,  7.2738],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0594, -1.5799],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1284, -9.2844],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-2.9936,  7.2741],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0595, -1.5799],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1300, -9.2838],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-2.9924,  7.2744],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0595, -1.5800],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1316, -9.2833],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-2.9913,  7.2747],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0596, -1.5800],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1332, -9.2827],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-2.9901,  7.2750],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0596, -1.5800],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1348, -9.2822],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-2.9890,  7.2753],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0597, -1.5800],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1363, -9.2816],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-2.9878,  7.2757],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0597, -1.5800],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1379, -9.2811],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-2.9867,  7.2760],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0597, -1.5800],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1394, -9.2806],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-2.9856,  7.2763],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0598, -1.5800],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.1408, -9.2801],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-2.9844,  7.2766],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "Gradient norm for W_0: 0.0031843620149719564\n",
            "Gradient norm for b: 0.00036808774255617287\n",
            "Gradient norm for V_0: 0.2231729573220128\n",
            "Gradient norm for c: 0.09972971174992401\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_raw)\n",
        "print(trap_X)\n",
        "hessian_matrix_trap, eigenvalues_trap = compute_hessian_and_eigenvalues(nn_model_trap, trap_X, Y)\n",
        "\n",
        "print(eigenvalues_trap)\n",
        "check_local_minimum(eigenvalues_trap)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0CYBTk5J-Fu",
        "outputId": "88cfa854-2b82-4436-ae3e-36d449faa728"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5467, -9.4852],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0576,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor([[-4.3286, -1.6539],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.6614, -9.1004],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-1.5847,  7.6610],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5682, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor([ 1.0231e-01+0.j,  1.1700e-03+0.j, -5.3397e-04+0.j, -1.1300e-04+0.j,\n",
            "         3.1105e-05+0.j, -1.3220e-04+0.j, -6.0797e-10+0.j,  1.0024e-11+0.j,\n",
            "        -8.7358e-13+0.j], dtype=torch.complex128)\n",
            "This is not a local minimum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_data_with_centralgradients(X_raw, Y, W_0, b, V_0, c, max_iterations=20, learning_rate=0.1,  threshold=0.001):\n",
        "    \"\"\"\n",
        "    Optimize data using gradient calculations and Monte Carlo method.\n",
        "\n",
        "    :param nn_model: Neural Network Model class.\n",
        "    :param X_raw: Input data.\n",
        "    :param Y: Target data.\n",
        "    :param W_0, b, V_0, c: Initial weights and biases for the neural network.\n",
        "    :param max_iterations: Maximum number of iterations.\n",
        "    :param learning_rate: Learning rate for optimization.\n",
        "    :param MC_num_samples: Number of samples for Monte Carlo method.\n",
        "    :param surrounding_proportion: Proportion of surrounding points' gradients.\n",
        "    :param max_deviation_for_weight: Maximum deviation for weight perturbation.\n",
        "    :param threshold: Threshold for the norm of the second-order gradient.\n",
        "    :return: Optimized X_raw tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert data to PyTorch tensors\n",
        "    X_raw_tensor = X_raw.clone().detach().requires_grad_(True) if X_raw.requires_grad else torch.tensor(X_raw, dtype=torch.float64, requires_grad=True)\n",
        "    Y_tensor = Y.clone().detach().requires_grad_(True) if Y.requires_grad else torch.tensor(Y, dtype=torch.float64, requires_grad=True)\n",
        "\n",
        "\n",
        "    # Initialize the neural network with provided weights\n",
        "    nn_model_instance = SimpleNN(W_0, b, V_0, c)\n",
        "\n",
        "    # Store original weights\n",
        "    original_weights = {\n",
        "        'W_0': nn_model_instance.W_0.data.clone(),\n",
        "        'b': nn_model_instance.b.data.clone(),\n",
        "        'V_0': nn_model_instance.V_0.data.clone(),\n",
        "        'c': nn_model_instance.c.data.clone()\n",
        "    }\n",
        "    print(\"Original weight is {}\".format(original_weights))\n",
        "    print(\"Initial X_raw_pre {}\".format(X_raw_tensor))\n",
        "\n",
        "    for i in range(max_iterations):\n",
        "        # [Insert the existing logic of your loop here, using nn_model_instance, X_raw_tensor, Y_tensor, and other parameters]\n",
        "        # Calculate the gradient at the central point\n",
        "        central_grad = calculate_second_order_grad(nn_model_instance, X_raw_tensor, Y_tensor)\n",
        "        # Check if grad_X is None before proceeding\n",
        "        central_grad_norm = torch.norm(central_grad)\n",
        "        central_grad = central_grad / central_grad_norm\n",
        "        #print(central_grad)\n",
        "        # Surrouning points' grads\n",
        "        surrounding_grads_pre = []\n",
        "        norms_pre = []\n",
        "        negative_eigenvalues = []\n",
        "\n",
        "\n",
        "        # Combine gradients\n",
        "        combined_grad = central_grad\n",
        "        #combined_grad =  average_surrounding_grad\n",
        "        #print(combined_grad)\n",
        "        # Calculate the norm of the combined gradient\n",
        "        combined_grad_norm = torch.norm(combined_grad)\n",
        "\n",
        "        # Check for a non-zero norm to avoid division by zero\n",
        "        if combined_grad_norm == 0:\n",
        "        # Normalize the gradient\n",
        "          print(\"Gradient is zero; no update required.\")\n",
        "\n",
        "###############\n",
        "\n",
        "        # Check if the norm of the second-order gradient is below the threshold\n",
        "        if torch.norm(combined_grad) < threshold:\n",
        "            print(f\"Convergence reached at iteration {i}\")\n",
        "            break\n",
        "        # Update X_raw using the normalized gradient and learning rate\n",
        "        X_raw_tensor.data -= learning_rate * combined_grad_norm\n",
        "\n",
        "        # Zero out gradients for the next iteration\n",
        "        nn_model_instance.zero_grad()\n",
        "        X_raw_tensor.grad = None\n",
        "        # Update and checks as per your original code\n",
        "\n",
        "\n",
        "\n",
        "    # Print final modified data\n",
        "\n",
        "    print(\"Output X is: {}\".format(X_raw_tensor))\n",
        "\n",
        "\n",
        "    print(central_grad_norm)\n",
        "    # Return the optimized X_raw tensor\n",
        "    return X_raw_tensor\n",
        "\n",
        "# Example usage\n",
        "optimized_X_1 = optimize_data_with_centralgradients(trap_X, Y, W_0, b, V_0, c, max_iterations=1000, learning_rate=0.001,  threshold=0.0001)\n"
      ],
      "metadata": {
        "id": "QR7lCrl3d2un",
        "outputId": "85d90dbe-5275-45ee-bd42-34fe4c78a383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-fb3eef455826>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Y_tensor = Y.clone().detach().requires_grad_(True) if Y.requires_grad else torch.tensor(Y, dtype=torch.float64, requires_grad=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weight is {'W_0': tensor([[-0.9854, -7.0746],\n",
            "        [-0.7950, -5.9667]], dtype=torch.float64), 'b': tensor([[2.9537, 2.3977]], dtype=torch.float64), 'V_0': tensor([[-8.6610],\n",
            "        [-6.9776]], dtype=torch.float64), 'c': tensor([[6.6996]], dtype=torch.float64)}\n",
            "Initial X_raw_pre tensor([[ 0.1222,  0.1974],\n",
            "        [ 0.6699,  1.4908],\n",
            "        [ 0.1828,  0.1296],\n",
            "        [-3.1624, -3.5892],\n",
            "        [ 0.2212,  0.0867],\n",
            "        [ 0.2715, -0.6380],\n",
            "        [ 0.7825,  1.3818],\n",
            "        [ 1.3966,  3.5302],\n",
            "        [ 0.2329,  0.0736],\n",
            "        [ 2.6141, -0.3701]], dtype=torch.float64, requires_grad=True)\n",
            "Output X is: tensor([[-0.8778, -0.8026],\n",
            "        [-0.3301,  0.4908],\n",
            "        [-0.8172, -0.8704],\n",
            "        [-4.1624, -4.5892],\n",
            "        [-0.7788, -0.9133],\n",
            "        [-0.7285, -1.6380],\n",
            "        [-0.2175,  0.3818],\n",
            "        [ 0.3966,  2.5302],\n",
            "        [-0.7671, -0.9264],\n",
            "        [ 1.6141, -1.3701]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.2884, dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model = SimpleNN(W_0, b, V_0, c)\n",
        "hessian_matrix_central, eigenvalues_central = compute_hessian_and_eigenvalues(nn_model, optimized_X_1, Y)\n",
        "\n",
        "print(eigenvalues_central)\n",
        "check_local_minimum(eigenvalues_central)"
      ],
      "metadata": {
        "id": "LOlqYSsAhqW5",
        "outputId": "71b0a1d5-e3d8-4eaf-de26-f1f0a22b8448",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 8.5687e-01+0.j, -8.2876e-02+0.j,  4.8516e-02+0.j,  1.3709e-02+0.j,\n",
            "         3.4205e-03+0.j, -2.7478e-03+0.j,  3.2365e-04+0.j,  1.6174e-04+0.j,\n",
            "        -7.9576e-06+0.j], dtype=torch.complex128)\n",
            "This is not a local minimum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_data_with_gradients(X_raw, Y, W_0, b, V_0, c, max_iterations=20, learning_rate=0.1, MC_num_samples=100, surrounding_proportion=0.5, max_deviation_for_weight=0.05, threshold=0.001):\n",
        "    \"\"\"\n",
        "    Optimize data using gradient calculations and Monte Carlo method.\n",
        "\n",
        "    :param nn_model: Neural Network Model class.\n",
        "    :param X_raw: Input data.\n",
        "    :param Y: Target data.\n",
        "    :param W_0, b, V_0, c: Initial weights and biases for the neural network.\n",
        "    :param max_iterations: Maximum number of iterations.\n",
        "    :param learning_rate: Learning rate for optimization.\n",
        "    :param MC_num_samples: Number of samples for Monte Carlo method.\n",
        "    :param surrounding_proportion: Proportion of surrounding points' gradients.\n",
        "    :param max_deviation_for_weight: Maximum deviation for weight perturbation.\n",
        "    :param threshold: Threshold for the norm of the second-order gradient.\n",
        "    :return: Optimized X_raw tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert data to PyTorch tensors\n",
        "    X_raw_tensor = X_raw.clone().detach().requires_grad_(True) if X_raw.requires_grad else torch.tensor(X_raw, dtype=torch.float64, requires_grad=True)\n",
        "    Y_tensor = Y.clone().detach().requires_grad_(True) if Y.requires_grad else torch.tensor(Y, dtype=torch.float64, requires_grad=True)\n",
        "\n",
        "\n",
        "    # Initialize the neural network with provided weights\n",
        "    nn_model_sur = SimpleNN(W_0, b, V_0, c)\n",
        "\n",
        "    # Store original weights\n",
        "    original_weights = {\n",
        "        'W_0': nn_model_sur.W_0.data.clone(),\n",
        "        'b': nn_model_sur.b.data.clone(),\n",
        "        'V_0': nn_model_sur.V_0.data.clone(),\n",
        "        'c': nn_model_sur.c.data.clone()\n",
        "    }\n",
        "    print(\"Original weight is {}\".format(original_weights))\n",
        "    print(\"Initial X_raw_pre {}\".format(X_raw_tensor))\n",
        "\n",
        "    for i in range(max_iterations):\n",
        "        # [Insert the existing logic of your loop here, using nn_model_instance, X_raw_tensor, Y_tensor, and other parameters]\n",
        "        # Calculate the gradient at the central point\n",
        "        central_grad = calculate_second_order_grad(nn_model_sur, X_raw_tensor, Y_tensor)\n",
        "        # Check if grad_X is None before proceeding\n",
        "        central_grad_norm = torch.norm(central_grad)\n",
        "        central_grad = central_grad / central_grad_norm\n",
        "        #print(central_grad)\n",
        "        # Surrouning points' grads\n",
        "        surrounding_grads_pre = []\n",
        "        norms_pre = []\n",
        "\n",
        "\n",
        "        # Calculate the gradient at the surrounding points by MC\n",
        "        for _ in range(MC_num_samples):\n",
        "\n",
        "            nn_model_sample_pre = SimpleNN(custom_W_0=original_weights['W_0'],custom_b=original_weights['b'],custom_V_0=original_weights['V_0'],custom_c=original_weights['c'])\n",
        "            #print(\"W_0 (before perturbation):\", nn_model_sample.W_0.data)\n",
        "            # Perturb weights\n",
        "            #perturb_weights_uniform_fixed_range(nn_model_sample, max_deviation=max_deviation_for_weight)\n",
        "            perturb_weights_uniform_fixed_range(nn_model_sample_pre, scale = max_deviation_for_weight)\n",
        "            #print(\"W_0 (after perturbation):\", nn_model_sample.W_0.data)\n",
        "            grad_pre = calculate_second_order_grad(nn_model_sample_pre, X_raw_tensor, Y_tensor)\n",
        "            grad_norm = torch.norm(grad_pre)\n",
        "            grad_pre = grad_pre / grad_norm\n",
        "            surrounding_grads_pre.append(grad_pre)\n",
        "            #negative_eigenvalues.append(torch.norm(grad_pre).item())\n",
        "\n",
        "        sum_surrounding_grads_pre = sum(surrounding_grads_pre)\n",
        "\n",
        "        # Average the large norm gradients\n",
        "        average_surrounding_grads_pre = sum_surrounding_grads_pre / len(surrounding_grads_pre)\n",
        "        # Calculate average pre_norm\n",
        "        #average_negative_eigenvalues = sum(negative_eigenvalues) / len(negative_eigenvalues)\n",
        "\n",
        "        # Calculate the median of negative eigenvalues\n",
        "        #median_negative_eigenvalue = np.median([eigenvalue for eigenvalue in negative_eigenvalues if eigenvalue < 0])\n",
        "\n",
        "\n",
        "        # Filter gradients corresponding to the smallest 50% of negative eigenvalues\n",
        "        #above_average_negative_eigenvalues = [grad for grad, eigenvalue in zip(surrounding_grads_pre, negative_eigenvalues) if eigenvalue < median_negative_eigenvalue]\n",
        "        #above_average_negative_eigenvalues = [grad / torch.norm(grad) for grad in above_average_negative_eigenvalues]\n",
        "\n",
        "        #print(above_average_grads)\n",
        "        #sum_above_average_negative_eigenvalues = sum(above_average_negative_eigenvalues)\n",
        "\n",
        "        # Average the large norm gradients\n",
        "        #if above_average_negative_eigenvalues:\n",
        "          #average_above_average_negative_eigenvalues = sum_above_average_negative_eigenvalues / len(above_average_negative_eigenvalues)\n",
        "          #print(average_above_average_grad)\n",
        "        #else:\n",
        "          # Handle the case where no gradient is above average\n",
        "          #average_above_average_negative_eigenvalues = torch.zeros_like(X_raw_tensor)\n",
        "\n",
        "\n",
        "        #print(\"Surrounding grad {}\".format(surrounding_grads))\n",
        "\n",
        "        # Combine gradients\n",
        "        combined_grad = (1-surrounding_proportion) * central_grad + surrounding_proportion * average_surrounding_grads_pre\n",
        "        #combined_grad =  average_surrounding_grad\n",
        "        #print(combined_grad)\n",
        "        # Calculate the norm of the combined gradient\n",
        "        combined_grad_norm = torch.norm(combined_grad)\n",
        "\n",
        "        # Check for a non-zero norm to avoid division by zero\n",
        "        if combined_grad_norm > 0:\n",
        "        # Normalize the gradient\n",
        "          normalized_grad = combined_grad / combined_grad_norm\n",
        "\n",
        "        else:\n",
        "          print(\"Gradient is zero; no update required.\")\n",
        "###############\n",
        "\n",
        "        # Check if the norm of the second-order gradient is below the threshold\n",
        "        if torch.norm(combined_grad) < threshold:\n",
        "            print(f\"Convergence reached at iteration {i}\")\n",
        "            break\n",
        "        # Update X_raw using the normalized gradient and learning rate\n",
        "        X_raw_tensor.data -= learning_rate * normalized_grad\n",
        "\n",
        "        # Zero out gradients for the next iteration\n",
        "        nn_model_sur.zero_grad()\n",
        "        X_raw_tensor.grad = None\n",
        "        # Update and checks as per your original code\n",
        "\n",
        "\n",
        "\n",
        "    # Print final modified data\n",
        "    #print(surrounding_grads)\n",
        "    #print(\"Final modified X_raw:\")\n",
        "    #if len(above_average_negative_eigenvalues) < 0.5*MC_pre_num_samples:\n",
        "      #print(\"need more MC_pre_num_samples\")\n",
        "    #else:\n",
        "    #print(\"Used surrounding points: {}\".format(len(above_average_negative_eigenvalues)))\n",
        "\n",
        "    print(\"Output X is: {}\".format(X_raw_tensor))\n",
        "    #print(negative_eigenvalues)\n",
        "\n",
        "\n",
        "\n",
        "    # Return the optimized X_raw tensor\n",
        "    return X_raw_tensor\n",
        "\n",
        "# Example usage\n",
        "optimized_X_2 = optimize_data_with_gradients(trap_X, Y, W_0, b, V_0, c, max_iterations=50, learning_rate=0.1, MC_num_samples=100, surrounding_proportion=0.3, max_deviation_for_weight=0.01, threshold=0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ug5G6aLkors",
        "outputId": "b59b5df0-4436-4512-c39f-90e4814308fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-5816f8b1477c>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Y_tensor = Y.clone().detach().requires_grad_(True) if Y.requires_grad else torch.tensor(Y, dtype=torch.float64, requires_grad=True)\n",
            "<ipython-input-3-2e4822dd5dc3>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_W_0 = torch.tensor(custom_W_0, dtype=torch.float64)\n",
            "<ipython-input-3-2e4822dd5dc3>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_b = torch.tensor(custom_b, dtype=torch.float64)\n",
            "<ipython-input-3-2e4822dd5dc3>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_V_0 = torch.tensor(custom_V_0, dtype=torch.float64)\n",
            "<ipython-input-3-2e4822dd5dc3>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_c = torch.tensor(custom_c, dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weight is {'W_0': tensor([[-0.9854, -7.0746],\n",
            "        [-0.7950, -5.9667]], dtype=torch.float64), 'b': tensor([[2.9537, 2.3977]], dtype=torch.float64), 'V_0': tensor([[-8.6610],\n",
            "        [-6.9776]], dtype=torch.float64), 'c': tensor([[6.6996]], dtype=torch.float64)}\n",
            "Initial X_raw_pre tensor([[ 0.1222,  0.1974],\n",
            "        [ 0.6699,  1.4908],\n",
            "        [ 0.1828,  0.1296],\n",
            "        [-3.1624, -3.5892],\n",
            "        [ 0.2212,  0.0867],\n",
            "        [ 0.2715, -0.6380],\n",
            "        [ 0.7825,  1.3818],\n",
            "        [ 1.3966,  3.5302],\n",
            "        [ 0.2329,  0.0736],\n",
            "        [ 2.6141, -0.3701]], dtype=torch.float64, requires_grad=True)\n",
            "Output X is: tensor([[-0.1250, -0.0626],\n",
            "        [ 0.2896,  1.2047],\n",
            "        [-0.0676, -0.1333],\n",
            "        [-3.1624, -3.5891],\n",
            "        [-0.0313, -0.1780],\n",
            "        [ 0.2775, -0.6330],\n",
            "        [ 0.3866,  1.0816],\n",
            "        [ 4.3140,  5.7800],\n",
            "        [-0.0203, -0.1916],\n",
            "        [ 1.9599, -0.9091]], dtype=torch.float64, requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model_X2 = SimpleNN(W_0, b, V_0, c)\n",
        "hessian_matrix_surrounding, eigenvalues_surrounding = compute_hessian_and_eigenvalues(nn_model_X2, optimized_X_2, Y)\n",
        "\n",
        "print(eigenvalues_surrounding)\n",
        "check_local_minimum(eigenvalues_surrounding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4_An8vDPjyE",
        "outputId": "20e0a19c-c0ae-4875-9371-0d09ca831f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.3254+0.j,  0.2093+0.j, -0.1277+0.j, -0.0679+0.j,  0.0189+0.j,  0.0015+0.j,\n",
            "        -0.0028+0.j, -0.0007+0.j, -0.0010+0.j], dtype=torch.complex128)\n",
            "This is not a local minimum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_X_2 = optimize_data_with_gradients(optimized_X_1, Y, W_0, b, V_0, c, max_iterations=20, learning_rate=0.05, MC_num_samples=100, surrounding_proportion=0.9, max_deviation_for_weight=0.02, threshold=0.001)"
      ],
      "metadata": {
        "id": "mi-VQ5D7R535",
        "outputId": "7105b639-e3a4-4236-cfde-d2a8e4470466",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-1e9be29dee3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_raw_tensor = torch.tensor(X_raw, requires_grad=True)\n",
            "<ipython-input-19-1e9be29dee3d>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Y_tensor = torch.tensor(Y)\n",
            "<ipython-input-3-a815e9696fa5>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_W_0 = torch.tensor(custom_W_0, dtype=torch.float64)\n",
            "<ipython-input-3-a815e9696fa5>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_b = torch.tensor(custom_b, dtype=torch.float64)\n",
            "<ipython-input-3-a815e9696fa5>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_V_0 = torch.tensor(custom_V_0, dtype=torch.float64)\n",
            "<ipython-input-3-a815e9696fa5>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_c = torch.tensor(custom_c, dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weight is {'W_0': tensor([[ 3.9979,  5.2638],\n",
            "        [ 1.0698, -1.8901]], dtype=torch.float64), 'b': tensor([[1.8545, 0.8022]], dtype=torch.float64), 'V_0': tensor([[-10.1389],\n",
            "        [-10.4242]], dtype=torch.float64), 'c': tensor([[5.0116]], dtype=torch.float64)}\n",
            "Initial X_raw_pre tensor([[11.0898, -7.6508],\n",
            "        [ 1.6931, -6.0680],\n",
            "        [ 4.9975, -0.8779],\n",
            "        [ 6.1208, -5.1308],\n",
            "        [-5.5432, -6.2103],\n",
            "        [ 1.1082,  0.1752],\n",
            "        [-7.4783,  0.5124],\n",
            "        [-7.9947,  0.8285],\n",
            "        [-1.3351,  2.2657],\n",
            "        [-3.4568,  2.3168]], dtype=torch.float64, requires_grad=True)\n",
            "Used surrounding points: 50\n",
            "Output X is: tensor([[11.0898, -7.6508],\n",
            "        [ 1.6931, -6.0680],\n",
            "        [ 4.9975, -0.8779],\n",
            "        [ 6.1208, -5.1308],\n",
            "        [-5.5432, -6.2103],\n",
            "        [ 1.1082,  0.1752],\n",
            "        [-7.4783,  0.5124],\n",
            "        [-7.9947,  0.8285],\n",
            "        [-1.3568,  2.0730],\n",
            "        [-3.4338,  2.3244]], dtype=torch.float64, requires_grad=True)\n",
            "[tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0002, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0002, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0002, dtype=torch.float64), tensor(-0.0002, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0002, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0002, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0002, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0002, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_X_3 = optimize_data_with_gradients(optimized_X_2, Y, W_0, b, V_0, c, max_iterations=20, learning_rate=0.02, MC_num_samples=100, surrounding_proportion=0.9, max_deviation_for_weight=0.01, threshold=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7uQAynJwxIu",
        "outputId": "f67d55c1-bd3b-4311-b085-90588d7c7964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-1e9be29dee3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_raw_tensor = torch.tensor(X_raw, requires_grad=True)\n",
            "<ipython-input-19-1e9be29dee3d>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Y_tensor = torch.tensor(Y)\n",
            "<ipython-input-3-a815e9696fa5>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_W_0 = torch.tensor(custom_W_0, dtype=torch.float64)\n",
            "<ipython-input-3-a815e9696fa5>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_b = torch.tensor(custom_b, dtype=torch.float64)\n",
            "<ipython-input-3-a815e9696fa5>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_V_0 = torch.tensor(custom_V_0, dtype=torch.float64)\n",
            "<ipython-input-3-a815e9696fa5>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_c = torch.tensor(custom_c, dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weight is {'W_0': tensor([[ 3.9979,  5.2638],\n",
            "        [ 1.0698, -1.8901]], dtype=torch.float64), 'b': tensor([[1.8545, 0.8022]], dtype=torch.float64), 'V_0': tensor([[-10.1389],\n",
            "        [-10.4242]], dtype=torch.float64), 'c': tensor([[5.0116]], dtype=torch.float64)}\n",
            "Initial X_raw_pre tensor([[11.0898, -7.6508],\n",
            "        [ 1.6931, -6.0680],\n",
            "        [ 4.9975, -0.8779],\n",
            "        [ 6.1208, -5.1308],\n",
            "        [-5.5432, -6.2103],\n",
            "        [ 1.1082,  0.1752],\n",
            "        [-7.4783,  0.5124],\n",
            "        [-7.9947,  0.8285],\n",
            "        [-1.3568,  2.0730],\n",
            "        [-3.4338,  2.3244]], dtype=torch.float64, requires_grad=True)\n",
            "Used surrounding points: 50\n",
            "Output X is: tensor([[11.0898, -7.6508],\n",
            "        [ 1.6932, -6.0680],\n",
            "        [ 4.9975, -0.8779],\n",
            "        [ 6.1208, -5.1308],\n",
            "        [-5.5432, -6.2103],\n",
            "        [ 1.1082,  0.1752],\n",
            "        [-7.4783,  0.5124],\n",
            "        [-7.9947,  0.8285],\n",
            "        [-1.2705,  1.9455],\n",
            "        [-3.4149,  2.3306]], dtype=torch.float64, requires_grad=True)\n",
            "[tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model_pre = SimpleNN(W_0, b, V_0, c)\n",
        "hessian_matrix_pre, eigenvalues_pre = compute_hessian_and_eigenvalues(nn_model_pre, optimized_X_3, Y)\n",
        "\n",
        "print(eigenvalues_pre)\n",
        "check_local_minimum(eigenvalues_pre)"
      ],
      "metadata": {
        "id": "PRbJ8sIWR1ge",
        "outputId": "73e82f59-33e2-4458-ad9c-39c4afa3ba9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.9566e-01+0.j,  4.0277e-03+0.j, -2.7943e-04+0.j, -2.2500e-04+0.j,\n",
            "         3.3531e-05+0.j, -4.1906e-06+0.j,  1.2490e-06+0.j,  4.5318e-08+0.j,\n",
            "         2.1484e-10+0.j], dtype=torch.complex128)\n",
            "This is not a local minimum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## use the eigenvalues of hessian to decide whether use the grad.\n",
        "\n",
        "def flatten_gradients(X_raw, Y, W_0, b, V_0, c, max_iterations=20, learning_rate=0.1, MC_num_samples=100, surrounding_proportion=0.5, max_deviation_for_weight=0.05, threshold=0.001):\n",
        "    \"\"\"\n",
        "    Optimize data using gradient calculations and Monte Carlo method.\n",
        "\n",
        "    :param nn_model: Neural Network Model class.\n",
        "    :param X_raw: Input data.\n",
        "    :param Y: Target data.\n",
        "    :param W_0, b, V_0, c: Initial weights and biases for the neural network.\n",
        "    :param max_iterations: Maximum number of iterations.\n",
        "    :param learning_rate: Learning rate for optimization.\n",
        "    :param MC_num_samples: Number of samples for Monte Carlo method.\n",
        "    :param surrounding_proportion: Proportion of surrounding points' gradients.\n",
        "    :param max_deviation_for_weight: Maximum deviation for weight perturbation.\n",
        "    :param threshold: Threshold for the norm of the second-order gradient.\n",
        "    :return: Optimized X_raw tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert data to PyTorch tensors\n",
        "    X_raw_tensor = torch.tensor(X_raw, requires_grad=True)\n",
        "    Y_tensor = torch.tensor(Y)\n",
        "\n",
        "    # Initialize the neural network with provided weights\n",
        "    nn_model_instance = SimpleNN(W_0, b, V_0, c)\n",
        "\n",
        "    # Store original weights\n",
        "    original_weights = {\n",
        "        'W_0': nn_model_instance.W_0.data.clone(),\n",
        "        'b': nn_model_instance.b.data.clone(),\n",
        "        'V_0': nn_model_instance.V_0.data.clone(),\n",
        "        'c': nn_model_instance.c.data.clone()\n",
        "    }\n",
        "    print(\"Original weight is {}\".format(original_weights))\n",
        "    print(\"Initial X_raw_pre {}\".format(X_raw_tensor))\n",
        "\n",
        "    for i in range(max_iterations):\n",
        "        # [Insert the existing logic of your loop here, using nn_model_instance, X_raw_tensor, Y_tensor, and other parameters]\n",
        "        # Calculate the gradient at the central point\n",
        "        central_grad = calculate_second_order_grad(nn_model_instance, X_raw_tensor, Y_tensor)\n",
        "        central_grad_norm = torch.norm(central_grad)\n",
        "        central_grad = central_grad / central_grad_norm\n",
        "        #print(central_grad)\n",
        "        # Surrouning points' grads\n",
        "        surrounding_grads_pre = []\n",
        "        norms_pre = []\n",
        "        negative_eigenvalues = []\n",
        "\n",
        "\n",
        "        # Calculate the gradient at the surrounding points by MC\n",
        "        for _ in range(MC_num_samples):\n",
        "\n",
        "            nn_model_sample_pre = SimpleNN(custom_W_0=original_weights['W_0'],custom_b=original_weights['b'],custom_V_0=original_weights['V_0'],custom_c=original_weights['c'])\n",
        "            #print(\"W_0 (before perturbation):\", nn_model_sample.W_0.data)\n",
        "            # Perturb weights\n",
        "            #perturb_weights_uniform_fixed_range(nn_model_sample, max_deviation=max_deviation_for_weight)\n",
        "            perturb_weights_uniform_fixed_range(nn_model_sample_pre, scale = max_deviation_for_weight)\n",
        "            #print(\"W_0 (after perturbation):\", nn_model_sample.W_0.data)\n",
        "            _, eigenvalues = compute_hessian_and_eigenvalues(nn_model_sample_pre, X_raw_tensor, Y_tensor)\n",
        "            # Filter out negative eigenvalues (considering the real part)\n",
        "            negative = [e.real for e in eigenvalues if e.real < 0]\n",
        "            if negative:\n",
        "              most_negative_eigenvalue = min(negative)\n",
        "            else:\n",
        "              # Return None if there are no negative eigenvalues\n",
        "              print(\"FOUND A LOCAM MINIMUM!\")\n",
        "              print(\"FOUND A LOCAM MINIMUM!at:{}\".format(X_raw_tensor))\n",
        "            negative_eigenvalues.append(most_negative_eigenvalue)\n",
        "            negative = []\n",
        "            grad_pre = calculate_second_order_grad(nn_model_sample_pre, X_raw_tensor, Y_tensor)\n",
        "            #grad_norm = torch.norm(grad)\n",
        "            #grad = grad / grad_norm\n",
        "            surrounding_grads_pre.append(grad_pre)\n",
        "            #negative_eigenvalues.append(torch.norm(grad_pre).item())\n",
        "\n",
        "\n",
        "        # Calculate average pre_norm\n",
        "        #average_negative_eigenvalues = sum(negative_eigenvalues) / len(negative_eigenvalues)\n",
        "\n",
        "        # Calculate the median of negative eigenvalues\n",
        "        median_negative_eigenvalue = np.median([eigenvalue for eigenvalue in negative_eigenvalues if eigenvalue < 0])\n",
        "\n",
        "\n",
        "        # Filter gradients corresponding to the smallest 50% of negative eigenvalues\n",
        "        above_average_negative_eigenvalues = [grad for grad, eigenvalue in zip(surrounding_grads_pre, negative_eigenvalues) if eigenvalue < median_negative_eigenvalue]\n",
        "        above_average_negative_eigenvalues = [grad / torch.norm(grad) for grad in above_average_negative_eigenvalues]\n",
        "\n",
        "        #print(above_average_grads)\n",
        "        sum_above_average_negative_eigenvalues = sum(above_average_negative_eigenvalues)\n",
        "\n",
        "        # Average the large norm gradients\n",
        "        if above_average_negative_eigenvalues:\n",
        "          average_above_average_negative_eigenvalues = sum_above_average_negative_eigenvalues / len(above_average_negative_eigenvalues)\n",
        "          #print(average_above_average_grad)\n",
        "        else:\n",
        "          # Handle the case where no gradient is above average\n",
        "          average_above_average_negative_eigenvalues = torch.zeros_like(X_raw_tensor)\n",
        "\n",
        "\n",
        "        #print(\"Surrounding grad {}\".format(surrounding_grads))\n",
        "\n",
        "        # Combine gradients\n",
        "        combined_grad = (1-surrounding_proportion) * central_grad + surrounding_proportion * average_above_average_negative_eigenvalues\n",
        "        #combined_grad =  average_surrounding_grad\n",
        "        #print(combined_grad)\n",
        "        # Calculate the norm of the combined gradient\n",
        "        combined_grad_norm = torch.norm(combined_grad)\n",
        "\n",
        "        # Check for a non-zero norm to avoid division by zero\n",
        "        if combined_grad_norm > 0:\n",
        "        # Normalize the gradient\n",
        "          normalized_grad = combined_grad / combined_grad_norm\n",
        "\n",
        "        else:\n",
        "          print(\"Gradient is zero; no update required.\")\n",
        "###############\n",
        "\n",
        "        # Check if the norm of the second-order gradient is below the threshold\n",
        "        if torch.norm(combined_grad) < threshold:\n",
        "            print(f\"Convergence reached at iteration {i}\")\n",
        "            break\n",
        "        # Update X_raw using the normalized gradient and learning rate\n",
        "        X_raw_tensor.data -= learning_rate * normalized_grad\n",
        "\n",
        "        # Zero out gradients for the next iteration\n",
        "        nn_model_instance.zero_grad()\n",
        "        X_raw_tensor.grad = None\n",
        "        # Update and checks as per your original code\n",
        "\n",
        "\n",
        "\n",
        "    # Print final modified data\n",
        "    #print(surrounding_grads)\n",
        "    #print(\"Final modified X_raw:\")\n",
        "    #if len(above_average_negative_eigenvalues) < 0.5*MC_pre_num_samples:\n",
        "      #print(\"need more MC_pre_num_samples\")\n",
        "    #else:\n",
        "    print(\"Used surrounding points: {}\".format(len(above_average_negative_eigenvalues)))\n",
        "\n",
        "    print(\"Output X is: {}\".format(X_raw_tensor))\n",
        "    print(negative_eigenvalues)\n",
        "\n",
        "\n",
        "\n",
        "    # Return the optimized X_raw tensor\n",
        "    return X_raw_tensor\n",
        "\n",
        "# Example usage\n",
        "optimized_X_1 = optimize_data_with_gradients(X_raw, Y, W_0, b, V_0, c, max_iterations=50, learning_rate=0.1, MC_num_samples=100, surrounding_proportion=0.9, max_deviation_for_weight=0.05, threshold=0.001)\n"
      ],
      "metadata": {
        "id": "hzb_VvUdxrG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_raw_torch = torch.tensor(optimized_X_3, requires_grad=True)\n",
        "Y_torch = torch.tensor(Y)\n",
        "\n",
        "\n",
        "# Set a threshold for the norm of the second-order gradient\n",
        "threshold = 0.001 # Adjust this threshold as needed\n",
        "max_iterations = 30 # Maximum number of iterations to prevent infinite loops\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Monte Carlo method sampling points\n",
        "MC_num_samples = 200\n",
        "\n",
        "# Surrouning points' grads' propotion\n",
        "surrounding_propotion = 0.9\n",
        "\n",
        "# Weight perturbation\n",
        "max_deviation_for_weight = 0.01\n",
        "\n",
        "nn_model = SimpleNN(W_0, b, V_0, c)\n",
        "\n",
        "#original_weights = W_0, b, V_0, c\n",
        "original_weights = {\n",
        "    'W_0': nn_model.W_0.data.clone(),\n",
        "    'b': nn_model.b.data.clone(),\n",
        "    'V_0': nn_model.V_0.data.clone(),\n",
        "    'c': nn_model.c.data.clone()\n",
        "}\n",
        "print(\"Original weight is {}\".format(original_weights))\n",
        "print(\"Initial X_raw {}\".format(X_raw_torch))\n",
        "#max_deviation_for_X = 0.02  # You can adjust this value as needed\n",
        "#perturb_data(X_raw_torch, max_deviation=max_deviation_for_X)\n",
        "#print(\"Perturbed X_raw {}\".format(X_raw_torch))\n",
        "\n",
        "for i in range(max_iterations):\n",
        "\n",
        "    # Calculate the gradient at the central point\n",
        "    central_grad = calculate_second_order_grad(nn_model, X_raw_torch, Y_torch)\n",
        "    central_grad_norm = torch.norm(central_grad)\n",
        "    central_grad = central_grad / central_grad_norm\n",
        "    #print(central_grad)\n",
        "    # Surrouning points' grads\n",
        "    surrounding_grads = []\n",
        "    norms = []\n",
        "\n",
        "\n",
        "    # Calculate the gradient at the surrounding points by MC\n",
        "    for _ in range(MC_num_samples):\n",
        "\n",
        "      nn_model_sample = SimpleNN(custom_W_0=original_weights['W_0'],custom_b=original_weights['b'],custom_V_0=original_weights['V_0'],custom_c=original_weights['c'])\n",
        "      #print(\"W_0 (before perturbation):\", nn_model_sample.W_0.data)\n",
        "      # Perturb weights\n",
        "      #perturb_weights_uniform_fixed_range(nn_model_sample, max_deviation=max_deviation_for_weight)\n",
        "      perturb_weights_uniform_fixed_range(nn_model_sample,scale = 0.05)\n",
        "      #print(\"W_0 (after perturbation):\", nn_model_sample.W_0.data)\n",
        "      # Calculate second-order gradient\n",
        "      grad = calculate_second_order_grad(nn_model_sample, X_raw_torch, Y_torch)\n",
        "      #grad_norm = torch.norm(grad)\n",
        "      #grad = grad / grad_norm\n",
        "      surrounding_grads.append(grad)\n",
        "      norms.append(torch.norm(grad).item())\n",
        "\n",
        "    # Calculate average norm\n",
        "    average_norm = sum(norms) / len(norms)\n",
        "\n",
        "    # Filter and sum gradients with norms above average\n",
        "    above_average_grads = [grad for grad, norm in zip(surrounding_grads, norms) if norm > 0.2 * average_norm]\n",
        "    above_average_grads = [grad / torch.norm(grad) for grad in above_average_grads]\n",
        "\n",
        "    #print(above_average_grads)\n",
        "    sum_above_average_grads = sum(above_average_grads)\n",
        "\n",
        "    # Average the large norm gradients\n",
        "    if above_average_grads:\n",
        "      average_above_average_grad = sum_above_average_grads / len(above_average_grads)\n",
        "      #print(average_above_average_grad)\n",
        "    else:\n",
        "    # Handle the case where no gradient is above average\n",
        "      average_above_average_grad = torch.zeros_like(X_raw_torch)\n",
        "\n",
        "\n",
        "    #print(\"Surrounding grad {}\".format(surrounding_grads))\n",
        "\n",
        "    # Combine gradients\n",
        "    combined_grad = (1-surrounding_propotion) * central_grad + surrounding_propotion * average_above_average_grad\n",
        "    #combined_grad =  average_surrounding_grad\n",
        "    #print(combined_grad)\n",
        "    # Calculate the norm of the combined gradient\n",
        "    combined_grad_norm = torch.norm(combined_grad)\n",
        "\n",
        "    # Check for a non-zero norm to avoid division by zero\n",
        "    if combined_grad_norm > 0:\n",
        "    # Normalize the gradient\n",
        "      normalized_grad = combined_grad / combined_grad_norm\n",
        "\n",
        "    else:\n",
        "      print(\"Gradient is zero; no update required.\")\n",
        "###############\n",
        "\n",
        "    # Check if the norm of the second-order gradient is below the threshold\n",
        "    if torch.norm(combined_grad) < threshold:\n",
        "        print(f\"Convergence reached at iteration {i}\")\n",
        "        break\n",
        "\n",
        "    # Update X_raw using gradient descent\n",
        "    X_raw_torch.data -= learning_rate * normalized_grad\n",
        "\n",
        "    # Zero out gradients for the next iteration\n",
        "    nn_model.zero_grad()\n",
        "    X_raw_torch.grad = None\n",
        "\n",
        "# Print final modified data\n",
        "#print(surrounding_grads)\n",
        "#print(\"Final modified X_raw:\")\n",
        "if len(above_average_grads) < 100:\n",
        "  print(\"need more MC_num_samples\")\n",
        "else:\n",
        "  print(\"Used surrounding points: {}\".format(len(above_average_grads)))\n",
        "\n",
        "print(X_raw_torch)\n",
        "print(negative_eigenvalues)"
      ],
      "metadata": {
        "id": "UUZ3a_stx46f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_raw_torch = torch.tensor(optimized_X_3, requires_grad=True)\n",
        "Y_torch = torch.tensor(Y)\n",
        "\n",
        "\n",
        "# Set a threshold for the norm of the second-order gradient\n",
        "threshold = 0.001 # Adjust this threshold as needed\n",
        "max_iterations = 30 # Maximum number of iterations to prevent infinite loops\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Monte Carlo method sampling points\n",
        "MC_num_samples = 200\n",
        "\n",
        "# Surrouning points' grads' propotion\n",
        "surrounding_propotion = 0.9\n",
        "\n",
        "# Weight perturbation\n",
        "max_deviation_for_weight = 0.01\n",
        "\n",
        "nn_model = SimpleNN(W_0, b, V_0, c)\n",
        "\n",
        "#original_weights = W_0, b, V_0, c\n",
        "original_weights = {\n",
        "    'W_0': nn_model.W_0.data.clone(),\n",
        "    'b': nn_model.b.data.clone(),\n",
        "    'V_0': nn_model.V_0.data.clone(),\n",
        "    'c': nn_model.c.data.clone()\n",
        "}\n",
        "print(\"Original weight is {}\".format(original_weights))\n",
        "print(\"Initial X_raw {}\".format(X_raw_torch))\n",
        "#max_deviation_for_X = 0.02  # You can adjust this value as needed\n",
        "#perturb_data(X_raw_torch, max_deviation=max_deviation_for_X)\n",
        "#print(\"Perturbed X_raw {}\".format(X_raw_torch))\n",
        "\n",
        "for i in range(max_iterations):\n",
        "\n",
        "    # Calculate the gradient at the central point\n",
        "    central_grad = calculate_second_order_grad(nn_model, X_raw_torch, Y_torch)\n",
        "    central_grad_norm = torch.norm(central_grad)\n",
        "    central_grad = central_grad / central_grad_norm\n",
        "    #print(central_grad)\n",
        "    # Surrouning points' grads\n",
        "    surrounding_grads = []\n",
        "    norms = []\n",
        "\n",
        "\n",
        "    # Calculate the gradient at the surrounding points by MC\n",
        "    for _ in range(MC_num_samples):\n",
        "\n",
        "      nn_model_sample = SimpleNN(custom_W_0=original_weights['W_0'],custom_b=original_weights['b'],custom_V_0=original_weights['V_0'],custom_c=original_weights['c'])\n",
        "      #print(\"W_0 (before perturbation):\", nn_model_sample.W_0.data)\n",
        "      # Perturb weights\n",
        "      #perturb_weights_uniform_fixed_range(nn_model_sample, max_deviation=max_deviation_for_weight)\n",
        "      perturb_weights_uniform_fixed_range(nn_model_sample,scale = 0.05)\n",
        "      #print(\"W_0 (after perturbation):\", nn_model_sample.W_0.data)\n",
        "      # Calculate second-order gradient\n",
        "      grad = calculate_second_order_grad(nn_model_sample, X_raw_torch, Y_torch)\n",
        "      #grad_norm = torch.norm(grad)\n",
        "      #grad = grad / grad_norm\n",
        "      surrounding_grads.append(grad)\n",
        "      norms.append(torch.norm(grad).item())\n",
        "\n",
        "    # Calculate average norm\n",
        "    average_norm = sum(norms) / len(norms)\n",
        "\n",
        "    # Filter and sum gradients with norms above average\n",
        "    above_average_grads = [grad for grad, norm in zip(surrounding_grads, norms) if norm > 0.2 * average_norm]\n",
        "    above_average_grads = [grad / torch.norm(grad) for grad in above_average_grads]\n",
        "\n",
        "    #print(above_average_grads)\n",
        "    sum_above_average_grads = sum(above_average_grads)\n",
        "\n",
        "    # Average the large norm gradients\n",
        "    if above_average_grads:\n",
        "      average_above_average_grad = sum_above_average_grads / len(above_average_grads)\n",
        "      #print(average_above_average_grad)\n",
        "    else:\n",
        "    # Handle the case where no gradient is above average\n",
        "      average_above_average_grad = torch.zeros_like(X_raw_torch)\n",
        "\n",
        "\n",
        "    #print(\"Surrounding grad {}\".format(surrounding_grads))\n",
        "\n",
        "    # Combine gradients\n",
        "    combined_grad = (1-surrounding_propotion) * central_grad + surrounding_propotion * average_above_average_grad\n",
        "    #combined_grad =  average_surrounding_grad\n",
        "    #print(combined_grad)\n",
        "    # Calculate the norm of the combined gradient\n",
        "    combined_grad_norm = torch.norm(combined_grad)\n",
        "\n",
        "    # Check for a non-zero norm to avoid division by zero\n",
        "    if combined_grad_norm > 0:\n",
        "    # Normalize the gradient\n",
        "      normalized_grad = combined_grad / combined_grad_norm\n",
        "\n",
        "    else:\n",
        "      print(\"Gradient is zero; no update required.\")\n",
        "###############\n",
        "\n",
        "    # Check if the norm of the second-order gradient is below the threshold\n",
        "    if torch.norm(combined_grad) < threshold:\n",
        "        print(f\"Convergence reached at iteration {i}\")\n",
        "        break\n",
        "\n",
        "    # Update X_raw using gradient descent\n",
        "    X_raw_torch.data -= learning_rate * normalized_grad\n",
        "\n",
        "    # Zero out gradients for the next iteration\n",
        "    nn_model.zero_grad()\n",
        "    X_raw_torch.grad = None\n",
        "\n",
        "# Print final modified data\n",
        "#print(surrounding_grads)\n",
        "#print(\"Final modified X_raw:\")\n",
        "if len(above_average_grads) < 100:\n",
        "  print(\"need more MC_num_samples\")\n",
        "else:\n",
        "  print(\"Used surrounding points: {}\".format(len(above_average_grads)))\n",
        "\n",
        "print(X_raw_torch)\n",
        "print(negative_eigenvalues)"
      ],
      "metadata": {
        "id": "fiqG3HcGV4u0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eead8b58-42e0-442a-f988-71507ff16df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-52c0fdd6e8f8>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_raw_torch = torch.tensor(X_raw_pre, requires_grad=True)\n",
            "<ipython-input-49-52c0fdd6e8f8>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Y_torch = torch.tensor(Y_pre)\n",
            "<ipython-input-14-a815e9696fa5>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_W_0 = torch.tensor(custom_W_0, dtype=torch.float64)\n",
            "<ipython-input-14-a815e9696fa5>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_b = torch.tensor(custom_b, dtype=torch.float64)\n",
            "<ipython-input-14-a815e9696fa5>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_V_0 = torch.tensor(custom_V_0, dtype=torch.float64)\n",
            "<ipython-input-14-a815e9696fa5>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_c = torch.tensor(custom_c, dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weight is {'W_0': tensor([[ 3.9979,  5.2638],\n",
            "        [ 1.0698, -1.8901]], dtype=torch.float64), 'b': tensor([[1.8545, 0.8022]], dtype=torch.float64), 'V_0': tensor([[-10.1389],\n",
            "        [-10.4242]], dtype=torch.float64), 'c': tensor([[5.0116]], dtype=torch.float64)}\n",
            "Initial X_raw tensor([[11.0898, -7.6508],\n",
            "        [ 2.0012, -5.9457],\n",
            "        [ 4.9975, -0.8779],\n",
            "        [ 6.1208, -5.1308],\n",
            "        [-5.5426, -6.2105],\n",
            "        [ 1.1080,  0.1753],\n",
            "        [-7.4783,  0.5124],\n",
            "        [-7.9947,  0.8285],\n",
            "        [-0.8698,  0.8182],\n",
            "        [-3.4649,  2.3132]], dtype=torch.float64, requires_grad=True)\n",
            "Used surrounding points: 200\n",
            "tensor([[11.0898, -7.6508],\n",
            "        [ 2.0012, -5.9457],\n",
            "        [ 4.9975, -0.8779],\n",
            "        [ 6.1208, -5.1308],\n",
            "        [-5.5426, -6.2105],\n",
            "        [ 1.1080,  0.1753],\n",
            "        [-7.4783,  0.5124],\n",
            "        [-7.9947,  0.8285],\n",
            "        [-0.7339,  0.4347],\n",
            "        [-3.4439,  2.3197]], dtype=torch.float64, requires_grad=True)\n",
            "[tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model_final = SimpleNN(W_0, b, V_0, c)\n",
        "hessian_matrix_final, eigenvalues_final = compute_hessian_and_eigenvalues(nn_model, X_raw_torch, Y_torch)\n",
        "print(X_raw_torch)\n",
        "print(Y_torch)\n",
        "print(eigenvalues_final)\n",
        "check_local_minimum(eigenvalues_final)"
      ],
      "metadata": {
        "id": "nDgON5VoZ6_X",
        "outputId": "6be587a7-eb5d-4503-bf05-bb0fbe6f0322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[11.0898, -7.6508],\n",
            "        [ 2.0012, -5.9457],\n",
            "        [ 4.9975, -0.8779],\n",
            "        [ 6.1208, -5.1308],\n",
            "        [-5.5426, -6.2105],\n",
            "        [ 1.1080,  0.1753],\n",
            "        [-7.4783,  0.5124],\n",
            "        [-7.9947,  0.8285],\n",
            "        [-0.7339,  0.4347],\n",
            "        [-3.4439,  2.3197]], dtype=torch.float64, requires_grad=True)\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]], dtype=torch.float64)\n",
            "tensor([ 2.0579e-01+0.j,  7.9276e-03+0.j,  4.7714e-03+0.j, -1.4180e-03+0.j,\n",
            "        -5.0715e-04+0.j, -4.3948e-05+0.j, -4.1439e-06+0.j,  1.1427e-07+0.j,\n",
            "        -1.8893e-09+0.j], dtype=torch.complex128)\n",
            "This is not a local minimum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "def calculate_gradient_for_smallest_eigenvalue(model, X_raw_torch, Y_torch):\n",
        "    # Forward pass\n",
        "    output = model(X_raw_torch)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = -torch.mean(Y_torch * torch.log(output) + (1 - Y_torch) * torch.log(1 - output))\n",
        "\n",
        "    # First-order gradients (w.r.t weights)\n",
        "    first_order_grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
        "\n",
        "    # Flatten the first-order gradients\n",
        "    grads_flatten = torch.cat([g.contiguous().view(-1) for g in first_order_grads])\n",
        "\n",
        "    # Hessian computation\n",
        "    hessian = []\n",
        "    for grad in grads_flatten:\n",
        "        # Compute second-order gradients (w.r.t each element in the first-order gradients)\n",
        "        second_order_grads = torch.autograd.grad(grad, model.parameters(), retain_graph=True)\n",
        "\n",
        "        # Flatten and collect the second-order gradients\n",
        "        hessian_row = torch.cat([g.contiguous().view(-1) for g in second_order_grads])\n",
        "        hessian.append(hessian_row)\n",
        "\n",
        "    # Stack to form the Hessian matrix\n",
        "    hessian_matrix = torch.stack(hessian)\n",
        "\n",
        "    # Compute eigenvalues\n",
        "    eigenvalues, _ = torch.linalg.eig(hessian_matrix)\n",
        "    # Extract the real parts of eigenvalues\n",
        "    eigenvalues_real = eigenvalues.real\n",
        "\n",
        "    # Identify the smallest eigenvalue\n",
        "    smallest_eigenvalue = torch.min(eigenvalues_real)\n",
        "\n",
        "    # Check if the smallest eigenvalue requires gradients\n",
        "    if smallest_eigenvalue.requires_grad:\n",
        "      # Compute the gradient of the smallest eigenvalue (or its negative) with respect to X\n",
        "      if smallest_eigenvalue < 0:\n",
        "        grad_X = torch.autograd.grad(-smallest_eigenvalue, X_raw_torch, retain_graph=True)[0]\n",
        "      else:\n",
        "        print(\"FOUND A LOCAL MINIMUM!\")\n",
        "        print(f\"Local minimum at X: {X_raw_torch.detach().numpy()}\")\n",
        "        weights = {name: param.clone().detach().numpy() for name, param in model.named_parameters()}\n",
        "        print(f\"Local minimum at W: {weights}\")\n",
        "        grad_X = None  # or handle this case as you see fit\n",
        "    else:\n",
        "      print(\"Smallest eigenvalue does not require grad or is not part of the computation graph.\")\n",
        "      grad_X = None\n",
        "\n",
        "    return grad_X, eigenvalues, smallest_eigenvalue"
      ],
      "metadata": {
        "id": "E6mAQ3Hz-55q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set a threshold for the norm of the second-order gradient\n",
        "threshold = 0.05 # Adjust this threshold as needed\n",
        "max_iterations = 10  # Maximum number of iterations to prevent infinite loops\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.2\n",
        "\n",
        "# Monte Carlo method sampling points\n",
        "MC_num_samples = 10\n",
        "\n",
        "# Surrouning points' grad\n",
        "surrounding_grads = []\n",
        "\n",
        "# parameters for the first layer\n",
        "W_0 = np.array([[1.05954587,-0.05625762],[-0.03749863,1.09518945]])\n",
        "b = np.array([[-0.050686,-0.06894291]])\n",
        "\n",
        "# parameters for the second layer\n",
        "\n",
        "V_0 = np.array([[3.76921058],[-3.72139955]])\n",
        "c = np.array([[-0.0148436]])\n",
        "\n",
        "nn_model = SimpleNN(W_0, b, V_0, c)\n",
        "\n",
        "perturb_weights(nn_model, max_deviation=0.01)\n",
        "restore_weights(nn_model, original_weights)  # Assuming perturb_weights is defined as before\n",
        "print(perturb_weights)\n",
        "K=calculate_second_order_grad(nn_model, X_raw_torch, Y_torch)\n",
        "print(K)\n",
        "print(\"W_0 (after perturbation):\", nn_model.W_0.data)\n",
        "print(\"b (after perturbation):\", nn_model.b.data)\n",
        "print(\"V_0 (after perturbation):\", nn_model.V_0.data)\n",
        "print(\"c (after perturbation):\", nn_model.c.data)"
      ],
      "metadata": {
        "id": "_qolZlVZ-x8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forward pass\n",
        "output = nn_model(X_raw_torch)\n",
        "\n",
        "# Compute loss\n",
        "loss = -torch.mean(Y_torch * torch.log(output) + (1 - Y_torch) * torch.log(1 - output))\n",
        "print(loss)\n",
        "# Compute gradients of the loss w.r.t. weights\n",
        "loss.backward(create_graph=True)\n",
        "\n",
        "\n",
        "# Combine and compute the norm of all gradients\n",
        "all_grads = torch.cat([nn_model.W_0.grad.flatten(), nn_model.V_0.grad.flatten(), nn_model.b.grad.flatten(), nn_model.c.grad.flatten()])\n",
        "print(all_grads)\n",
        "grad_norm = torch.norm(all_grads)\n",
        "print(grad_norm)\n",
        "# Compute the derivative of the grad_norm with respect to X\n",
        "second_order_grad = torch.autograd.grad(grad_norm, X_raw_torch, retain_graph=True)[0]\n",
        "print(torch.norm(second_order_grad))\n",
        "# If you want to perform gradient descent on X_raw\n",
        "learning_rate = 0.01\n",
        "#X_raw_torch.data -= learning_rate * second_order_grad"
      ],
      "metadata": {
        "id": "s_654-o11XCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_raw_pre_1 = torch.tensor(X_raw_pre, requires_grad=True)\n",
        "Y_pre_1 = torch.tensor(Y_pre_1)\n",
        "\n",
        "\n",
        "# Set a threshold for the norm of the second-order gradient\n",
        "threshold = 0.001 # Adjust this threshold as needed\n",
        "max_iterations_pre = 50 # Maximum number of iterations to prevent infinite loops\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Monte Carlo method sampling points\n",
        "MC_pre_num_samples = 150\n",
        "\n",
        "# Surrouning points' grads' propotion\n",
        "surrounding_propotion_pre = 0.5\n",
        "\n",
        "# Weight perturbation\n",
        "max_deviation_for_weight_pre = 0.05\n",
        "\n",
        "nn_model_pre = SimpleNN(W_0, b, V_0, c)\n",
        "\n",
        "#original_weights = W_0, b, V_0, c\n",
        "original_weights = {\n",
        "    'W_0': nn_model.W_0.data.clone(),\n",
        "    'b': nn_model.b.data.clone(),\n",
        "    'V_0': nn_model.V_0.data.clone(),\n",
        "    'c': nn_model.c.data.clone()\n",
        "}\n",
        "print(\"Original weight is {}\".format(original_weights))\n",
        "print(\"Initial X_raw_pre_1 {}\".format(X_raw_pre_1))\n",
        "#max_deviation_for_X = 0.02  # You can adjust this value as needed\n",
        "#perturb_data(X_raw_torch, max_deviation=max_deviation_for_X)\n",
        "#print(\"Perturbed X_raw {}\".format(X_raw_torch))\n",
        "\n",
        "for i in range(max_iterations_pre):\n",
        "\n",
        "    # Calculate the gradient at the central point\n",
        "    central_grad_pre = calculate_second_order_grad(nn_model_pre, X_raw_pre_1, Y_pre_1)\n",
        "    central_grad_pre_norm = torch.norm(central_grad_pre)\n",
        "    central_grad_pre = central_grad_pre / central_grad_pre_norm\n",
        "    #print(central_grad)\n",
        "    # Surrouning points' grads\n",
        "    surrounding_grads_pre = []\n",
        "    norms_pre = []\n",
        "    negative_eigenvalues = []\n",
        "\n",
        "\n",
        "    # Calculate the gradient at the surrounding points by MC\n",
        "    for _ in range(MC_pre_num_samples):\n",
        "\n",
        "      nn_model_sample_pre = SimpleNN(custom_W_0=original_weights['W_0'],custom_b=original_weights['b'],custom_V_0=original_weights['V_0'],custom_c=original_weights['c'])\n",
        "      #print(\"W_0 (before perturbation):\", nn_model_sample.W_0.data)\n",
        "      # Perturb weights\n",
        "      #perturb_weights_uniform_fixed_range(nn_model_sample, max_deviation=max_deviation_for_weight)\n",
        "      perturb_weights_uniform_fixed_range(nn_model_sample_pre, scale = 0.1)\n",
        "      #print(\"W_0 (after perturbation):\", nn_model_sample.W_0.data)\n",
        "      _, eigenvalues = compute_hessian_and_eigenvalues(nn_model_sample_pre, X_raw_pre_1, Y_pre_1)\n",
        "      most_negative_eigenvalue = select_most_negative_eigenvalue(eigenvalues)\n",
        "      negative_eigenvalues.append(most_negative_eigenvalue)\n",
        "      grad_pre = calculate_second_order_grad(nn_model_sample_pre, X_raw_pre_1, Y_pre_1)\n",
        "      #grad_norm = torch.norm(grad)\n",
        "      #grad = grad / grad_norm\n",
        "      surrounding_grads_pre.append(grad_pre)\n",
        "      #negative_eigenvalues.append(torch.norm(grad_pre).item())\n",
        "\n",
        "    # Calculate average pre_norm\n",
        "    average_negative_eigenvalues = sum(negative_eigenvalues) / len(negative_eigenvalues)\n",
        "\n",
        "    # Calculate the median of negative eigenvalues\n",
        "    median_negative_eigenvalue = np.median([eigenvalue for eigenvalue in negative_eigenvalues if eigenvalue < 0])\n",
        "\n",
        "    # Filter gradients corresponding to the smallest 50% of negative eigenvalues\n",
        "    above_average_negative_eigenvalues = [grad for grad, eigenvalue in zip(surrounding_grads_pre, negative_eigenvalues) if eigenvalue < median_negative_eigenvalue]\n",
        "    above_average_negative_eigenvalues = [grad / torch.norm(grad) for grad in above_average_negative_eigenvalues]\n",
        "\n",
        "    #print(above_average_grads)\n",
        "    sum_above_average_negative_eigenvalues = sum(above_average_negative_eigenvalues)\n",
        "\n",
        "    # Average the large norm gradients\n",
        "    if above_average_negative_eigenvalues:\n",
        "      average_above_average_negative_eigenvalues = sum_above_average_negative_eigenvalues / len(above_average_negative_eigenvalues)\n",
        "      #print(average_above_average_grad)\n",
        "    else:\n",
        "    # Handle the case where no gradient is above average\n",
        "      average_above_average_negative_eigenvalues = torch.zeros_like(X_raw_pre_1)\n",
        "\n",
        "\n",
        "    #print(\"Surrounding grad {}\".format(surrounding_grads))\n",
        "\n",
        "    # Combine gradients\n",
        "    combined_grad_pre = (1-surrounding_propotion_pre) * central_grad_pre + surrounding_propotion_pre * average_above_average_negative_eigenvalues\n",
        "    #combined_grad =  average_surrounding_grad\n",
        "    #print(combined_grad)\n",
        "    # Calculate the norm of the combined gradient\n",
        "    combined_grad_pre_norm = torch.norm(combined_grad_pre)\n",
        "\n",
        "    # Check for a non-zero norm to avoid division by zero\n",
        "    if combined_grad_pre_norm > 0:\n",
        "    # Normalize the gradient\n",
        "      normalized_grad_pre = combined_grad_pre / combined_grad_pre_norm\n",
        "\n",
        "    else:\n",
        "      print(\"Gradient is zero; no update required.\")\n",
        "###############\n",
        "\n",
        "    # Check if the norm of the second-order gradient is below the threshold\n",
        "    if torch.norm(combined_grad_pre) < threshold:\n",
        "        print(f\"Convergence reached at iteration {i}\")\n",
        "        break\n",
        "    # Update X_raw using the normalized gradient and learning rate\n",
        "    X_raw_pre_1.data -= learning_rate * normalized_grad_pre\n",
        "\n",
        "    # Zero out gradients for the next iteration\n",
        "    nn_model.zero_grad()\n",
        "    X_raw_pre_1.grad = None\n",
        "\n",
        "# Print final modified data\n",
        "#print(surrounding_grads)\n",
        "#print(\"Final modified X_raw:\")\n",
        "if len(above_average_negative_eigenvalues) < 0.5*MC_pre_num_samples:\n",
        "  print(\"need more MC_pre_num_samples\")\n",
        "else:\n",
        "  print(\"Used surrounding points: {}\".format(len(above_average_negative_eigenvalues)))\n",
        "\n",
        "print(X_raw_pre_1)\n",
        "print(negative_eigenvalues)"
      ],
      "metadata": {
        "id": "9UEa48L2rbb3"
      }
    }
  ]
}