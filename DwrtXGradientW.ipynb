{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjJiPVVscP3zMnt97xvdIe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zw2788/LocalMinimaConstruction/blob/main/DwrtXGradientW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from IPython.display import Image\n",
        "from torch.autograd import grad\n"
      ],
      "metadata": {
        "id": "6IhL4Cbb1mfH"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, custom_W_0, custom_b, custom_V_0, custom_c):\n",
        "        super(SimpleNN, self).__init__()\n",
        "\n",
        "        # Ensure that the custom weights are tensors\n",
        "        custom_W_0 = torch.tensor(custom_W_0, dtype=torch.float64)\n",
        "        custom_b = torch.tensor(custom_b, dtype=torch.float64)\n",
        "        custom_V_0 = torch.tensor(custom_V_0, dtype=torch.float64)\n",
        "        custom_c = torch.tensor(custom_c, dtype=torch.float64)\n",
        "\n",
        "        # Set the custom weights and biases\n",
        "        self.W_0 = nn.Parameter(custom_W_0)\n",
        "        self.b = nn.Parameter(custom_b)\n",
        "        self.V_0 = nn.Parameter(custom_V_0)\n",
        "        self.c = nn.Parameter(custom_c)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.sigmoid(torch.add(torch.matmul(x, self.W_0), self.b))\n",
        "        x = F.sigmoid(torch.add(torch.matmul(x, self.V_0), self.c))\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "#custom_W_0 = [[0.1, 0.2], [0.3, 0.4]]  # Replace with your own initial values\n",
        "#custom_b = [0.1, 0.2]  # Replace with your own initial values\n",
        "#custom_V_0 = [[0.1], [0.2]]  # Replace with your own initial values\n",
        "#custom_c = [0.1]  # Replace with your own initial values\n",
        "\n",
        "\n",
        "def calculate_second_order_grad(model, X_raw_torch, Y_torch):\n",
        "    # Forward pass\n",
        "    output = model(X_raw_torch)\n",
        "    # Compute loss\n",
        "    loss = -torch.mean(Y_torch * torch.log(output) + (1 - Y_torch) * torch.log(1 - output))\n",
        "    # Compute gradients of the loss w.r.t. weights\n",
        "    loss.backward(create_graph=True)\n",
        "    # Combine and compute the norm of all gradients\n",
        "    all_grads = torch.cat([param.grad.flatten() for param in model.parameters()])\n",
        "    grad_norm = torch.norm(all_grads)\n",
        "    #print(all_grads)\n",
        "    # Compute the derivative of the grad_norm with respect to X\n",
        "    second_order_grad = torch.autograd.grad(grad_norm, X_raw_torch, retain_graph=True)[0]\n",
        "    return second_order_grad\n",
        "\n",
        "def calculate_second_order_grad_trap(model, X_raw_torch, Y_torch):\n",
        "    # Forward pass\n",
        "    output = model(X_raw_torch)\n",
        "    # Compute loss\n",
        "    loss = -torch.mean(Y_torch * torch.log(output) + (1 - Y_torch) * torch.log(1 - output))\n",
        "    # Compute gradients of the loss w.r.t. weights\n",
        "    loss.backward(create_graph=True)\n",
        "    # Combine and compute the norm of all gradients\n",
        "    all_grads = torch.cat([param.grad.flatten() for param in model.parameters()])\n",
        "    grad_norm = torch.norm(all_grads)\n",
        "    #print(all_grads)\n",
        "    # Compute the derivative of the grad_norm with respect to X\n",
        "    second_order_grad = torch.autograd.grad(grad_norm, X_raw_torch, retain_graph=True)[0]\n",
        "    return second_order_grad\n"
      ],
      "metadata": {
        "id": "vBoW060Y1pZB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perturb_weights_normal(model, max_deviation=0.01):\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            std_dev = param.abs().mean() * max_deviation\n",
        "            noise = torch.randn(param.size()) * std_dev\n",
        "            param[:] = param + noise\n",
        "\n",
        "def perturb_weights_uniform(model, max_deviation=0.01):\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            scale_factor = param.abs().mean() * max_deviation\n",
        "            # Generate uniform noise in the range [-scale_factor, scale_factor]\n",
        "            noise = (torch.rand(param.size()) * 2 - 1) * scale_factor\n",
        "            param[:] = param + noise\n",
        "def perturb_weights_uniform_fixed_range(model, scale):\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            # Generate uniform noise in the range [-0.1, 0.1]\n",
        "            noise = (torch.rand(param.size()) * 2 - 1) * scale\n",
        "            param[:] = param + noise\n",
        "\n",
        "def restore_weights(model, saved_state):\n",
        "    with torch.no_grad():\n",
        "        for name, param in model.named_parameters():\n",
        "            param[:] = saved_state[name]\n",
        "\n",
        "def perturb_data(X, max_deviation=0.01):\n",
        "    \"\"\"Perturb the data tensor X.\"\"\"\n",
        "    with torch.no_grad():\n",
        "        std_dev = X.abs().mean() * max_deviation\n",
        "        noise = torch.randn(X.size()) * std_dev\n",
        "        X.add_(noise)"
      ],
      "metadata": {
        "id": "iuOrsYOiJo91"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-executing the code to define the function for computing the Hessian matrix and its eigenvalues\n",
        "\n",
        "def compute_hessian_and_eigenvalues(model, data, target):\n",
        "    \"\"\"\n",
        "    Compute the Hessian matrix and its eigenvalues for the weights of a neural network model.\n",
        "\n",
        "    :param model: The neural network model.\n",
        "    :param data: Input data (X).\n",
        "    :param target: Target data (Y).\n",
        "    :return: Hessian matrix and its eigenvalues.\n",
        "    \"\"\"\n",
        "    # Forward pass\n",
        "    output = model(data)\n",
        "    # Compute loss\n",
        "    loss = -torch.mean(target * torch.log(output) + (1 - target) * torch.log(1 - output))\n",
        "\n",
        "    # First-order gradients (w.r.t weights)\n",
        "    first_order_grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
        "\n",
        "    # Flatten the first-order gradients\n",
        "    grads_flatten = torch.cat([g.contiguous().view(-1) for g in first_order_grads])\n",
        "\n",
        "    # Hessian computation\n",
        "    hessian = []\n",
        "    for grad in grads_flatten:\n",
        "        # Compute second-order gradients (w.r.t each element in the first-order gradients)\n",
        "        second_order_grads = torch.autograd.grad(grad, model.parameters(), retain_graph=True)\n",
        "\n",
        "        # Flatten and collect the second-order gradients\n",
        "        hessian_row = torch.cat([g.contiguous().view(-1) for g in second_order_grads])\n",
        "        hessian.append(hessian_row)\n",
        "\n",
        "    # Stack to form the Hessian matrix\n",
        "    hessian_matrix = torch.stack(hessian)\n",
        "\n",
        "    # Compute eigenvalues\n",
        "    eigenvalues, _ = torch.linalg.eig(hessian_matrix)\n",
        "\n",
        "    return hessian_matrix, eigenvalues\n",
        "\n",
        "# Note: To use this function, you'll need to provide your neural network model, the input data (X), and the target data (Y).\n",
        "\n",
        "\n",
        "def check_local_minimum(eigenvalues):\n",
        "    # Check if all eigenvalues have a positive real part\n",
        "    if all(eig.real > 0 for eig in eigenvalues):\n",
        "        print(\"This is a local minimum.\")\n",
        "    else:\n",
        "        print(\"This is not a local minimum.\")\n"
      ],
      "metadata": {
        "id": "DG4bccfJA4Jk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/zw2788/LocalMinimaConstruction/main/output(49830_100000).csv\")\n",
        "\n",
        "data.head()\n",
        "\n",
        "# data , drop NaN values\n",
        "X_raw,  Y, W_0, b, V_0, c = data[['x_2dvec']].dropna().values, data['y'].dropna().values, data[['W_0']].dropna().values, data[['b']].dropna().values, data[['V_0']].dropna().values, data[['c']].dropna().values\n",
        "\n",
        "#convert string to array\n",
        "\n",
        "X_raw = np.array([eval(s[0]) for s in X_raw])\n",
        "\n",
        "W_0 = np.array([eval(s[0]) for s in W_0])\n",
        "\n",
        "b = np.array([eval(s[0]) for s in b])\n",
        "\n",
        "V_0 = np.array([eval(s[0]) for s in V_0])\n",
        "\n",
        "c = np.array([eval(s[0]) for s in c])\n",
        "\n",
        "# Standardize the input\n",
        "# Leave blank to match the example in paper\n",
        "\n",
        "# formatting\n",
        "Y = Y.reshape((-1, 1))\n",
        "print(X_raw)\n",
        "print(Y)\n",
        "print(W_0)\n",
        "#print(X_raw.shape[0])\n",
        "X_raw = torch.tensor(X_raw, requires_grad=True)\n",
        "Y = torch.tensor(Y)\n",
        "print(W_0, b, V_0, c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0h9evkU59mR",
        "outputId": "69001f48-7a68-4d93-9e05-3fe4866a883f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-4.05673409 -1.57919633]\n",
            " [-4.08621693 -7.32655954]\n",
            " [ 5.7382369   6.51035595]\n",
            " [-3.54674959 -9.48523903]\n",
            " [-5.44635487 -1.49153161]\n",
            " [-3.05762291  7.25649118]\n",
            " [-9.07657528  3.435395  ]\n",
            " [-3.56827617 -2.80349135]\n",
            " [ 4.2420435   2.56337643]\n",
            " [-8.37438869  4.51332331]]\n",
            "[[1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "[[ 3.37760234 -8.4564867 ]\n",
            " [ 0.92768544  2.91912866]]\n",
            "[[ 3.37760234 -8.4564867 ]\n",
            " [ 0.92768544  2.91912866]] [[ 4.70377207 -0.07312825]] [[ 4.8233037 ]\n",
            " [-4.45070505]] [[-4.8279748]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model = SimpleNN(W_0, b, V_0, c)\n",
        "hessian_matrix_initial, eigenvalues_initial = compute_hessian_and_eigenvalues(nn_model, X_raw, Y)\n",
        "\n",
        "print(eigenvalues_initial)\n",
        "check_local_minimum(eigenvalues_initial)"
      ],
      "metadata": {
        "id": "zkVm-srfFTQZ",
        "outputId": "febfb9f8-a991-4566-c0f0-649cdb989aee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-3.2549e+00+0.j,  1.0070e-01+0.j,  8.7098e-03+0.j,  1.8168e-03+0.j,\n",
            "        -2.7687e-04+0.j,  4.1569e-05+0.j, -6.5372e-09+0.j,  1.3711e-10+0.j,\n",
            "        -4.7058e-13+0.j], dtype=torch.complex128)\n",
            "This is not a local minimum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable anomaly detection\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "def make_model_copy(original_model):\n",
        "    # Create a new instance of the model\n",
        "    model_copy = SimpleNN(W_0, b, V_0, c)  # Use the same parameters as used to create the original model\n",
        "    # Copy the initial weights from the original model\n",
        "    model_copy.load_state_dict(original_model.state_dict())\n",
        "    return model_copy\n",
        "\n",
        "def trap_model(original_model, X, Y, max_iterations, number_of_x_iterations, weightlr=0.01, xlr=0.01):\n",
        "    X_modifiable = X.clone().detach().requires_grad_(True)\n",
        "\n",
        "    for current_iteration in range(max_iterations):\n",
        "        # Use a fresh copy of the model\n",
        "        model = make_model_copy(original_model)\n",
        "\n",
        "        optimizer_weights = optim.SGD(model.parameters(), lr=weightlr)\n",
        "\n",
        "    # Optimizer for the weights\n",
        "    #optimizer_weights = optim.SGD(model.parameters(), lr=weightlr)\n",
        "\n",
        "        # Save initial state of the model\n",
        "        initial_state_dict = model.state_dict()\n",
        "\n",
        "        # Load initial weights using the deep copied state\n",
        "        model.load_state_dict(copy.deepcopy(initial_state_dict))\n",
        "\n",
        "        # Reset the optimizer state\n",
        "        optimizer_weights = optim.SGD(model.parameters(), lr=weightlr)\n",
        "\n",
        "        # Forward pass with current X_modifiable and initial weights\n",
        "        model_output = model(X_modifiable)\n",
        "\n",
        "        old_loss = -torch.mean(Y * torch.log(model_output) + (1 - Y) * torch.log(1 - model_output))\n",
        "\n",
        "        # Gradient descent step for weights\n",
        "        optimizer_weights.zero_grad()\n",
        "        old_loss.backward()\n",
        "        optimizer_weights.step()\n",
        "        # Gather all gradients into a list after flattening\n",
        "        gradients = [param.grad.view(-1) for param in model.parameters() if param.grad is not None]\n",
        "\n",
        "        # Concatenate all gradients to form a single vector and calculate its norm\n",
        "        total_gradient = torch.cat(gradients)\n",
        "        total_gradient_norm = total_gradient.norm()\n",
        "\n",
        "        # Check if the combined gradient norm is below the threshold\n",
        "        if total_gradient_norm < 1e-8:\n",
        "            print(\"Combined gradient norm below threshold, stopping optimization.\")\n",
        "            break\n",
        "\n",
        "        # Save new weights and create a copy of X_modifiable for the inner loop\n",
        "        new_state_dict = model.state_dict()\n",
        "        X_inner = X_modifiable.clone().detach().requires_grad_(True)\n",
        "        optimizer_x = optim.SGD([X_inner], lr=xlr)\n",
        "\n",
        "        for _ in range(number_of_x_iterations):\n",
        "            # Load new weights\n",
        "            model.load_state_dict(new_state_dict)\n",
        "            print(\"before {}\".format(X_inner))\n",
        "            output_new = model(X_inner)\n",
        "            new_loss = -torch.mean(Y * torch.log(output_new) + (1 - Y) * torch.log(1 - output_new))\n",
        "\n",
        "            # Calculate combined loss\n",
        "            combined_loss = old_loss.detach() - new_loss\n",
        "            print(combined_loss)\n",
        "\n",
        "\n",
        "            # Check condition\n",
        "            if combined_loss <= 0:\n",
        "                print(\"acheive! at:{}\".format(current_iteration))\n",
        "                print(X_inner)\n",
        "                break\n",
        "            else:\n",
        "                optimizer_x.zero_grad()\n",
        "                combined_loss.backward()\n",
        "                optimizer_x.step()\n",
        "        #print(X_inner.data)\n",
        "        # Update X_modifiable with changes from the inner loop\n",
        "        X_modifiable.data = X_inner.data\n",
        "\n",
        "    # After completing all iterations, load initial weights\n",
        "    model.load_state_dict(initial_state_dict)\n",
        "\n",
        "    # Forward pass with the final X_modifiable and initial weights\n",
        "    final_output = model(X_modifiable)\n",
        "    final_loss = -torch.mean(Y * torch.log(final_output) + (1 - Y) * torch.log(1 - final_output))\n",
        "\n",
        "    # Calculate gradients with respect to the initial weights\n",
        "    optimizer_weights.zero_grad()\n",
        "    final_loss.backward()\n",
        "\n",
        "    # Calculate and print the norm of the gradients for each parameter\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"Gradient norm for {name}: {param.grad.norm().item()}\")\n",
        "\n",
        "    # Return the modified X\n",
        "    return X_modifiable\n",
        "\n",
        "# Initialize your model, X, Y, etc. outside the function\n",
        "# ... [Your initialization code here] ...\n",
        "\n",
        "# Call the function\n",
        "# ... [Call to train_model function here] ...\n",
        "#Example\n",
        "# Initialize your model, X, Y, etc. outside the function\n",
        "#custom_W_0 = [...]  # Replace [...] with your initial weights\n",
        "#custom_b = [...]   # Replace [...] with your initial bias\n",
        "#custom_V_0 = [...]  # Replace [...] with your next layer weights\n",
        "#custom_c = [...]   # Replace [...] with your next layer bias\n",
        "#model = SimpleNN(custom_W_0, custom_b, custom_V_0, custom_c)\n",
        "#X = torch.tensor([...], dtype=torch.float64, requires_grad=True)  # Replace [...] with your initial data\n",
        "#Y = torch.tensor([...], dtype=torch.float64)  # Replace [...] with target data\n",
        "\n",
        "# Call the function\n",
        "nn_model_trap = SimpleNN(W_0, b, V_0, c)\n",
        "trap_X = trap_model(nn_model_trap, X_raw, Y, max_iterations=50, number_of_x_iterations=10, weightlr= 0.005, xlr= 0.02)\n"
      ],
      "metadata": {
        "id": "szMjSQUcynkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea2d902e-cc3e-4920-8b0f-884581be2488"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5467, -9.4852],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0576,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0011, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5534, -9.4829],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0576,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0014, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:0\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5534, -9.4829],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0576,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5534, -9.4829],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0576,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0010, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5598, -9.4807],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0576,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0012, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:1\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5598, -9.4807],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0576,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5598, -9.4807],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0576,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0009, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5659, -9.4786],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0576,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0011, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:2\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5659, -9.4786],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0576,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5659, -9.4786],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0576,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0009, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5716, -9.4767],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0575,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0009, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:3\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5716, -9.4767],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0575,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5716, -9.4767],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0575,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0008, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5771, -9.4747],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0575,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0008, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:4\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5771, -9.4747],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0575,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5771, -9.4747],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0575,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0008, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5824, -9.4729],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0575,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0007, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:5\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5824, -9.4729],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0575,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5824, -9.4729],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0575,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0007, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5874, -9.4712],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0575,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0007, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:6\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5874, -9.4712],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0575,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5874, -9.4712],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0575,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0007, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5923, -9.4695],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0575,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0006, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:7\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5923, -9.4695],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0575,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5923, -9.4695],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0575,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0007, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5969, -9.4679],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0574,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0005, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:8\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5969, -9.4679],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0574,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5969, -9.4679],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0574,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0006, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6014, -9.4664],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0574,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0005, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:9\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6014, -9.4664],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0574,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6014, -9.4664],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0574,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0006, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6057, -9.4649],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0574,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:10\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6057, -9.4649],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0574,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6057, -9.4649],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0574,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0006, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6098, -9.4635],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0574,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:11\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6098, -9.4635],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0574,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6098, -9.4635],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0574,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0006, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6138, -9.4621],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0573,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:12\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6138, -9.4621],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0573,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6138, -9.4621],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0573,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0006, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6177, -9.4607],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0573,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:13\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6177, -9.4607],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0573,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6177, -9.4607],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0573,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0005, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6215, -9.4594],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0573,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:14\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6215, -9.4594],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0573,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6215, -9.4594],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0573,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0005, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6251, -9.4582],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0573,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:15\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6251, -9.4582],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0573,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6251, -9.4582],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0573,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0005, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6286, -9.4570],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0573,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:16\n",
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6286, -9.4570],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0573,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6286, -9.4570],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0573,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0005, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6320, -9.4558],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0572,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:17\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6320, -9.4558],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0572,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6320, -9.4558],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0572,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0005, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6353, -9.4546],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0572,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:18\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6353, -9.4546],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0572,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6353, -9.4546],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0572,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0005, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6386, -9.4535],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0572,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-9.6531e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:19\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6386, -9.4535],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0572,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6386, -9.4535],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0572,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0005, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6417, -9.4525],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0572,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-7.5324e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:20\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6417, -9.4525],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0572,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6417, -9.4525],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0572,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0005, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6447, -9.4514],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0572,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-5.5749e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:21\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6447, -9.4514],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0572,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6447, -9.4514],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0572,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6477, -9.4504],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0571,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-3.7645e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:22\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6477, -9.4504],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0571,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6477, -9.4504],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0571,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6506, -9.4494],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0571,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-2.0871e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:23\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6506, -9.4494],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0571,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6506, -9.4494],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0571,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6534, -9.4484],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0571,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-5.3014e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:24\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6534, -9.4484],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0571,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6534, -9.4484],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0571,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6561, -9.4475],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0571,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(9.1738e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6588, -9.4465],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0570,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:25\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6588, -9.4465],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0570,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6588, -9.4465],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0570,  7.2566],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6615, -9.4456],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0570,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(3.5228e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6640, -9.4447],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0570,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:26\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6640, -9.4447],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0570,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6640, -9.4447],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0570,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6665, -9.4439],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0570,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(5.7957e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6690, -9.4430],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0570,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:27\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6690, -9.4430],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0570,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6690, -9.4430],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0570,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6714, -9.4422],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0569,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(7.7897e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6737, -9.4414],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0569,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:28\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6737, -9.4414],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0569,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6737, -9.4414],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0569,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6760, -9.4406],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0569,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(9.5481e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6782, -9.4398],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0569,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:29\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6782, -9.4398],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0569,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6782, -9.4398],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0569,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6805, -9.4391],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0569,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6826, -9.4383],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0568,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:30\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6826, -9.4383],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0568,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6826, -9.4383],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0568,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6847, -9.4376],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0568,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6868, -9.4369],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0568,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:31\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6868, -9.4369],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0568,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6868, -9.4369],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0568,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6889, -9.4362],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0568,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6909, -9.4355],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0568,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-8.5482e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:32\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6909, -9.4355],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0568,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6909, -9.4355],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0568,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6928, -9.4348],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0567,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6948, -9.4341],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0567,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-5.9034e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:33\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6948, -9.4341],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0567,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6948, -9.4341],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0567,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6967, -9.4335],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0567,  7.2567],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6985, -9.4328],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0567,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-3.5201e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:34\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6985, -9.4328],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0567,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.6985, -9.4328],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0567,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7004, -9.4322],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0566,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7022, -9.4316],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0566,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-1.3652e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:35\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7022, -9.4316],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0566,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7022, -9.4316],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0566,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0004, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7039, -9.4310],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0566,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7057, -9.4303],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0566,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(5.8939e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7074, -9.4298],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0566,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:36\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7074, -9.4298],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0566,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7074, -9.4298],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0566,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7091, -9.4292],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0565,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7108, -9.4286],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0565,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(3.1969e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7124, -9.4280],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0565,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:37\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7124, -9.4280],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0565,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7124, -9.4280],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0565,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7140, -9.4275],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0565,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7156, -9.4269],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0565,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(5.4733e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7172, -9.4264],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0564,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-8.2729e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:38\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7172, -9.4264],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0564,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7172, -9.4264],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0564,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7188, -9.4258],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0564,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7203, -9.4253],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0564,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(7.4720e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7218, -9.4248],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0564,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-5.1608e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:39\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7218, -9.4248],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0564,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7218, -9.4248],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0564,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7233, -9.4243],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0563,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7248, -9.4238],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0563,  7.2568],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(9.2361e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7262, -9.4233],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0563,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-2.4121e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:40\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7262, -9.4233],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0563,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7262, -9.4233],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0563,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7276, -9.4228],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0563,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7290, -9.4223],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0563,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7304, -9.4218],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0562,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(2.7374e-07, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7318, -9.4213],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0562,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:41\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7318, -9.4213],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0562,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7318, -9.4213],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0562,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7332, -9.4209],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0562,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7345, -9.4204],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0562,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7358, -9.4199],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0562,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(2.8746e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7371, -9.4195],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0561,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-6.6443e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:42\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7371, -9.4195],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0561,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7371, -9.4195],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0561,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7384, -9.4191],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0561,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7397, -9.4186],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0561,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7410, -9.4182],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0561,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(5.3350e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7422, -9.4177],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0560,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-3.3298e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:43\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7422, -9.4177],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0560,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7422, -9.4177],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0560,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7434, -9.4173],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0560,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7447, -9.4169],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0560,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7459, -9.4165],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0560,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(7.4753e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7471, -9.4161],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0560,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-4.4464e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:44\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7471, -9.4161],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0560,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7471, -9.4161],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0560,  7.2569],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7482, -9.4157],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0559,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7494, -9.4153],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0559,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7506, -9.4149],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0559,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(9.3484e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7517, -9.4145],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0559,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(2.0819e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7528, -9.4141],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0559,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-5.0343e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:45\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7528, -9.4141],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0559,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7528, -9.4141],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0559,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7540, -9.4137],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0558,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7551, -9.4133],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0558,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7562, -9.4129],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0558,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7572, -9.4126],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0558,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(4.8213e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7583, -9.4122],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0557,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-1.6064e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:46\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7583, -9.4122],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0557,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7583, -9.4122],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0557,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7594, -9.4118],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0557,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7604, -9.4115],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0557,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7615, -9.4111],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0557,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7625, -9.4107],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0557,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(7.1762e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7635, -9.4104],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0556,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(1.3423e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7645, -9.4100],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0556,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-4.3830e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:47\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7645, -9.4100],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0556,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7645, -9.4100],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0556,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7655, -9.4097],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0556,  7.2570],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7665, -9.4093],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0556,  7.2571],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7675, -9.4090],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0556,  7.2571],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7685, -9.4087],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0555,  7.2571],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(9.5899e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7695, -9.4083],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0555,  7.2571],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(4.3666e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7704, -9.4080],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0555,  7.2571],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-7.6450e-06, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:48\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7704, -9.4080],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0555,  7.2571],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7704, -9.4080],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0555,  7.2571],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7714, -9.4077],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0555,  7.2571],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0003, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7723, -9.4073],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0554,  7.2571],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7733, -9.4070],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0554,  7.2571],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0002, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7742, -9.4067],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0554,  7.2571],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.0001, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7751, -9.4064],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0554,  7.2571],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(6.9359e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7760, -9.4061],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0554,  7.2571],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(2.3114e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "before tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7769, -9.4058],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0553,  7.2571],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(-2.2361e-05, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "acheive! at:49\n",
            "tensor([[-4.0568, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.7769, -9.4058],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0553,  7.2571],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "Gradient norm for W_0: 0.05373089836654497\n",
            "Gradient norm for b: 0.005304058805093577\n",
            "Gradient norm for V_0: 0.2221693310666097\n",
            "Gradient norm for c: 0.09981507013073573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_raw)\n",
        "print(trap_X)\n",
        "hessian_matrix_trap, eigenvalues_trap = compute_hessian_and_eigenvalues(nn_model_trap, trap_X, Y)\n",
        "\n",
        "print(eigenvalues_trap)\n",
        "check_local_minimum(eigenvalues_trap)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0CYBTk5J-Fu",
        "outputId": "e3f07e7c-986e-4194-9517-70179838e466"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4.0567, -1.5792],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-3.5467, -9.4852],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-3.0576,  7.2565],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor([[-4.0608, -1.5803],\n",
            "        [-4.0862, -7.3266],\n",
            "        [ 5.7382,  6.5104],\n",
            "        [-4.2783, -9.2243],\n",
            "        [-5.4464, -1.4915],\n",
            "        [-2.8733,  7.3065],\n",
            "        [-9.0766,  3.4354],\n",
            "        [-3.5683, -2.8035],\n",
            "        [ 4.2420,  2.5634],\n",
            "        [-8.3744,  4.5133]], dtype=torch.float64, requires_grad=True)\n",
            "tensor([ 1.0365e-01+0.j, -1.3196e-02+0.j, -9.1241e-03+0.j,  5.9365e-03+0.j,\n",
            "        -2.4236e-04+0.j,  1.8963e-04+0.j, -4.0391e-10+0.j,  3.4897e-10+0.j,\n",
            "        -9.1514e-13+0.j], dtype=torch.complex128)\n",
            "This is not a local minimum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_data_with_centralgradients(X_raw, Y, W_0, b, V_0, c, max_iterations=20, learning_rate=0.1,  threshold=0.001):\n",
        "    \"\"\"\n",
        "    Optimize data using gradient calculations and Monte Carlo method.\n",
        "\n",
        "    :param nn_model: Neural Network Model class.\n",
        "    :param X_raw: Input data.\n",
        "    :param Y: Target data.\n",
        "    :param W_0, b, V_0, c: Initial weights and biases for the neural network.\n",
        "    :param max_iterations: Maximum number of iterations.\n",
        "    :param learning_rate: Learning rate for optimization.\n",
        "    :param MC_num_samples: Number of samples for Monte Carlo method.\n",
        "    :param surrounding_proportion: Proportion of surrounding points' gradients.\n",
        "    :param max_deviation_for_weight: Maximum deviation for weight perturbation.\n",
        "    :param threshold: Threshold for the norm of the second-order gradient.\n",
        "    :return: Optimized X_raw tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert data to PyTorch tensors\n",
        "    X_raw_tensor = X_raw.clone().detach().requires_grad_(True) if X_raw.requires_grad else torch.tensor(X_raw, dtype=torch.float64, requires_grad=True)\n",
        "    Y_tensor = Y.clone().detach().requires_grad_(True) if Y.requires_grad else torch.tensor(Y, dtype=torch.float64, requires_grad=True)\n",
        "\n",
        "\n",
        "    # Initialize the neural network with provided weights\n",
        "    nn_model_instance = SimpleNN(W_0, b, V_0, c)\n",
        "\n",
        "    # Store original weights\n",
        "    original_weights = {\n",
        "        'W_0': nn_model_instance.W_0.data.clone(),\n",
        "        'b': nn_model_instance.b.data.clone(),\n",
        "        'V_0': nn_model_instance.V_0.data.clone(),\n",
        "        'c': nn_model_instance.c.data.clone()\n",
        "    }\n",
        "    print(\"Original weight is {}\".format(original_weights))\n",
        "    print(\"Initial X_raw_pre {}\".format(X_raw_tensor))\n",
        "\n",
        "    for i in range(max_iterations):\n",
        "        # [Insert the existing logic of your loop here, using nn_model_instance, X_raw_tensor, Y_tensor, and other parameters]\n",
        "        # Calculate the gradient at the central point\n",
        "        central_grad = calculate_second_order_grad(nn_model_instance, X_raw_tensor, Y_tensor)\n",
        "        # Check if grad_X is None before proceeding\n",
        "        central_grad_norm = torch.norm(central_grad)\n",
        "        central_grad = central_grad / central_grad_norm\n",
        "        #print(central_grad)\n",
        "        # Surrouning points' grads\n",
        "        surrounding_grads_pre = []\n",
        "        norms_pre = []\n",
        "        negative_eigenvalues = []\n",
        "\n",
        "\n",
        "        # Combine gradients\n",
        "        combined_grad = central_grad\n",
        "        #combined_grad =  average_surrounding_grad\n",
        "        #print(combined_grad)\n",
        "        # Calculate the norm of the combined gradient\n",
        "        combined_grad_norm = torch.norm(combined_grad)\n",
        "\n",
        "        # Check for a non-zero norm to avoid division by zero\n",
        "        if combined_grad_norm == 0:\n",
        "        # Normalize the gradient\n",
        "          print(\"Gradient is zero; no update required.\")\n",
        "\n",
        "###############\n",
        "\n",
        "        # Check if the norm of the second-order gradient is below the threshold\n",
        "        if torch.norm(combined_grad) < threshold:\n",
        "            print(f\"Convergence reached at iteration {i}\")\n",
        "            break\n",
        "        # Update X_raw using the normalized gradient and learning rate\n",
        "        X_raw_tensor.data -= learning_rate * combined_grad_norm\n",
        "\n",
        "        # Zero out gradients for the next iteration\n",
        "        nn_model_instance.zero_grad()\n",
        "        X_raw_tensor.grad = None\n",
        "        # Update and checks as per your original code\n",
        "\n",
        "\n",
        "\n",
        "    # Print final modified data\n",
        "\n",
        "    print(\"Output X is: {}\".format(X_raw_tensor))\n",
        "\n",
        "\n",
        "    print(central_grad_norm)\n",
        "    # Return the optimized X_raw tensor\n",
        "    return X_raw_tensor\n",
        "\n",
        "# Example usage\n",
        "optimized_X_1 = optimize_data_with_centralgradients(trap_X, Y, W_0, b, V_0, c, max_iterations=1000, learning_rate=0.001,  threshold=0.0001)\n"
      ],
      "metadata": {
        "id": "QR7lCrl3d2un",
        "outputId": "85d90dbe-5275-45ee-bd42-34fe4c78a383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-fb3eef455826>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Y_tensor = Y.clone().detach().requires_grad_(True) if Y.requires_grad else torch.tensor(Y, dtype=torch.float64, requires_grad=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weight is {'W_0': tensor([[-0.9854, -7.0746],\n",
            "        [-0.7950, -5.9667]], dtype=torch.float64), 'b': tensor([[2.9537, 2.3977]], dtype=torch.float64), 'V_0': tensor([[-8.6610],\n",
            "        [-6.9776]], dtype=torch.float64), 'c': tensor([[6.6996]], dtype=torch.float64)}\n",
            "Initial X_raw_pre tensor([[ 0.1222,  0.1974],\n",
            "        [ 0.6699,  1.4908],\n",
            "        [ 0.1828,  0.1296],\n",
            "        [-3.1624, -3.5892],\n",
            "        [ 0.2212,  0.0867],\n",
            "        [ 0.2715, -0.6380],\n",
            "        [ 0.7825,  1.3818],\n",
            "        [ 1.3966,  3.5302],\n",
            "        [ 0.2329,  0.0736],\n",
            "        [ 2.6141, -0.3701]], dtype=torch.float64, requires_grad=True)\n",
            "Output X is: tensor([[-0.8778, -0.8026],\n",
            "        [-0.3301,  0.4908],\n",
            "        [-0.8172, -0.8704],\n",
            "        [-4.1624, -4.5892],\n",
            "        [-0.7788, -0.9133],\n",
            "        [-0.7285, -1.6380],\n",
            "        [-0.2175,  0.3818],\n",
            "        [ 0.3966,  2.5302],\n",
            "        [-0.7671, -0.9264],\n",
            "        [ 1.6141, -1.3701]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.2884, dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model = SimpleNN(W_0, b, V_0, c)\n",
        "hessian_matrix_central, eigenvalues_central = compute_hessian_and_eigenvalues(nn_model, optimized_X_1, Y)\n",
        "\n",
        "print(eigenvalues_central)\n",
        "check_local_minimum(eigenvalues_central)"
      ],
      "metadata": {
        "id": "LOlqYSsAhqW5",
        "outputId": "71b0a1d5-e3d8-4eaf-de26-f1f0a22b8448",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 8.5687e-01+0.j, -8.2876e-02+0.j,  4.8516e-02+0.j,  1.3709e-02+0.j,\n",
            "         3.4205e-03+0.j, -2.7478e-03+0.j,  3.2365e-04+0.j,  1.6174e-04+0.j,\n",
            "        -7.9576e-06+0.j], dtype=torch.complex128)\n",
            "This is not a local minimum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_data_with_gradients(X_raw, Y, W_0, b, V_0, c, max_iterations=20, learning_rate=0.1, MC_num_samples=100, surrounding_proportion=0.5, max_deviation_for_weight=0.05, threshold=0.001):\n",
        "    \"\"\"\n",
        "    Optimize data using gradient calculations and Monte Carlo method.\n",
        "\n",
        "    :param nn_model: Neural Network Model class.\n",
        "    :param X_raw: Input data.\n",
        "    :param Y: Target data.\n",
        "    :param W_0, b, V_0, c: Initial weights and biases for the neural network.\n",
        "    :param max_iterations: Maximum number of iterations.\n",
        "    :param learning_rate: Learning rate for optimization.\n",
        "    :param MC_num_samples: Number of samples for Monte Carlo method.\n",
        "    :param surrounding_proportion: Proportion of surrounding points' gradients.\n",
        "    :param max_deviation_for_weight: Maximum deviation for weight perturbation.\n",
        "    :param threshold: Threshold for the norm of the second-order gradient.\n",
        "    :return: Optimized X_raw tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert data to PyTorch tensors\n",
        "    X_raw_tensor = X_raw.clone().detach().requires_grad_(True) if X_raw.requires_grad else torch.tensor(X_raw, dtype=torch.float64, requires_grad=True)\n",
        "    Y_tensor = Y.clone().detach().requires_grad_(True) if Y.requires_grad else torch.tensor(Y, dtype=torch.float64, requires_grad=True)\n",
        "\n",
        "\n",
        "    # Initialize the neural network with provided weights\n",
        "    nn_model_sur = SimpleNN(W_0, b, V_0, c)\n",
        "\n",
        "    # Store original weights\n",
        "    original_weights = {\n",
        "        'W_0': nn_model_sur.W_0.data.clone(),\n",
        "        'b': nn_model_sur.b.data.clone(),\n",
        "        'V_0': nn_model_sur.V_0.data.clone(),\n",
        "        'c': nn_model_sur.c.data.clone()\n",
        "    }\n",
        "    print(\"Original weight is {}\".format(original_weights))\n",
        "    print(\"Initial X_raw_pre {}\".format(X_raw_tensor))\n",
        "\n",
        "    for i in range(max_iterations):\n",
        "        # [Insert the existing logic of your loop here, using nn_model_instance, X_raw_tensor, Y_tensor, and other parameters]\n",
        "        # Calculate the gradient at the central point\n",
        "        central_grad = calculate_second_order_grad(nn_model_sur, X_raw_tensor, Y_tensor)\n",
        "        # Check if grad_X is None before proceeding\n",
        "        central_grad_norm = torch.norm(central_grad)\n",
        "        central_grad = central_grad / central_grad_norm\n",
        "        #print(central_grad)\n",
        "        # Surrouning points' grads\n",
        "        surrounding_grads_pre = []\n",
        "        norms_pre = []\n",
        "\n",
        "\n",
        "        # Calculate the gradient at the surrounding points by MC\n",
        "        for _ in range(MC_num_samples):\n",
        "\n",
        "            nn_model_sample_pre = SimpleNN(custom_W_0=original_weights['W_0'],custom_b=original_weights['b'],custom_V_0=original_weights['V_0'],custom_c=original_weights['c'])\n",
        "            #print(\"W_0 (before perturbation):\", nn_model_sample.W_0.data)\n",
        "            # Perturb weights\n",
        "            #perturb_weights_uniform_fixed_range(nn_model_sample, max_deviation=max_deviation_for_weight)\n",
        "            perturb_weights_uniform_fixed_range(nn_model_sample_pre, scale = max_deviation_for_weight)\n",
        "            #print(\"W_0 (after perturbation):\", nn_model_sample.W_0.data)\n",
        "            grad_pre = calculate_second_order_grad(nn_model_sample_pre, X_raw_tensor, Y_tensor)\n",
        "            grad_norm = torch.norm(grad_pre)\n",
        "            grad_pre = grad_pre / grad_norm\n",
        "            surrounding_grads_pre.append(grad_pre)\n",
        "            #negative_eigenvalues.append(torch.norm(grad_pre).item())\n",
        "\n",
        "        sum_surrounding_grads_pre = sum(surrounding_grads_pre)\n",
        "\n",
        "        # Average the large norm gradients\n",
        "        average_surrounding_grads_pre = sum_surrounding_grads_pre / len(surrounding_grads_pre)\n",
        "        # Calculate average pre_norm\n",
        "        #average_negative_eigenvalues = sum(negative_eigenvalues) / len(negative_eigenvalues)\n",
        "\n",
        "        # Calculate the median of negative eigenvalues\n",
        "        #median_negative_eigenvalue = np.median([eigenvalue for eigenvalue in negative_eigenvalues if eigenvalue < 0])\n",
        "\n",
        "\n",
        "        # Filter gradients corresponding to the smallest 50% of negative eigenvalues\n",
        "        #above_average_negative_eigenvalues = [grad for grad, eigenvalue in zip(surrounding_grads_pre, negative_eigenvalues) if eigenvalue < median_negative_eigenvalue]\n",
        "        #above_average_negative_eigenvalues = [grad / torch.norm(grad) for grad in above_average_negative_eigenvalues]\n",
        "\n",
        "        #print(above_average_grads)\n",
        "        #sum_above_average_negative_eigenvalues = sum(above_average_negative_eigenvalues)\n",
        "\n",
        "        # Average the large norm gradients\n",
        "        #if above_average_negative_eigenvalues:\n",
        "          #average_above_average_negative_eigenvalues = sum_above_average_negative_eigenvalues / len(above_average_negative_eigenvalues)\n",
        "          #print(average_above_average_grad)\n",
        "        #else:\n",
        "          # Handle the case where no gradient is above average\n",
        "          #average_above_average_negative_eigenvalues = torch.zeros_like(X_raw_tensor)\n",
        "\n",
        "\n",
        "        #print(\"Surrounding grad {}\".format(surrounding_grads))\n",
        "\n",
        "        # Combine gradients\n",
        "        combined_grad = (1-surrounding_proportion) * central_grad + surrounding_proportion * average_surrounding_grads_pre\n",
        "        #combined_grad =  average_surrounding_grad\n",
        "        #print(combined_grad)\n",
        "        # Calculate the norm of the combined gradient\n",
        "        combined_grad_norm = torch.norm(combined_grad)\n",
        "\n",
        "        # Check for a non-zero norm to avoid division by zero\n",
        "        if combined_grad_norm > 0:\n",
        "        # Normalize the gradient\n",
        "          normalized_grad = combined_grad / combined_grad_norm\n",
        "\n",
        "        else:\n",
        "          print(\"Gradient is zero; no update required.\")\n",
        "###############\n",
        "\n",
        "        # Check if the norm of the second-order gradient is below the threshold\n",
        "        if torch.norm(combined_grad) < threshold:\n",
        "            print(f\"Convergence reached at iteration {i}\")\n",
        "            break\n",
        "        # Update X_raw using the normalized gradient and learning rate\n",
        "        X_raw_tensor.data -= learning_rate * normalized_grad\n",
        "\n",
        "        # Zero out gradients for the next iteration\n",
        "        nn_model_sur.zero_grad()\n",
        "        X_raw_tensor.grad = None\n",
        "        # Update and checks as per your original code\n",
        "\n",
        "\n",
        "\n",
        "    # Print final modified data\n",
        "    #print(surrounding_grads)\n",
        "    #print(\"Final modified X_raw:\")\n",
        "    #if len(above_average_negative_eigenvalues) < 0.5*MC_pre_num_samples:\n",
        "      #print(\"need more MC_pre_num_samples\")\n",
        "    #else:\n",
        "    #print(\"Used surrounding points: {}\".format(len(above_average_negative_eigenvalues)))\n",
        "\n",
        "    print(\"Output X is: {}\".format(X_raw_tensor))\n",
        "    #print(negative_eigenvalues)\n",
        "\n",
        "\n",
        "\n",
        "    # Return the optimized X_raw tensor\n",
        "    return X_raw_tensor\n",
        "\n",
        "# Example usage\n",
        "optimized_X_2 = optimize_data_with_gradients(trap_X, Y, W_0, b, V_0, c, max_iterations=50, learning_rate=0.1, MC_num_samples=100, surrounding_proportion=0.3, max_deviation_for_weight=0.01, threshold=0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ug5G6aLkors",
        "outputId": "b59b5df0-4436-4512-c39f-90e4814308fa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-5816f8b1477c>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Y_tensor = Y.clone().detach().requires_grad_(True) if Y.requires_grad else torch.tensor(Y, dtype=torch.float64, requires_grad=True)\n",
            "<ipython-input-3-2e4822dd5dc3>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_W_0 = torch.tensor(custom_W_0, dtype=torch.float64)\n",
            "<ipython-input-3-2e4822dd5dc3>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_b = torch.tensor(custom_b, dtype=torch.float64)\n",
            "<ipython-input-3-2e4822dd5dc3>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_V_0 = torch.tensor(custom_V_0, dtype=torch.float64)\n",
            "<ipython-input-3-2e4822dd5dc3>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_c = torch.tensor(custom_c, dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weight is {'W_0': tensor([[-0.9854, -7.0746],\n",
            "        [-0.7950, -5.9667]], dtype=torch.float64), 'b': tensor([[2.9537, 2.3977]], dtype=torch.float64), 'V_0': tensor([[-8.6610],\n",
            "        [-6.9776]], dtype=torch.float64), 'c': tensor([[6.6996]], dtype=torch.float64)}\n",
            "Initial X_raw_pre tensor([[ 0.1222,  0.1974],\n",
            "        [ 0.6699,  1.4908],\n",
            "        [ 0.1828,  0.1296],\n",
            "        [-3.1624, -3.5892],\n",
            "        [ 0.2212,  0.0867],\n",
            "        [ 0.2715, -0.6380],\n",
            "        [ 0.7825,  1.3818],\n",
            "        [ 1.3966,  3.5302],\n",
            "        [ 0.2329,  0.0736],\n",
            "        [ 2.6141, -0.3701]], dtype=torch.float64, requires_grad=True)\n",
            "Output X is: tensor([[-0.1250, -0.0626],\n",
            "        [ 0.2896,  1.2047],\n",
            "        [-0.0676, -0.1333],\n",
            "        [-3.1624, -3.5891],\n",
            "        [-0.0313, -0.1780],\n",
            "        [ 0.2775, -0.6330],\n",
            "        [ 0.3866,  1.0816],\n",
            "        [ 4.3140,  5.7800],\n",
            "        [-0.0203, -0.1916],\n",
            "        [ 1.9599, -0.9091]], dtype=torch.float64, requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model_X2 = SimpleNN(W_0, b, V_0, c)\n",
        "hessian_matrix_surrounding, eigenvalues_surrounding = compute_hessian_and_eigenvalues(nn_model_X2, optimized_X_2, Y)\n",
        "\n",
        "print(eigenvalues_surrounding)\n",
        "check_local_minimum(eigenvalues_surrounding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4_An8vDPjyE",
        "outputId": "20e0a19c-c0ae-4875-9371-0d09ca831f30"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.3254+0.j,  0.2093+0.j, -0.1277+0.j, -0.0679+0.j,  0.0189+0.j,  0.0015+0.j,\n",
            "        -0.0028+0.j, -0.0007+0.j, -0.0010+0.j], dtype=torch.complex128)\n",
            "This is not a local minimum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_X_2 = optimize_data_with_gradients(optimized_X_1, Y, W_0, b, V_0, c, max_iterations=20, learning_rate=0.05, MC_num_samples=100, surrounding_proportion=0.9, max_deviation_for_weight=0.02, threshold=0.001)"
      ],
      "metadata": {
        "id": "mi-VQ5D7R535",
        "outputId": "7105b639-e3a4-4236-cfde-d2a8e4470466",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-1e9be29dee3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_raw_tensor = torch.tensor(X_raw, requires_grad=True)\n",
            "<ipython-input-19-1e9be29dee3d>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Y_tensor = torch.tensor(Y)\n",
            "<ipython-input-3-a815e9696fa5>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_W_0 = torch.tensor(custom_W_0, dtype=torch.float64)\n",
            "<ipython-input-3-a815e9696fa5>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_b = torch.tensor(custom_b, dtype=torch.float64)\n",
            "<ipython-input-3-a815e9696fa5>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_V_0 = torch.tensor(custom_V_0, dtype=torch.float64)\n",
            "<ipython-input-3-a815e9696fa5>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_c = torch.tensor(custom_c, dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weight is {'W_0': tensor([[ 3.9979,  5.2638],\n",
            "        [ 1.0698, -1.8901]], dtype=torch.float64), 'b': tensor([[1.8545, 0.8022]], dtype=torch.float64), 'V_0': tensor([[-10.1389],\n",
            "        [-10.4242]], dtype=torch.float64), 'c': tensor([[5.0116]], dtype=torch.float64)}\n",
            "Initial X_raw_pre tensor([[11.0898, -7.6508],\n",
            "        [ 1.6931, -6.0680],\n",
            "        [ 4.9975, -0.8779],\n",
            "        [ 6.1208, -5.1308],\n",
            "        [-5.5432, -6.2103],\n",
            "        [ 1.1082,  0.1752],\n",
            "        [-7.4783,  0.5124],\n",
            "        [-7.9947,  0.8285],\n",
            "        [-1.3351,  2.2657],\n",
            "        [-3.4568,  2.3168]], dtype=torch.float64, requires_grad=True)\n",
            "Used surrounding points: 50\n",
            "Output X is: tensor([[11.0898, -7.6508],\n",
            "        [ 1.6931, -6.0680],\n",
            "        [ 4.9975, -0.8779],\n",
            "        [ 6.1208, -5.1308],\n",
            "        [-5.5432, -6.2103],\n",
            "        [ 1.1082,  0.1752],\n",
            "        [-7.4783,  0.5124],\n",
            "        [-7.9947,  0.8285],\n",
            "        [-1.3568,  2.0730],\n",
            "        [-3.4338,  2.3244]], dtype=torch.float64, requires_grad=True)\n",
            "[tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0002, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0002, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0002, dtype=torch.float64), tensor(-0.0002, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0002, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0002, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0002, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0002, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_X_3 = optimize_data_with_gradients(optimized_X_2, Y, W_0, b, V_0, c, max_iterations=20, learning_rate=0.02, MC_num_samples=100, surrounding_proportion=0.9, max_deviation_for_weight=0.01, threshold=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7uQAynJwxIu",
        "outputId": "f67d55c1-bd3b-4311-b085-90588d7c7964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-1e9be29dee3d>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_raw_tensor = torch.tensor(X_raw, requires_grad=True)\n",
            "<ipython-input-19-1e9be29dee3d>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Y_tensor = torch.tensor(Y)\n",
            "<ipython-input-3-a815e9696fa5>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_W_0 = torch.tensor(custom_W_0, dtype=torch.float64)\n",
            "<ipython-input-3-a815e9696fa5>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_b = torch.tensor(custom_b, dtype=torch.float64)\n",
            "<ipython-input-3-a815e9696fa5>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_V_0 = torch.tensor(custom_V_0, dtype=torch.float64)\n",
            "<ipython-input-3-a815e9696fa5>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_c = torch.tensor(custom_c, dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weight is {'W_0': tensor([[ 3.9979,  5.2638],\n",
            "        [ 1.0698, -1.8901]], dtype=torch.float64), 'b': tensor([[1.8545, 0.8022]], dtype=torch.float64), 'V_0': tensor([[-10.1389],\n",
            "        [-10.4242]], dtype=torch.float64), 'c': tensor([[5.0116]], dtype=torch.float64)}\n",
            "Initial X_raw_pre tensor([[11.0898, -7.6508],\n",
            "        [ 1.6931, -6.0680],\n",
            "        [ 4.9975, -0.8779],\n",
            "        [ 6.1208, -5.1308],\n",
            "        [-5.5432, -6.2103],\n",
            "        [ 1.1082,  0.1752],\n",
            "        [-7.4783,  0.5124],\n",
            "        [-7.9947,  0.8285],\n",
            "        [-1.3568,  2.0730],\n",
            "        [-3.4338,  2.3244]], dtype=torch.float64, requires_grad=True)\n",
            "Used surrounding points: 50\n",
            "Output X is: tensor([[11.0898, -7.6508],\n",
            "        [ 1.6932, -6.0680],\n",
            "        [ 4.9975, -0.8779],\n",
            "        [ 6.1208, -5.1308],\n",
            "        [-5.5432, -6.2103],\n",
            "        [ 1.1082,  0.1752],\n",
            "        [-7.4783,  0.5124],\n",
            "        [-7.9947,  0.8285],\n",
            "        [-1.2705,  1.9455],\n",
            "        [-3.4149,  2.3306]], dtype=torch.float64, requires_grad=True)\n",
            "[tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64), tensor(-0.0003, dtype=torch.float64)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model_pre = SimpleNN(W_0, b, V_0, c)\n",
        "hessian_matrix_pre, eigenvalues_pre = compute_hessian_and_eigenvalues(nn_model_pre, optimized_X_3, Y)\n",
        "\n",
        "print(eigenvalues_pre)\n",
        "check_local_minimum(eigenvalues_pre)"
      ],
      "metadata": {
        "id": "PRbJ8sIWR1ge",
        "outputId": "73e82f59-33e2-4458-ad9c-39c4afa3ba9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.9566e-01+0.j,  4.0277e-03+0.j, -2.7943e-04+0.j, -2.2500e-04+0.j,\n",
            "         3.3531e-05+0.j, -4.1906e-06+0.j,  1.2490e-06+0.j,  4.5318e-08+0.j,\n",
            "         2.1484e-10+0.j], dtype=torch.complex128)\n",
            "This is not a local minimum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## use the eigenvalues of hessian to decide whether use the grad.\n",
        "\n",
        "def flatten_gradients(X_raw, Y, W_0, b, V_0, c, max_iterations=20, learning_rate=0.1, MC_num_samples=100, surrounding_proportion=0.5, max_deviation_for_weight=0.05, threshold=0.001):\n",
        "    \"\"\"\n",
        "    Optimize data using gradient calculations and Monte Carlo method.\n",
        "\n",
        "    :param nn_model: Neural Network Model class.\n",
        "    :param X_raw: Input data.\n",
        "    :param Y: Target data.\n",
        "    :param W_0, b, V_0, c: Initial weights and biases for the neural network.\n",
        "    :param max_iterations: Maximum number of iterations.\n",
        "    :param learning_rate: Learning rate for optimization.\n",
        "    :param MC_num_samples: Number of samples for Monte Carlo method.\n",
        "    :param surrounding_proportion: Proportion of surrounding points' gradients.\n",
        "    :param max_deviation_for_weight: Maximum deviation for weight perturbation.\n",
        "    :param threshold: Threshold for the norm of the second-order gradient.\n",
        "    :return: Optimized X_raw tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert data to PyTorch tensors\n",
        "    X_raw_tensor = torch.tensor(X_raw, requires_grad=True)\n",
        "    Y_tensor = torch.tensor(Y)\n",
        "\n",
        "    # Initialize the neural network with provided weights\n",
        "    nn_model_instance = SimpleNN(W_0, b, V_0, c)\n",
        "\n",
        "    # Store original weights\n",
        "    original_weights = {\n",
        "        'W_0': nn_model_instance.W_0.data.clone(),\n",
        "        'b': nn_model_instance.b.data.clone(),\n",
        "        'V_0': nn_model_instance.V_0.data.clone(),\n",
        "        'c': nn_model_instance.c.data.clone()\n",
        "    }\n",
        "    print(\"Original weight is {}\".format(original_weights))\n",
        "    print(\"Initial X_raw_pre {}\".format(X_raw_tensor))\n",
        "\n",
        "    for i in range(max_iterations):\n",
        "        # [Insert the existing logic of your loop here, using nn_model_instance, X_raw_tensor, Y_tensor, and other parameters]\n",
        "        # Calculate the gradient at the central point\n",
        "        central_grad = calculate_second_order_grad(nn_model_instance, X_raw_tensor, Y_tensor)\n",
        "        central_grad_norm = torch.norm(central_grad)\n",
        "        central_grad = central_grad / central_grad_norm\n",
        "        #print(central_grad)\n",
        "        # Surrouning points' grads\n",
        "        surrounding_grads_pre = []\n",
        "        norms_pre = []\n",
        "        negative_eigenvalues = []\n",
        "\n",
        "\n",
        "        # Calculate the gradient at the surrounding points by MC\n",
        "        for _ in range(MC_num_samples):\n",
        "\n",
        "            nn_model_sample_pre = SimpleNN(custom_W_0=original_weights['W_0'],custom_b=original_weights['b'],custom_V_0=original_weights['V_0'],custom_c=original_weights['c'])\n",
        "            #print(\"W_0 (before perturbation):\", nn_model_sample.W_0.data)\n",
        "            # Perturb weights\n",
        "            #perturb_weights_uniform_fixed_range(nn_model_sample, max_deviation=max_deviation_for_weight)\n",
        "            perturb_weights_uniform_fixed_range(nn_model_sample_pre, scale = max_deviation_for_weight)\n",
        "            #print(\"W_0 (after perturbation):\", nn_model_sample.W_0.data)\n",
        "            _, eigenvalues = compute_hessian_and_eigenvalues(nn_model_sample_pre, X_raw_tensor, Y_tensor)\n",
        "            # Filter out negative eigenvalues (considering the real part)\n",
        "            negative = [e.real for e in eigenvalues if e.real < 0]\n",
        "            if negative:\n",
        "              most_negative_eigenvalue = min(negative)\n",
        "            else:\n",
        "              # Return None if there are no negative eigenvalues\n",
        "              print(\"FOUND A LOCAM MINIMUM!\")\n",
        "              print(\"FOUND A LOCAM MINIMUM!at:{}\".format(X_raw_tensor))\n",
        "            negative_eigenvalues.append(most_negative_eigenvalue)\n",
        "            negative = []\n",
        "            grad_pre = calculate_second_order_grad(nn_model_sample_pre, X_raw_tensor, Y_tensor)\n",
        "            #grad_norm = torch.norm(grad)\n",
        "            #grad = grad / grad_norm\n",
        "            surrounding_grads_pre.append(grad_pre)\n",
        "            #negative_eigenvalues.append(torch.norm(grad_pre).item())\n",
        "\n",
        "\n",
        "        # Calculate average pre_norm\n",
        "        #average_negative_eigenvalues = sum(negative_eigenvalues) / len(negative_eigenvalues)\n",
        "\n",
        "        # Calculate the median of negative eigenvalues\n",
        "        median_negative_eigenvalue = np.median([eigenvalue for eigenvalue in negative_eigenvalues if eigenvalue < 0])\n",
        "\n",
        "\n",
        "        # Filter gradients corresponding to the smallest 50% of negative eigenvalues\n",
        "        above_average_negative_eigenvalues = [grad for grad, eigenvalue in zip(surrounding_grads_pre, negative_eigenvalues) if eigenvalue < median_negative_eigenvalue]\n",
        "        above_average_negative_eigenvalues = [grad / torch.norm(grad) for grad in above_average_negative_eigenvalues]\n",
        "\n",
        "        #print(above_average_grads)\n",
        "        sum_above_average_negative_eigenvalues = sum(above_average_negative_eigenvalues)\n",
        "\n",
        "        # Average the large norm gradients\n",
        "        if above_average_negative_eigenvalues:\n",
        "          average_above_average_negative_eigenvalues = sum_above_average_negative_eigenvalues / len(above_average_negative_eigenvalues)\n",
        "          #print(average_above_average_grad)\n",
        "        else:\n",
        "          # Handle the case where no gradient is above average\n",
        "          average_above_average_negative_eigenvalues = torch.zeros_like(X_raw_tensor)\n",
        "\n",
        "\n",
        "        #print(\"Surrounding grad {}\".format(surrounding_grads))\n",
        "\n",
        "        # Combine gradients\n",
        "        combined_grad = (1-surrounding_proportion) * central_grad + surrounding_proportion * average_above_average_negative_eigenvalues\n",
        "        #combined_grad =  average_surrounding_grad\n",
        "        #print(combined_grad)\n",
        "        # Calculate the norm of the combined gradient\n",
        "        combined_grad_norm = torch.norm(combined_grad)\n",
        "\n",
        "        # Check for a non-zero norm to avoid division by zero\n",
        "        if combined_grad_norm > 0:\n",
        "        # Normalize the gradient\n",
        "          normalized_grad = combined_grad / combined_grad_norm\n",
        "\n",
        "        else:\n",
        "          print(\"Gradient is zero; no update required.\")\n",
        "###############\n",
        "\n",
        "        # Check if the norm of the second-order gradient is below the threshold\n",
        "        if torch.norm(combined_grad) < threshold:\n",
        "            print(f\"Convergence reached at iteration {i}\")\n",
        "            break\n",
        "        # Update X_raw using the normalized gradient and learning rate\n",
        "        X_raw_tensor.data -= learning_rate * normalized_grad\n",
        "\n",
        "        # Zero out gradients for the next iteration\n",
        "        nn_model_instance.zero_grad()\n",
        "        X_raw_tensor.grad = None\n",
        "        # Update and checks as per your original code\n",
        "\n",
        "\n",
        "\n",
        "    # Print final modified data\n",
        "    #print(surrounding_grads)\n",
        "    #print(\"Final modified X_raw:\")\n",
        "    #if len(above_average_negative_eigenvalues) < 0.5*MC_pre_num_samples:\n",
        "      #print(\"need more MC_pre_num_samples\")\n",
        "    #else:\n",
        "    print(\"Used surrounding points: {}\".format(len(above_average_negative_eigenvalues)))\n",
        "\n",
        "    print(\"Output X is: {}\".format(X_raw_tensor))\n",
        "    print(negative_eigenvalues)\n",
        "\n",
        "\n",
        "\n",
        "    # Return the optimized X_raw tensor\n",
        "    return X_raw_tensor\n",
        "\n",
        "# Example usage\n",
        "optimized_X_1 = optimize_data_with_gradients(X_raw, Y, W_0, b, V_0, c, max_iterations=50, learning_rate=0.1, MC_num_samples=100, surrounding_proportion=0.9, max_deviation_for_weight=0.05, threshold=0.001)\n"
      ],
      "metadata": {
        "id": "hzb_VvUdxrG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_raw_torch = torch.tensor(optimized_X_3, requires_grad=True)\n",
        "Y_torch = torch.tensor(Y)\n",
        "\n",
        "\n",
        "# Set a threshold for the norm of the second-order gradient\n",
        "threshold = 0.001 # Adjust this threshold as needed\n",
        "max_iterations = 30 # Maximum number of iterations to prevent infinite loops\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Monte Carlo method sampling points\n",
        "MC_num_samples = 200\n",
        "\n",
        "# Surrouning points' grads' propotion\n",
        "surrounding_propotion = 0.9\n",
        "\n",
        "# Weight perturbation\n",
        "max_deviation_for_weight = 0.01\n",
        "\n",
        "nn_model = SimpleNN(W_0, b, V_0, c)\n",
        "\n",
        "#original_weights = W_0, b, V_0, c\n",
        "original_weights = {\n",
        "    'W_0': nn_model.W_0.data.clone(),\n",
        "    'b': nn_model.b.data.clone(),\n",
        "    'V_0': nn_model.V_0.data.clone(),\n",
        "    'c': nn_model.c.data.clone()\n",
        "}\n",
        "print(\"Original weight is {}\".format(original_weights))\n",
        "print(\"Initial X_raw {}\".format(X_raw_torch))\n",
        "#max_deviation_for_X = 0.02  # You can adjust this value as needed\n",
        "#perturb_data(X_raw_torch, max_deviation=max_deviation_for_X)\n",
        "#print(\"Perturbed X_raw {}\".format(X_raw_torch))\n",
        "\n",
        "for i in range(max_iterations):\n",
        "\n",
        "    # Calculate the gradient at the central point\n",
        "    central_grad = calculate_second_order_grad(nn_model, X_raw_torch, Y_torch)\n",
        "    central_grad_norm = torch.norm(central_grad)\n",
        "    central_grad = central_grad / central_grad_norm\n",
        "    #print(central_grad)\n",
        "    # Surrouning points' grads\n",
        "    surrounding_grads = []\n",
        "    norms = []\n",
        "\n",
        "\n",
        "    # Calculate the gradient at the surrounding points by MC\n",
        "    for _ in range(MC_num_samples):\n",
        "\n",
        "      nn_model_sample = SimpleNN(custom_W_0=original_weights['W_0'],custom_b=original_weights['b'],custom_V_0=original_weights['V_0'],custom_c=original_weights['c'])\n",
        "      #print(\"W_0 (before perturbation):\", nn_model_sample.W_0.data)\n",
        "      # Perturb weights\n",
        "      #perturb_weights_uniform_fixed_range(nn_model_sample, max_deviation=max_deviation_for_weight)\n",
        "      perturb_weights_uniform_fixed_range(nn_model_sample,scale = 0.05)\n",
        "      #print(\"W_0 (after perturbation):\", nn_model_sample.W_0.data)\n",
        "      # Calculate second-order gradient\n",
        "      grad = calculate_second_order_grad(nn_model_sample, X_raw_torch, Y_torch)\n",
        "      #grad_norm = torch.norm(grad)\n",
        "      #grad = grad / grad_norm\n",
        "      surrounding_grads.append(grad)\n",
        "      norms.append(torch.norm(grad).item())\n",
        "\n",
        "    # Calculate average norm\n",
        "    average_norm = sum(norms) / len(norms)\n",
        "\n",
        "    # Filter and sum gradients with norms above average\n",
        "    above_average_grads = [grad for grad, norm in zip(surrounding_grads, norms) if norm > 0.2 * average_norm]\n",
        "    above_average_grads = [grad / torch.norm(grad) for grad in above_average_grads]\n",
        "\n",
        "    #print(above_average_grads)\n",
        "    sum_above_average_grads = sum(above_average_grads)\n",
        "\n",
        "    # Average the large norm gradients\n",
        "    if above_average_grads:\n",
        "      average_above_average_grad = sum_above_average_grads / len(above_average_grads)\n",
        "      #print(average_above_average_grad)\n",
        "    else:\n",
        "    # Handle the case where no gradient is above average\n",
        "      average_above_average_grad = torch.zeros_like(X_raw_torch)\n",
        "\n",
        "\n",
        "    #print(\"Surrounding grad {}\".format(surrounding_grads))\n",
        "\n",
        "    # Combine gradients\n",
        "    combined_grad = (1-surrounding_propotion) * central_grad + surrounding_propotion * average_above_average_grad\n",
        "    #combined_grad =  average_surrounding_grad\n",
        "    #print(combined_grad)\n",
        "    # Calculate the norm of the combined gradient\n",
        "    combined_grad_norm = torch.norm(combined_grad)\n",
        "\n",
        "    # Check for a non-zero norm to avoid division by zero\n",
        "    if combined_grad_norm > 0:\n",
        "    # Normalize the gradient\n",
        "      normalized_grad = combined_grad / combined_grad_norm\n",
        "\n",
        "    else:\n",
        "      print(\"Gradient is zero; no update required.\")\n",
        "###############\n",
        "\n",
        "    # Check if the norm of the second-order gradient is below the threshold\n",
        "    if torch.norm(combined_grad) < threshold:\n",
        "        print(f\"Convergence reached at iteration {i}\")\n",
        "        break\n",
        "\n",
        "    # Update X_raw using gradient descent\n",
        "    X_raw_torch.data -= learning_rate * normalized_grad\n",
        "\n",
        "    # Zero out gradients for the next iteration\n",
        "    nn_model.zero_grad()\n",
        "    X_raw_torch.grad = None\n",
        "\n",
        "# Print final modified data\n",
        "#print(surrounding_grads)\n",
        "#print(\"Final modified X_raw:\")\n",
        "if len(above_average_grads) < 100:\n",
        "  print(\"need more MC_num_samples\")\n",
        "else:\n",
        "  print(\"Used surrounding points: {}\".format(len(above_average_grads)))\n",
        "\n",
        "print(X_raw_torch)\n",
        "print(negative_eigenvalues)"
      ],
      "metadata": {
        "id": "UUZ3a_stx46f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_raw_torch = torch.tensor(optimized_X_3, requires_grad=True)\n",
        "Y_torch = torch.tensor(Y)\n",
        "\n",
        "\n",
        "# Set a threshold for the norm of the second-order gradient\n",
        "threshold = 0.001 # Adjust this threshold as needed\n",
        "max_iterations = 30 # Maximum number of iterations to prevent infinite loops\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Monte Carlo method sampling points\n",
        "MC_num_samples = 200\n",
        "\n",
        "# Surrouning points' grads' propotion\n",
        "surrounding_propotion = 0.9\n",
        "\n",
        "# Weight perturbation\n",
        "max_deviation_for_weight = 0.01\n",
        "\n",
        "nn_model = SimpleNN(W_0, b, V_0, c)\n",
        "\n",
        "#original_weights = W_0, b, V_0, c\n",
        "original_weights = {\n",
        "    'W_0': nn_model.W_0.data.clone(),\n",
        "    'b': nn_model.b.data.clone(),\n",
        "    'V_0': nn_model.V_0.data.clone(),\n",
        "    'c': nn_model.c.data.clone()\n",
        "}\n",
        "print(\"Original weight is {}\".format(original_weights))\n",
        "print(\"Initial X_raw {}\".format(X_raw_torch))\n",
        "#max_deviation_for_X = 0.02  # You can adjust this value as needed\n",
        "#perturb_data(X_raw_torch, max_deviation=max_deviation_for_X)\n",
        "#print(\"Perturbed X_raw {}\".format(X_raw_torch))\n",
        "\n",
        "for i in range(max_iterations):\n",
        "\n",
        "    # Calculate the gradient at the central point\n",
        "    central_grad = calculate_second_order_grad(nn_model, X_raw_torch, Y_torch)\n",
        "    central_grad_norm = torch.norm(central_grad)\n",
        "    central_grad = central_grad / central_grad_norm\n",
        "    #print(central_grad)\n",
        "    # Surrouning points' grads\n",
        "    surrounding_grads = []\n",
        "    norms = []\n",
        "\n",
        "\n",
        "    # Calculate the gradient at the surrounding points by MC\n",
        "    for _ in range(MC_num_samples):\n",
        "\n",
        "      nn_model_sample = SimpleNN(custom_W_0=original_weights['W_0'],custom_b=original_weights['b'],custom_V_0=original_weights['V_0'],custom_c=original_weights['c'])\n",
        "      #print(\"W_0 (before perturbation):\", nn_model_sample.W_0.data)\n",
        "      # Perturb weights\n",
        "      #perturb_weights_uniform_fixed_range(nn_model_sample, max_deviation=max_deviation_for_weight)\n",
        "      perturb_weights_uniform_fixed_range(nn_model_sample,scale = 0.05)\n",
        "      #print(\"W_0 (after perturbation):\", nn_model_sample.W_0.data)\n",
        "      # Calculate second-order gradient\n",
        "      grad = calculate_second_order_grad(nn_model_sample, X_raw_torch, Y_torch)\n",
        "      #grad_norm = torch.norm(grad)\n",
        "      #grad = grad / grad_norm\n",
        "      surrounding_grads.append(grad)\n",
        "      norms.append(torch.norm(grad).item())\n",
        "\n",
        "    # Calculate average norm\n",
        "    average_norm = sum(norms) / len(norms)\n",
        "\n",
        "    # Filter and sum gradients with norms above average\n",
        "    above_average_grads = [grad for grad, norm in zip(surrounding_grads, norms) if norm > 0.2 * average_norm]\n",
        "    above_average_grads = [grad / torch.norm(grad) for grad in above_average_grads]\n",
        "\n",
        "    #print(above_average_grads)\n",
        "    sum_above_average_grads = sum(above_average_grads)\n",
        "\n",
        "    # Average the large norm gradients\n",
        "    if above_average_grads:\n",
        "      average_above_average_grad = sum_above_average_grads / len(above_average_grads)\n",
        "      #print(average_above_average_grad)\n",
        "    else:\n",
        "    # Handle the case where no gradient is above average\n",
        "      average_above_average_grad = torch.zeros_like(X_raw_torch)\n",
        "\n",
        "\n",
        "    #print(\"Surrounding grad {}\".format(surrounding_grads))\n",
        "\n",
        "    # Combine gradients\n",
        "    combined_grad = (1-surrounding_propotion) * central_grad + surrounding_propotion * average_above_average_grad\n",
        "    #combined_grad =  average_surrounding_grad\n",
        "    #print(combined_grad)\n",
        "    # Calculate the norm of the combined gradient\n",
        "    combined_grad_norm = torch.norm(combined_grad)\n",
        "\n",
        "    # Check for a non-zero norm to avoid division by zero\n",
        "    if combined_grad_norm > 0:\n",
        "    # Normalize the gradient\n",
        "      normalized_grad = combined_grad / combined_grad_norm\n",
        "\n",
        "    else:\n",
        "      print(\"Gradient is zero; no update required.\")\n",
        "###############\n",
        "\n",
        "    # Check if the norm of the second-order gradient is below the threshold\n",
        "    if torch.norm(combined_grad) < threshold:\n",
        "        print(f\"Convergence reached at iteration {i}\")\n",
        "        break\n",
        "\n",
        "    # Update X_raw using gradient descent\n",
        "    X_raw_torch.data -= learning_rate * normalized_grad\n",
        "\n",
        "    # Zero out gradients for the next iteration\n",
        "    nn_model.zero_grad()\n",
        "    X_raw_torch.grad = None\n",
        "\n",
        "# Print final modified data\n",
        "#print(surrounding_grads)\n",
        "#print(\"Final modified X_raw:\")\n",
        "if len(above_average_grads) < 100:\n",
        "  print(\"need more MC_num_samples\")\n",
        "else:\n",
        "  print(\"Used surrounding points: {}\".format(len(above_average_grads)))\n",
        "\n",
        "print(X_raw_torch)\n",
        "print(negative_eigenvalues)"
      ],
      "metadata": {
        "id": "fiqG3HcGV4u0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eead8b58-42e0-442a-f988-71507ff16df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-52c0fdd6e8f8>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_raw_torch = torch.tensor(X_raw_pre, requires_grad=True)\n",
            "<ipython-input-49-52c0fdd6e8f8>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Y_torch = torch.tensor(Y_pre)\n",
            "<ipython-input-14-a815e9696fa5>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_W_0 = torch.tensor(custom_W_0, dtype=torch.float64)\n",
            "<ipython-input-14-a815e9696fa5>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_b = torch.tensor(custom_b, dtype=torch.float64)\n",
            "<ipython-input-14-a815e9696fa5>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_V_0 = torch.tensor(custom_V_0, dtype=torch.float64)\n",
            "<ipython-input-14-a815e9696fa5>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  custom_c = torch.tensor(custom_c, dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weight is {'W_0': tensor([[ 3.9979,  5.2638],\n",
            "        [ 1.0698, -1.8901]], dtype=torch.float64), 'b': tensor([[1.8545, 0.8022]], dtype=torch.float64), 'V_0': tensor([[-10.1389],\n",
            "        [-10.4242]], dtype=torch.float64), 'c': tensor([[5.0116]], dtype=torch.float64)}\n",
            "Initial X_raw tensor([[11.0898, -7.6508],\n",
            "        [ 2.0012, -5.9457],\n",
            "        [ 4.9975, -0.8779],\n",
            "        [ 6.1208, -5.1308],\n",
            "        [-5.5426, -6.2105],\n",
            "        [ 1.1080,  0.1753],\n",
            "        [-7.4783,  0.5124],\n",
            "        [-7.9947,  0.8285],\n",
            "        [-0.8698,  0.8182],\n",
            "        [-3.4649,  2.3132]], dtype=torch.float64, requires_grad=True)\n",
            "Used surrounding points: 200\n",
            "tensor([[11.0898, -7.6508],\n",
            "        [ 2.0012, -5.9457],\n",
            "        [ 4.9975, -0.8779],\n",
            "        [ 6.1208, -5.1308],\n",
            "        [-5.5426, -6.2105],\n",
            "        [ 1.1080,  0.1753],\n",
            "        [-7.4783,  0.5124],\n",
            "        [-7.9947,  0.8285],\n",
            "        [-0.7339,  0.4347],\n",
            "        [-3.4439,  2.3197]], dtype=torch.float64, requires_grad=True)\n",
            "[tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0004, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64), tensor(-0.0005, dtype=torch.float64)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model_final = SimpleNN(W_0, b, V_0, c)\n",
        "hessian_matrix_final, eigenvalues_final = compute_hessian_and_eigenvalues(nn_model, X_raw_torch, Y_torch)\n",
        "print(X_raw_torch)\n",
        "print(Y_torch)\n",
        "print(eigenvalues_final)\n",
        "check_local_minimum(eigenvalues_final)"
      ],
      "metadata": {
        "id": "nDgON5VoZ6_X",
        "outputId": "6be587a7-eb5d-4503-bf05-bb0fbe6f0322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[11.0898, -7.6508],\n",
            "        [ 2.0012, -5.9457],\n",
            "        [ 4.9975, -0.8779],\n",
            "        [ 6.1208, -5.1308],\n",
            "        [-5.5426, -6.2105],\n",
            "        [ 1.1080,  0.1753],\n",
            "        [-7.4783,  0.5124],\n",
            "        [-7.9947,  0.8285],\n",
            "        [-0.7339,  0.4347],\n",
            "        [-3.4439,  2.3197]], dtype=torch.float64, requires_grad=True)\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]], dtype=torch.float64)\n",
            "tensor([ 2.0579e-01+0.j,  7.9276e-03+0.j,  4.7714e-03+0.j, -1.4180e-03+0.j,\n",
            "        -5.0715e-04+0.j, -4.3948e-05+0.j, -4.1439e-06+0.j,  1.1427e-07+0.j,\n",
            "        -1.8893e-09+0.j], dtype=torch.complex128)\n",
            "This is not a local minimum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "def calculate_gradient_for_smallest_eigenvalue(model, X_raw_torch, Y_torch):\n",
        "    # Forward pass\n",
        "    output = model(X_raw_torch)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = -torch.mean(Y_torch * torch.log(output) + (1 - Y_torch) * torch.log(1 - output))\n",
        "\n",
        "    # First-order gradients (w.r.t weights)\n",
        "    first_order_grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
        "\n",
        "    # Flatten the first-order gradients\n",
        "    grads_flatten = torch.cat([g.contiguous().view(-1) for g in first_order_grads])\n",
        "\n",
        "    # Hessian computation\n",
        "    hessian = []\n",
        "    for grad in grads_flatten:\n",
        "        # Compute second-order gradients (w.r.t each element in the first-order gradients)\n",
        "        second_order_grads = torch.autograd.grad(grad, model.parameters(), retain_graph=True)\n",
        "\n",
        "        # Flatten and collect the second-order gradients\n",
        "        hessian_row = torch.cat([g.contiguous().view(-1) for g in second_order_grads])\n",
        "        hessian.append(hessian_row)\n",
        "\n",
        "    # Stack to form the Hessian matrix\n",
        "    hessian_matrix = torch.stack(hessian)\n",
        "\n",
        "    # Compute eigenvalues\n",
        "    eigenvalues, _ = torch.linalg.eig(hessian_matrix)\n",
        "    # Extract the real parts of eigenvalues\n",
        "    eigenvalues_real = eigenvalues.real\n",
        "\n",
        "    # Identify the smallest eigenvalue\n",
        "    smallest_eigenvalue = torch.min(eigenvalues_real)\n",
        "\n",
        "    # Check if the smallest eigenvalue requires gradients\n",
        "    if smallest_eigenvalue.requires_grad:\n",
        "      # Compute the gradient of the smallest eigenvalue (or its negative) with respect to X\n",
        "      if smallest_eigenvalue < 0:\n",
        "        grad_X = torch.autograd.grad(-smallest_eigenvalue, X_raw_torch, retain_graph=True)[0]\n",
        "      else:\n",
        "        print(\"FOUND A LOCAL MINIMUM!\")\n",
        "        print(f\"Local minimum at X: {X_raw_torch.detach().numpy()}\")\n",
        "        weights = {name: param.clone().detach().numpy() for name, param in model.named_parameters()}\n",
        "        print(f\"Local minimum at W: {weights}\")\n",
        "        grad_X = None  # or handle this case as you see fit\n",
        "    else:\n",
        "      print(\"Smallest eigenvalue does not require grad or is not part of the computation graph.\")\n",
        "      grad_X = None\n",
        "\n",
        "    return grad_X, eigenvalues, smallest_eigenvalue"
      ],
      "metadata": {
        "id": "E6mAQ3Hz-55q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set a threshold for the norm of the second-order gradient\n",
        "threshold = 0.05 # Adjust this threshold as needed\n",
        "max_iterations = 10  # Maximum number of iterations to prevent infinite loops\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.2\n",
        "\n",
        "# Monte Carlo method sampling points\n",
        "MC_num_samples = 10\n",
        "\n",
        "# Surrouning points' grad\n",
        "surrounding_grads = []\n",
        "\n",
        "# parameters for the first layer\n",
        "W_0 = np.array([[1.05954587,-0.05625762],[-0.03749863,1.09518945]])\n",
        "b = np.array([[-0.050686,-0.06894291]])\n",
        "\n",
        "# parameters for the second layer\n",
        "\n",
        "V_0 = np.array([[3.76921058],[-3.72139955]])\n",
        "c = np.array([[-0.0148436]])\n",
        "\n",
        "nn_model = SimpleNN(W_0, b, V_0, c)\n",
        "\n",
        "perturb_weights(nn_model, max_deviation=0.01)\n",
        "restore_weights(nn_model, original_weights)  # Assuming perturb_weights is defined as before\n",
        "print(perturb_weights)\n",
        "K=calculate_second_order_grad(nn_model, X_raw_torch, Y_torch)\n",
        "print(K)\n",
        "print(\"W_0 (after perturbation):\", nn_model.W_0.data)\n",
        "print(\"b (after perturbation):\", nn_model.b.data)\n",
        "print(\"V_0 (after perturbation):\", nn_model.V_0.data)\n",
        "print(\"c (after perturbation):\", nn_model.c.data)"
      ],
      "metadata": {
        "id": "_qolZlVZ-x8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forward pass\n",
        "output = nn_model(X_raw_torch)\n",
        "\n",
        "# Compute loss\n",
        "loss = -torch.mean(Y_torch * torch.log(output) + (1 - Y_torch) * torch.log(1 - output))\n",
        "print(loss)\n",
        "# Compute gradients of the loss w.r.t. weights\n",
        "loss.backward(create_graph=True)\n",
        "\n",
        "\n",
        "# Combine and compute the norm of all gradients\n",
        "all_grads = torch.cat([nn_model.W_0.grad.flatten(), nn_model.V_0.grad.flatten(), nn_model.b.grad.flatten(), nn_model.c.grad.flatten()])\n",
        "print(all_grads)\n",
        "grad_norm = torch.norm(all_grads)\n",
        "print(grad_norm)\n",
        "# Compute the derivative of the grad_norm with respect to X\n",
        "second_order_grad = torch.autograd.grad(grad_norm, X_raw_torch, retain_graph=True)[0]\n",
        "print(torch.norm(second_order_grad))\n",
        "# If you want to perform gradient descent on X_raw\n",
        "learning_rate = 0.01\n",
        "#X_raw_torch.data -= learning_rate * second_order_grad"
      ],
      "metadata": {
        "id": "s_654-o11XCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_raw_pre_1 = torch.tensor(X_raw_pre, requires_grad=True)\n",
        "Y_pre_1 = torch.tensor(Y_pre_1)\n",
        "\n",
        "\n",
        "# Set a threshold for the norm of the second-order gradient\n",
        "threshold = 0.001 # Adjust this threshold as needed\n",
        "max_iterations_pre = 50 # Maximum number of iterations to prevent infinite loops\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Monte Carlo method sampling points\n",
        "MC_pre_num_samples = 150\n",
        "\n",
        "# Surrouning points' grads' propotion\n",
        "surrounding_propotion_pre = 0.5\n",
        "\n",
        "# Weight perturbation\n",
        "max_deviation_for_weight_pre = 0.05\n",
        "\n",
        "nn_model_pre = SimpleNN(W_0, b, V_0, c)\n",
        "\n",
        "#original_weights = W_0, b, V_0, c\n",
        "original_weights = {\n",
        "    'W_0': nn_model.W_0.data.clone(),\n",
        "    'b': nn_model.b.data.clone(),\n",
        "    'V_0': nn_model.V_0.data.clone(),\n",
        "    'c': nn_model.c.data.clone()\n",
        "}\n",
        "print(\"Original weight is {}\".format(original_weights))\n",
        "print(\"Initial X_raw_pre_1 {}\".format(X_raw_pre_1))\n",
        "#max_deviation_for_X = 0.02  # You can adjust this value as needed\n",
        "#perturb_data(X_raw_torch, max_deviation=max_deviation_for_X)\n",
        "#print(\"Perturbed X_raw {}\".format(X_raw_torch))\n",
        "\n",
        "for i in range(max_iterations_pre):\n",
        "\n",
        "    # Calculate the gradient at the central point\n",
        "    central_grad_pre = calculate_second_order_grad(nn_model_pre, X_raw_pre_1, Y_pre_1)\n",
        "    central_grad_pre_norm = torch.norm(central_grad_pre)\n",
        "    central_grad_pre = central_grad_pre / central_grad_pre_norm\n",
        "    #print(central_grad)\n",
        "    # Surrouning points' grads\n",
        "    surrounding_grads_pre = []\n",
        "    norms_pre = []\n",
        "    negative_eigenvalues = []\n",
        "\n",
        "\n",
        "    # Calculate the gradient at the surrounding points by MC\n",
        "    for _ in range(MC_pre_num_samples):\n",
        "\n",
        "      nn_model_sample_pre = SimpleNN(custom_W_0=original_weights['W_0'],custom_b=original_weights['b'],custom_V_0=original_weights['V_0'],custom_c=original_weights['c'])\n",
        "      #print(\"W_0 (before perturbation):\", nn_model_sample.W_0.data)\n",
        "      # Perturb weights\n",
        "      #perturb_weights_uniform_fixed_range(nn_model_sample, max_deviation=max_deviation_for_weight)\n",
        "      perturb_weights_uniform_fixed_range(nn_model_sample_pre, scale = 0.1)\n",
        "      #print(\"W_0 (after perturbation):\", nn_model_sample.W_0.data)\n",
        "      _, eigenvalues = compute_hessian_and_eigenvalues(nn_model_sample_pre, X_raw_pre_1, Y_pre_1)\n",
        "      most_negative_eigenvalue = select_most_negative_eigenvalue(eigenvalues)\n",
        "      negative_eigenvalues.append(most_negative_eigenvalue)\n",
        "      grad_pre = calculate_second_order_grad(nn_model_sample_pre, X_raw_pre_1, Y_pre_1)\n",
        "      #grad_norm = torch.norm(grad)\n",
        "      #grad = grad / grad_norm\n",
        "      surrounding_grads_pre.append(grad_pre)\n",
        "      #negative_eigenvalues.append(torch.norm(grad_pre).item())\n",
        "\n",
        "    # Calculate average pre_norm\n",
        "    average_negative_eigenvalues = sum(negative_eigenvalues) / len(negative_eigenvalues)\n",
        "\n",
        "    # Calculate the median of negative eigenvalues\n",
        "    median_negative_eigenvalue = np.median([eigenvalue for eigenvalue in negative_eigenvalues if eigenvalue < 0])\n",
        "\n",
        "    # Filter gradients corresponding to the smallest 50% of negative eigenvalues\n",
        "    above_average_negative_eigenvalues = [grad for grad, eigenvalue in zip(surrounding_grads_pre, negative_eigenvalues) if eigenvalue < median_negative_eigenvalue]\n",
        "    above_average_negative_eigenvalues = [grad / torch.norm(grad) for grad in above_average_negative_eigenvalues]\n",
        "\n",
        "    #print(above_average_grads)\n",
        "    sum_above_average_negative_eigenvalues = sum(above_average_negative_eigenvalues)\n",
        "\n",
        "    # Average the large norm gradients\n",
        "    if above_average_negative_eigenvalues:\n",
        "      average_above_average_negative_eigenvalues = sum_above_average_negative_eigenvalues / len(above_average_negative_eigenvalues)\n",
        "      #print(average_above_average_grad)\n",
        "    else:\n",
        "    # Handle the case where no gradient is above average\n",
        "      average_above_average_negative_eigenvalues = torch.zeros_like(X_raw_pre_1)\n",
        "\n",
        "\n",
        "    #print(\"Surrounding grad {}\".format(surrounding_grads))\n",
        "\n",
        "    # Combine gradients\n",
        "    combined_grad_pre = (1-surrounding_propotion_pre) * central_grad_pre + surrounding_propotion_pre * average_above_average_negative_eigenvalues\n",
        "    #combined_grad =  average_surrounding_grad\n",
        "    #print(combined_grad)\n",
        "    # Calculate the norm of the combined gradient\n",
        "    combined_grad_pre_norm = torch.norm(combined_grad_pre)\n",
        "\n",
        "    # Check for a non-zero norm to avoid division by zero\n",
        "    if combined_grad_pre_norm > 0:\n",
        "    # Normalize the gradient\n",
        "      normalized_grad_pre = combined_grad_pre / combined_grad_pre_norm\n",
        "\n",
        "    else:\n",
        "      print(\"Gradient is zero; no update required.\")\n",
        "###############\n",
        "\n",
        "    # Check if the norm of the second-order gradient is below the threshold\n",
        "    if torch.norm(combined_grad_pre) < threshold:\n",
        "        print(f\"Convergence reached at iteration {i}\")\n",
        "        break\n",
        "    # Update X_raw using the normalized gradient and learning rate\n",
        "    X_raw_pre_1.data -= learning_rate * normalized_grad_pre\n",
        "\n",
        "    # Zero out gradients for the next iteration\n",
        "    nn_model.zero_grad()\n",
        "    X_raw_pre_1.grad = None\n",
        "\n",
        "# Print final modified data\n",
        "#print(surrounding_grads)\n",
        "#print(\"Final modified X_raw:\")\n",
        "if len(above_average_negative_eigenvalues) < 0.5*MC_pre_num_samples:\n",
        "  print(\"need more MC_pre_num_samples\")\n",
        "else:\n",
        "  print(\"Used surrounding points: {}\".format(len(above_average_negative_eigenvalues)))\n",
        "\n",
        "print(X_raw_pre_1)\n",
        "print(negative_eigenvalues)"
      ],
      "metadata": {
        "id": "9UEa48L2rbb3"
      }
    }
  ]
}