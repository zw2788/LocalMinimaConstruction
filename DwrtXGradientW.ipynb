{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9/axosG6xfd4nWmmLg+10",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zw2788/LocalMinimaConstruction/blob/main/DwrtXGradientW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "6IhL4Cbb1mfH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters for the first layer\n",
        "W_0 = np.array([[1.05954587,-0.05625762],[-0.03749863,1.09518945]])\n",
        "b = np.array([[-0.050686,-0.06894291]])\n",
        "\n",
        "# parameters for the second layer\n",
        "\n",
        "V_0 = np.array([[3.76921058],[-3.72139955]])\n",
        "c = np.array([[-0.0148436]])"
      ],
      "metadata": {
        "id": "vBoW060Y1pZB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/zw2788/LocalMinimaConstruction/main/Ex1.csv\")\n",
        "\n",
        "data.head()\n",
        "features = [\n",
        "    \"x_2dvec\",\n",
        "\n",
        "]\n",
        "label = \"y\"\n",
        "\n",
        "# train test split\n",
        "X_raw,  Y = data[features].values, data[label].values\n",
        "\n",
        "#convert string to array\n",
        "X_raw = np.array([eval(s[0]) for s in X_raw])\n",
        "\n",
        "# Standardize the input\n",
        "# Leave blank to match the example in paper\n",
        "\n",
        "# formatting\n",
        "Y = Y.reshape((-1, 1))\n",
        "print(X_raw)\n",
        "print(Y)\n",
        "print(X_raw.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0h9evkU59mR",
        "outputId": "f6b22f3d-ba86-4491-df39-263ee24aacdd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.8  0.4]\n",
            " [ 3.1  4.3]\n",
            " [ 0.1 -3.4]\n",
            " [-4.2 -3.3]\n",
            " [-0.5  0.2]\n",
            " [-2.7 -0.4]\n",
            " [-3.  -4.3]\n",
            " [-0.1  3.4]\n",
            " [ 4.2  3.2]\n",
            " [ 0.4 -0.1]]\n",
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, custom_W_0, custom_b, custom_V_0, custom_c):\n",
        "        super(SimpleNN, self).__init__()\n",
        "\n",
        "        # Ensure that the custom weights are tensors\n",
        "        custom_W_0 = torch.tensor(custom_W_0, dtype=torch.float64)\n",
        "        custom_b = torch.tensor(custom_b, dtype=torch.float64)\n",
        "        custom_V_0 = torch.tensor(custom_V_0, dtype=torch.float64)\n",
        "        custom_c = torch.tensor(custom_c, dtype=torch.float64)\n",
        "\n",
        "        # Set the custom weights and biases\n",
        "        self.W_0 = nn.Parameter(custom_W_0)\n",
        "        self.b = nn.Parameter(custom_b)\n",
        "        self.V_0 = nn.Parameter(custom_V_0)\n",
        "        self.c = nn.Parameter(custom_c)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.sigmoid(torch.add(torch.matmul(x, self.W_0), self.b))\n",
        "        x = F.sigmoid(torch.add(torch.matmul(x, self.V_0), self.c))\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "custom_W_0 = [[0.1, 0.2], [0.3, 0.4]]  # Replace with your own initial values\n",
        "custom_b = [0.1, 0.2]  # Replace with your own initial values\n",
        "custom_V_0 = [[0.1], [0.2]]  # Replace with your own initial values\n",
        "custom_c = [0.1]  # Replace with your own initial values\n",
        "\n",
        "nn_model = SimpleNN(W_0, b, V_0, c)\n"
      ],
      "metadata": {
        "id": "bJ0z4fS_1p0H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "s_654-o11XCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98cb56d3-d2a3-403a-8072-aa4d0a894dae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.8000,  0.4000],\n",
            "        [ 3.1000,  4.3000],\n",
            "        [ 0.1000, -3.4000],\n",
            "        [-4.2000, -3.3000],\n",
            "        [-0.5000,  0.2000],\n",
            "        [-2.7000, -0.4000],\n",
            "        [-3.0000, -4.3000],\n",
            "        [-0.1000,  3.4000],\n",
            "        [ 4.2000,  3.2000],\n",
            "        [ 0.4000, -0.1000]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.5777, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
            "tensor([-5.0638e-06,  8.5365e-06, -1.0746e-05,  4.3353e-06, -3.4659e-06,\n",
            "        -3.3150e-06, -1.4286e-06,  1.8137e-06, -3.3791e-06],\n",
            "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "tensor(1.6509e-05, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
            "tensor(0.1384, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_raw_torch = torch.tensor(X_raw, requires_grad=True)\n",
        "print(X_raw_torch)\n",
        "Y_torch = torch.tensor(Y)\n",
        "\n",
        "# Forward pass\n",
        "output = nn_model(X_raw_torch)\n",
        "\n",
        "# Compute loss\n",
        "loss = -torch.mean(Y_torch * torch.log(output) + (1 - Y_torch) * torch.log(1 - output))\n",
        "print(loss)\n",
        "# Compute gradients of the loss w.r.t. weights\n",
        "loss.backward(create_graph=True)\n",
        "\n",
        "\n",
        "# Combine and compute the norm of all gradients\n",
        "all_grads = torch.cat([nn_model.W_0.grad.flatten(), nn_model.V_0.grad.flatten(), nn_model.b.grad.flatten(), nn_model.c.grad.flatten()])\n",
        "print(all_grads)\n",
        "grad_norm = torch.norm(all_grads)\n",
        "print(grad_norm)\n",
        "# Compute the derivative of the grad_norm with respect to X\n",
        "second_order_grad = torch.autograd.grad(grad_norm, X_raw_torch, retain_graph=True)[0]\n",
        "print(torch.norm(second_order_grad))\n",
        "# If you want to perform gradient descent on X_raw\n",
        "learning_rate = 0.01\n",
        "#X_raw_torch.data -= learning_rate * second_order_grad"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a threshold for the norm of the second-order gradient\n",
        "threshold = 0.05 # Adjust this threshold as needed\n",
        "max_iterations = 1000  # Maximum number of iterations to prevent infinite loops\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.01\n",
        "\n",
        "for i in range(max_iterations):\n",
        "    # Forward pass\n",
        "    output = nn_model(X_raw_torch)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = -torch.mean(Y_torch * torch.log(output) + (1 - Y_torch) * torch.log(1 - output))\n",
        "\n",
        "    # Compute gradients of the loss w.r.t. weights, with graph creation for higher-order gradients\n",
        "    loss.backward(create_graph=True)\n",
        "\n",
        "    # Combine and compute the norm of all gradients\n",
        "    all_grads = torch.cat([nn_model.W_0.grad.flatten(), nn_model.V_0.grad.flatten(), nn_model.b.grad.flatten(), nn_model.c.grad.flatten()])\n",
        "    grad_norm = torch.norm(all_grads)\n",
        "\n",
        "    # Compute the derivative of the grad_norm with respect to X\n",
        "    second_order_grad = torch.autograd.grad(grad_norm, X_raw_torch, retain_graph=True)[0]\n",
        "\n",
        "    # Check if the norm of the second-order gradient is below the threshold\n",
        "    if torch.norm(second_order_grad) < threshold:\n",
        "        print(f\"Convergence reached at iteration {i}\")\n",
        "        break\n",
        "\n",
        "    # Update X_raw using gradient descent\n",
        "    X_raw_torch.data -= learning_rate * second_order_grad\n",
        "\n",
        "    # Zero out gradients for the next iteration\n",
        "    nn_model.zero_grad()\n",
        "    X_raw_torch.grad = None\n",
        "\n",
        "# Print final modified data\n",
        "print(\"Final modified X_raw:\")\n",
        "print(X_raw_torch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiqG3HcGV4u0",
        "outputId": "6027350f-b2b1-4095-8314-df1460cb834c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final modified X_raw:\n",
            "tensor([[ 2.8000,  0.4002],\n",
            "        [ 3.0999,  4.3000],\n",
            "        [ 0.1000, -3.4000],\n",
            "        [-4.2000, -3.3002],\n",
            "        [-0.4993,  0.1999],\n",
            "        [-2.7000, -0.4003],\n",
            "        [-3.0000, -4.3000],\n",
            "        [-0.1001,  3.4000],\n",
            "        [ 4.1999,  3.2003],\n",
            "        [ 0.3991, -0.0999]], dtype=torch.float64, requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}