{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYpzEERfp1D1+hu5K1VxJW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zw2788/LocalMinimaConstruction/blob/main/DwrtXGradientW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "6IhL4Cbb1mfH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vBoW060Y1pZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8476a2a3-275f-4415-ee78-0bb74ddcd514"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'W_0': tensor([[ 1.0595, -0.0563],\n",
            "        [-0.0375,  1.0952]], dtype=torch.float64), 'V_0': tensor([[ 3.7692],\n",
            "        [-3.7214]], dtype=torch.float64), 'b': tensor([[-0.0507, -0.0689]], dtype=torch.float64), 'c': tensor([[-0.0148]], dtype=torch.float64)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/zw2788/LocalMinimaConstruction/main/Ex1.csv\")\n",
        "\n",
        "data.head()\n",
        "features = [\n",
        "    \"x_2dvec\",\n",
        "\n",
        "]\n",
        "label = \"y\"\n",
        "\n",
        "# train test split\n",
        "X_raw,  Y = data[features].values, data[label].values\n",
        "\n",
        "#convert string to array\n",
        "X_raw = np.array([eval(s[0]) for s in X_raw])\n",
        "\n",
        "# Standardize the input\n",
        "# Leave blank to match the example in paper\n",
        "\n",
        "# formatting\n",
        "Y = Y.reshape((-1, 1))\n",
        "print(X_raw)\n",
        "print(Y)\n",
        "print(X_raw.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0h9evkU59mR",
        "outputId": "57d31cea-6074-4997-b272-4f6399f744ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.8  0.4]\n",
            " [ 3.1  4.3]\n",
            " [ 0.1 -3.4]\n",
            " [-4.2 -3.3]\n",
            " [-0.5  0.2]\n",
            " [-2.7 -0.4]\n",
            " [-3.  -4.3]\n",
            " [-0.1  3.4]\n",
            " [ 4.2  3.2]\n",
            " [ 0.4 -0.1]]\n",
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, custom_W_0, custom_b, custom_V_0, custom_c):\n",
        "        super(SimpleNN, self).__init__()\n",
        "\n",
        "        # Ensure that the custom weights are tensors\n",
        "        custom_W_0 = torch.tensor(custom_W_0, dtype=torch.float64)\n",
        "        custom_b = torch.tensor(custom_b, dtype=torch.float64)\n",
        "        custom_V_0 = torch.tensor(custom_V_0, dtype=torch.float64)\n",
        "        custom_c = torch.tensor(custom_c, dtype=torch.float64)\n",
        "\n",
        "        # Set the custom weights and biases\n",
        "        self.W_0 = nn.Parameter(custom_W_0)\n",
        "        self.b = nn.Parameter(custom_b)\n",
        "        self.V_0 = nn.Parameter(custom_V_0)\n",
        "        self.c = nn.Parameter(custom_c)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.sigmoid(torch.add(torch.matmul(x, self.W_0), self.b))\n",
        "        x = F.sigmoid(torch.add(torch.matmul(x, self.V_0), self.c))\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "#custom_W_0 = [[0.1, 0.2], [0.3, 0.4]]  # Replace with your own initial values\n",
        "#custom_b = [0.1, 0.2]  # Replace with your own initial values\n",
        "#custom_V_0 = [[0.1], [0.2]]  # Replace with your own initial values\n",
        "#custom_c = [0.1]  # Replace with your own initial values\n",
        "\n",
        "\n",
        "def calculate_second_order_grad(model, X_raw_torch, Y_torch):\n",
        "    # Forward pass\n",
        "    output = model(X_raw_torch)\n",
        "    # Compute loss\n",
        "    loss = -torch.mean(Y_torch * torch.log(output) + (1 - Y_torch) * torch.log(1 - output))\n",
        "    # Compute gradients of the loss w.r.t. weights\n",
        "    loss.backward(create_graph=True)\n",
        "    # Combine and compute the norm of all gradients\n",
        "    all_grads = torch.cat([param.grad.flatten() for param in model.parameters()])\n",
        "    grad_norm = torch.norm(all_grads)\n",
        "    # Compute the derivative of the grad_norm with respect to X\n",
        "    second_order_grad = torch.autograd.grad(grad_norm, X_raw_torch, retain_graph=True)[0]\n",
        "    return second_order_grad\n"
      ],
      "metadata": {
        "id": "bJ0z4fS_1p0H"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "s_654-o11XCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a14f77a-5573-47ff-bebe-ece49ddf5526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.8000,  0.4000],\n",
            "        [ 3.1000,  4.3000],\n",
            "        [ 0.1000, -3.4000],\n",
            "        [-4.2000, -3.3000],\n",
            "        [-0.5000,  0.2000],\n",
            "        [-2.7000, -0.4000],\n",
            "        [-3.0000, -4.3000],\n",
            "        [-0.1000,  3.4000],\n",
            "        [ 4.2000,  3.2000],\n",
            "        [ 0.4000, -0.1000]], dtype=torch.float64, requires_grad=True)\n",
            "tensor(0.5777, dtype=torch.float64, grad_fn=<NegBackward0>)\n",
            "tensor([-4.6034e-07,  7.7605e-07, -9.7695e-07,  3.9412e-07, -3.1508e-07,\n",
            "        -3.0137e-07, -1.2987e-07,  1.6488e-07, -3.0719e-07],\n",
            "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
            "tensor(1.5008e-06, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
            "tensor(0.1384, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_raw_torch = torch.tensor(X_raw, requires_grad=True)\n",
        "print(X_raw_torch)\n",
        "Y_torch = torch.tensor(Y)\n",
        "\n",
        "# Forward pass\n",
        "output = nn_model(X_raw_torch)\n",
        "\n",
        "# Compute loss\n",
        "loss = -torch.mean(Y_torch * torch.log(output) + (1 - Y_torch) * torch.log(1 - output))\n",
        "print(loss)\n",
        "# Compute gradients of the loss w.r.t. weights\n",
        "loss.backward(create_graph=True)\n",
        "\n",
        "\n",
        "# Combine and compute the norm of all gradients\n",
        "all_grads = torch.cat([nn_model.W_0.grad.flatten(), nn_model.V_0.grad.flatten(), nn_model.b.grad.flatten(), nn_model.c.grad.flatten()])\n",
        "print(all_grads)\n",
        "grad_norm = torch.norm(all_grads)\n",
        "print(grad_norm)\n",
        "# Compute the derivative of the grad_norm with respect to X\n",
        "second_order_grad = torch.autograd.grad(grad_norm, X_raw_torch, retain_graph=True)[0]\n",
        "print(torch.norm(second_order_grad))\n",
        "# If you want to perform gradient descent on X_raw\n",
        "learning_rate = 0.01\n",
        "#X_raw_torch.data -= learning_rate * second_order_grad"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a threshold for the norm of the second-order gradient\n",
        "threshold = 0.05 # Adjust this threshold as needed\n",
        "max_iterations = 10  # Maximum number of iterations to prevent infinite loops\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.2\n",
        "\n",
        "# Monte Carlo method sampling points\n",
        "MC_num_samples = 10\n",
        "\n",
        "# Surrouning points' grad\n",
        "surrounding_grads = []\n",
        "\n",
        "# parameters for the first layer\n",
        "W_0 = np.array([[1.05954587,-0.05625762],[-0.03749863,1.09518945]])\n",
        "b = np.array([[-0.050686,-0.06894291]])\n",
        "\n",
        "# parameters for the second layer\n",
        "\n",
        "V_0 = np.array([[3.76921058],[-3.72139955]])\n",
        "c = np.array([[-0.0148436]])\n",
        "\n",
        "nn_model = SimpleNN(W_0, b, V_0, c)\n",
        "\n",
        "original_weights = {\n",
        "    'W_0': nn_model.W_0.data.clone(),\n",
        "    'V_0': nn_model.V_0.data.clone(),\n",
        "    'b': nn_model.b.data.clone(),\n",
        "    'c': nn_model.c.data.clone()\n",
        "}\n",
        "print(original_weights)\n",
        "\n",
        "for i in range(max_iterations):\n",
        "\n",
        "    # Calculate the gradient at the central point\n",
        "    central_grad = calculate_second_order_grad(nn_model, X_raw_torch, Y_torch)\n",
        "\n",
        "    # Calculate the gradient at the surrounding points by MC\n",
        "    for _ in range(MC_num_samples):\n",
        "      perturb_weights(nn_model, std_dev=0.01)  # Assuming perturb_weights is defined as before\n",
        "      print(perturb_weights)\n",
        "      grad = calculate_second_order_grad(nn_model, X_raw_torch, Y_torch)\n",
        "      surrounding_grads.append(grad)\n",
        "      restore_weights(nn_model, original_weights)  # Restore to central point weights\n",
        "\n",
        "\n",
        "    # Combine and compute the norm of all gradients\n",
        "    all_grads = torch.cat([nn_model.W_0.grad.flatten(), nn_model.V_0.grad.flatten(), nn_model.b.grad.flatten(), nn_model.c.grad.flatten()])\n",
        "    grad_norm = torch.norm(all_grads)\n",
        "\n",
        "    # Compute the derivative of the grad_norm with respect to X\n",
        "    second_order_grad = torch.autograd.grad(grad_norm, X_raw_torch, retain_graph=True)[0]\n",
        "\n",
        "    # Check if the norm of the second-order gradient is below the threshold\n",
        "    if torch.norm(second_order_grad) < threshold:\n",
        "        print(f\"Convergence reached at iteration {i}\")\n",
        "        break\n",
        "\n",
        "    # Update X_raw using gradient descent\n",
        "    X_raw_torch.data -= learning_rate * second_order_grad\n",
        "\n",
        "    # Zero out gradients for the next iteration\n",
        "    nn_model.zero_grad()\n",
        "    X_raw_torch.grad = None\n",
        "\n",
        "# Print final modified data\n",
        "print(\"Final modified X_raw:\")\n",
        "print(X_raw_torch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiqG3HcGV4u0",
        "outputId": "a09cfdbd-4891-4a4d-cfd3-89269ad44470"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final modified X_raw:\n",
            "tensor([[ 2.7985,  0.3892],\n",
            "        [ 3.1008,  4.3033],\n",
            "        [ 0.0998, -3.4012],\n",
            "        [-4.1983, -3.3030],\n",
            "        [-0.5101,  0.1976],\n",
            "        [-2.6957, -0.4041],\n",
            "        [-3.0027, -4.3008],\n",
            "        [-0.1050,  3.4008],\n",
            "        [ 4.1978,  3.2024],\n",
            "        [ 0.3985, -0.1022]], dtype=torch.float64, requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}