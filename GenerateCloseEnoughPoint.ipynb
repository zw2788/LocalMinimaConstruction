{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAFF0/ozi74Py+q52SbxK3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zw2788/LocalMinimaConstruction/blob/main/GenerateCloseEnoughPoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "j3uuvPWyq8id"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network\n",
        "class FFNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FFNN, self).__init__()\n",
        "        self.hidden = nn.Linear(2, 2)\n",
        "        self.output = nn.Linear(2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sigmoid(self.hidden(x))\n",
        "        x = self.sigmoid(self.output(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "# Custom loss function\n",
        "def custom_loss(output, target):\n",
        "    return -torch.mean(target * torch.log(output) + (1 - target) * torch.log(1 - output))\n"
      ],
      "metadata": {
        "id": "5U9XkAe5rD8y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the network\n",
        "model = FFNN()\n",
        "# Optimizer (using simple Gradient Descent)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.02)\n",
        "\n",
        "# Dummy input and output data\n",
        "input_data = torch.randn(10, 2)\n",
        "print(input_data)\n",
        "output_data = torch.randn(10, 1)\n",
        "output_data = (output_data > 0.5).float()\n",
        "# Training loop\n",
        "max_num_epoch = 1000\n",
        "prev_loss = None\n",
        "for epoch in range(max_num_epoch):\n",
        "    optimizer.zero_grad()   # clear the gradients\n",
        "    outputs = model(input_data)  # forward pass\n",
        "    loss = custom_loss(outputs, output_data)  # calculate the loss\n",
        "    loss.backward()  # backward pass (compute gradients)\n",
        "    optimizer.step()  # update weights\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/1000], Loss: {loss.item():.6f}')\n",
        "        # Check for early stopping condition\n",
        "    if prev_loss is not None:\n",
        "        loss_diff = abs(prev_loss - loss.item())\n",
        "        if loss_diff < 0.0001:\n",
        "            print(f'Early stopping at epoch {epoch+1}, Loss: {loss.item():.6f}')\n",
        "            break\n",
        "\n",
        "    prev_loss = loss.item()\n",
        "\n",
        "# Track weights and biases\n",
        "weights_hidden = model.hidden.weight.data.numpy()\n",
        "bias_hidden = model.hidden.bias.data.numpy()\n",
        "\n",
        "weights_output = model.output.weight.data.numpy()\n",
        "V_0_transposed = weights_output.T\n",
        "bias_output = model.output.bias.data.numpy()\n",
        "\n",
        "\n",
        "# Prepare data for DataFrame\n",
        "input_data_list = [str(row.tolist()) for row in input_data]\n",
        "output_data_list = [str(row.item()) for row in output_data]\n",
        "weights_hidden_list = [str(row.tolist()) for row in weights_hidden]\n",
        "bias_hidden_list = [str(bias_hidden.tolist())]\n",
        "V_0_transposed_list = [str(row.tolist()) for row in V_0_transposed]\n",
        "bias_output_list = [str(bias_output.tolist())]\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'x_2dvec': input_data_list + [None] * (max(len(weights_hidden_list), len(V_0_transposed_list)) - len(input_data_list)),\n",
        "    'y': output_data_list + [None] * (max(len(weights_hidden_list), len(V_0_transposed_list)) - len(output_data_list)),\n",
        "    'W_0': weights_hidden_list + [None] * (max(len(input_data_list), len(output_data_list)) - len(weights_hidden_list)),\n",
        "    'b': bias_hidden_list + [None] * (max(len(input_data_list), len(output_data_list)) - len(bias_hidden_list)),\n",
        "    'V_0': V_0_transposed_list + [None] * (max(len(input_data_list), len(output_data_list)) - len(V_0_transposed_list)),\n",
        "    'c': bias_output_list + [None] * (max(len(input_data_list), len(output_data_list)) - len(bias_output_list))\n",
        "})\n",
        "\n",
        "# Save to CSV file\n",
        "df.to_csv('output.csv', index=False)\n",
        "\n",
        "print(\"Weights of hidden layer:\", weights_hidden)\n",
        "print(\"Bias of hidden layer:\", bias_hidden)\n",
        "print(\"Weights of output layer:\", weights_output)\n",
        "print(\"Bias of output layer:\", bias_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnJvvA13rGJf",
        "outputId": "df8390be-8277-4dbc-9d3b-37f81057e49e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.1959e+00, -1.7239e+00],\n",
            "        [ 3.2780e-01, -9.2969e-04],\n",
            "        [-3.2181e-01,  5.0979e-02],\n",
            "        [ 5.1391e-02, -1.8637e+00],\n",
            "        [ 1.4383e-01, -8.8913e-01],\n",
            "        [ 8.2575e-01, -9.1271e-01],\n",
            "        [-1.0502e+00,  2.1276e-01],\n",
            "        [-3.4244e-01, -3.2497e+00],\n",
            "        [ 5.9189e-01,  1.8070e+00],\n",
            "        [-9.3555e-01,  1.2251e+00]])\n",
            "Epoch [10/1000], Loss: 0.754942\n",
            "Epoch [20/1000], Loss: 0.718320\n",
            "Epoch [30/1000], Loss: 0.687161\n",
            "Epoch [40/1000], Loss: 0.660629\n",
            "Epoch [50/1000], Loss: 0.638005\n",
            "Epoch [60/1000], Loss: 0.618680\n",
            "Epoch [70/1000], Loss: 0.602139\n",
            "Epoch [80/1000], Loss: 0.587948\n",
            "Epoch [90/1000], Loss: 0.575744\n",
            "Epoch [100/1000], Loss: 0.565223\n",
            "Epoch [110/1000], Loss: 0.556131\n",
            "Epoch [120/1000], Loss: 0.548253\n",
            "Epoch [130/1000], Loss: 0.541411\n",
            "Epoch [140/1000], Loss: 0.535453\n",
            "Epoch [150/1000], Loss: 0.530254\n",
            "Epoch [160/1000], Loss: 0.525704\n",
            "Epoch [170/1000], Loss: 0.521715\n",
            "Epoch [180/1000], Loss: 0.518208\n",
            "Epoch [190/1000], Loss: 0.515118\n",
            "Epoch [200/1000], Loss: 0.512390\n",
            "Epoch [210/1000], Loss: 0.509975\n",
            "Epoch [220/1000], Loss: 0.507833\n",
            "Epoch [230/1000], Loss: 0.505929\n",
            "Epoch [240/1000], Loss: 0.504232\n",
            "Epoch [250/1000], Loss: 0.502716\n",
            "Epoch [260/1000], Loss: 0.501359\n",
            "Epoch [270/1000], Loss: 0.500141\n",
            "Epoch [280/1000], Loss: 0.499045\n",
            "Early stopping at epoch 285, Loss: 0.498539\n",
            "Weights of hidden layer: [[-0.5142641  -0.54784214]\n",
            " [-0.09929168  0.3280283 ]]\n",
            "Bias of hidden layer: [-0.07914338  0.13920937]\n",
            "Weights of output layer: [[-0.4331298  -0.01937802]]\n",
            "Bias of output layer: [-0.8682207]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "MPsAxkul3vsh"
      }
    }
  ]
}