{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3BQ6Eh5hSuJXw/AqIrHsO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zw2788/LocalMinimaConstruction/blob/main/LocalMinimuaEx1Creating.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MA-T-qKzC7Uv"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from IPython.display import Image\n",
        "import torch\n",
        "from torch.autograd.functional import hessian"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters for the first layer\n",
        "W_0 = np.array([[1.05954587,-0.03749863],[-0.05625762,1.09518945]])\n",
        "b = np.array([[-0.050686],[-0.06894291]])\n",
        "\n",
        "# parameters for the second layer\n",
        "\n",
        "V_0 = np.array([[3.76921058,-3.72139955]])\n",
        "c = np.array([[-0.0148436]])"
      ],
      "metadata": {
        "id": "pZVfoVbfDD8a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    \"\"\"Calculates sigmoid function.\"\"\"\n",
        "    return 1. / (1 + np.exp(-x))\n",
        "\n",
        "def forward_prop(\n",
        "    X_raw: np.array,\n",
        "    W_0: np.array,\n",
        "    b: np.array,\n",
        "    V_0: np.array,\n",
        "    c: np.array,\n",
        ") -> Tuple:\n",
        "    \"\"\"Performs the forward propagation of the given NN.\"\"\"\n",
        "    # Note the NN structure is passed in from outside.\n",
        "    Z_1 = X_raw @ W_0.T\n",
        "    A_1 = sigmoid(Z_1 + b.T)\n",
        "\n",
        "    Z_2 = A_1 @ V_0.T\n",
        "    A_2 = Y = sigmoid(Z_2 + c.T)\n",
        "\n",
        "    return A_2, Z_2, A_1, Z_1\n",
        "\n",
        "#Y_hat, _, _, _ = forward_prop(X_raw=X_raw, W_0=W_0, b=b, V_0=V_0, c=c)\n",
        "\n",
        "def derivatives_with_respect_to_input(\n",
        "    X_raw: np.array,\n",
        "    Y: np.array,\n",
        "    W_0: np.array,\n",
        "    b: np.array,\n",
        "    V_0: np.array,\n",
        "    c: np.array,\n",
        ") -> Tuple:\n",
        "    \"\"\"Calculates the derivatives of the loss with respect to the input data, X_raw.\n",
        "\n",
        "    Here we assume it is a binary classification problem, with sigmoid activation functions.\n",
        "    \"\"\"\n",
        "    # forward propagation\n",
        "    dX_raw = 0\n",
        "    Y_hat, Z_2, A_1, Z_1 = forward_prop(X_raw=X_raw, W_0=W_0, b=b, V_0=V_0, c=c)\n",
        "    n = len(Y_hat)\n",
        "    # Backward propagation to compute gradient with respect to X_raw\n",
        "    dZ_2 = Y_hat - Y\n",
        "    dA_1 = dZ_2 @ V_0 / n\n",
        "    dZ_1 = np.multiply(dZ_2 @ V_0, sigmoid_derivative(Z_1))  # Assuming sigmoid activation, need its derivative\n",
        "    dX_raw = dZ_1 @ W_0 / n\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = -np.mean(np.multiply(Y, np.log(Y_hat)) + np.multiply(1 - Y, np.log(1 - Y_hat)))\n",
        "\n",
        "    return dX_raw, loss\n",
        "\n",
        "# Function to compute the derivative of the sigmoid function\n",
        "def sigmoid_derivative(Z):\n",
        "    S = 1 / (1 + np.exp(-Z))\n",
        "    return S * (1 - S)\n",
        "\n",
        "# Example usage:\n",
        "# Initialize your variables (X_raw, Y, W_0, b, V_0, c) before calling this function\n",
        "#dX_raw, loss = derivatives_with_respect_to_input(X_raw=X_raw, Y=Y, W_0=W_0, b=b, V_0=V_0, c=c)\n"
      ],
      "metadata": {
        "id": "ehS3p6hEDiJi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_ascent(\n",
        "    X_raw_init: np.array,\n",
        "    Y: np.array,\n",
        "    W_0_init: np.array,\n",
        "    b_init: np.array,\n",
        "    V_0_init: np.array,\n",
        "    c_init: np.array,\n",
        "    learning_rate: float = 0.5,\n",
        "    epsilon: float = 1e-2,\n",
        "    verbose: bool = False,\n",
        ") -> Tuple:\n",
        "    \"\"\"Runs gradient descent to fit the NN via backprop.\"\"\"\n",
        "\n",
        "    W_0 = W_0_init\n",
        "    b = b_init\n",
        "    V_0 = V_0_init\n",
        "    c = c_init\n",
        "    X_raw = X_raw_init\n",
        "    losses = [float(\"inf\"), ]\n",
        "    roc_auc_scores = [0.5, ]\n",
        "\n",
        "    diff_in_loss = float(\"inf\")\n",
        "    iteration = 0\n",
        "    while abs(diff_in_loss) > epsilon:\n",
        "        iteration += 1\n",
        "        dX_raw, loss = derivatives_with_respect_to_input(\n",
        "            X_raw=X_raw, Y=Y, W_0=W_0, b=b, V_0=V_0, c=c\n",
        "        )\n",
        "\n",
        "        X_raw += learning_rate * dX_raw\n",
        "        print(X_raw)\n",
        "        losses.append(loss)\n",
        "        diff_in_loss = losses[-1] - losses[-2]\n",
        "\n",
        "        Y_hat, _, _, _ = forward_prop(X_raw=X_raw, W_0=W_0, b=b, V_0=V_0, c=c)\n",
        "        roc_auc = roc_auc_score(y_true=Y, y_score=Y_hat)\n",
        "        roc_auc_scores.append(roc_auc)\n",
        "\n",
        "        if verbose and iteration % 10 == 0:\n",
        "            print(loss, roc_auc)\n",
        "    return X_raw, losses"
      ],
      "metadata": {
        "id": "mA2JK2dLNwA5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters for the first layer\n",
        "W_0_init = np.array([[1.06,-0.037],[-0.056,1.095]])\n",
        "b_init = np.array([[-0.051],[-0.0689]])\n",
        "\n",
        "# parameters for the second layer\n",
        "\n",
        "V_0_init = np.array([[3.769,-3.72]])\n",
        "c_init = np.array([[-0.0148]])\n",
        "\n",
        "X_raw = np.array([[ 2.8*(1+0.01*np.random.choice([-1,1])) , 0.4*(1+0.01*np.random.choice([-1,1]))],\n",
        " [ 3.1*(1+0.01*np.random.choice([-1,1])) , 4.3*(1+0.01*np.random.choice([-1,1]))],\n",
        " [ 0.1*(1+0.01*np.random.choice([-1,1])) , -3.4*(1+0.001*np.random.choice([-1,1]))],\n",
        " [-4.2 , -3.3],\n",
        " [-0.5 , 0.2],\n",
        " [-2.7 , -0.4],\n",
        " [-3. , -4.3],\n",
        " [-0.1 , 3.4],\n",
        " [ 4.2 , 3.2],\n",
        " [ 0.4, -0.1]])\n",
        "\n",
        "Y = np.array([[1],\n",
        " [1],\n",
        " [1],\n",
        " [1],\n",
        " [1],\n",
        " [0],\n",
        " [0],\n",
        " [0],\n",
        " [0],\n",
        " [0]])\n",
        "\n",
        "\n",
        "X_raw_end, losses = gradient_ascent(\n",
        "    X_raw_init=X_raw,\n",
        "    Y=Y,\n",
        "    W_0_init=W_0_init,\n",
        "    b_init =b_init,\n",
        "    V_0_init=V_0_init,\n",
        "    c_init =c_init,\n",
        "    learning_rate=0.0001,\n",
        "    epsilon=1e-5,\n",
        "    verbose=True,\n",
        ")\n",
        "print(X_raw_end)\n",
        "print(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmjHB5eXWjW0",
        "outputId": "330f9960-b6ec-4578-cbc0-b3ef474c2018"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.82799957  0.40400183]\n",
            " [ 3.13099918  4.25700026]\n",
            " [ 0.09899877 -3.40339984]\n",
            " [-4.2000003  -3.29999931]\n",
            " [-0.50000654  0.20000691]\n",
            " [-2.69999947 -0.40000207]\n",
            " [-2.99999905 -4.30000026]\n",
            " [-0.09999884  3.39999985]\n",
            " [ 4.20000031  3.19999923]\n",
            " [ 0.40000637 -0.10000663]]\n",
            "[[ 2.82799915  0.40400365]\n",
            " [ 3.13099835  4.25700052]\n",
            " [ 0.09899755 -3.40339968]\n",
            " [-4.2000006  -3.29999863]\n",
            " [-0.50001309  0.20001381]\n",
            " [-2.69999894 -0.40000414]\n",
            " [-2.9999981  -4.30000052]\n",
            " [-0.09999768  3.3999997 ]\n",
            " [ 4.20000062  3.19999845]\n",
            " [ 0.40001275 -0.10001327]]\n",
            "[[ 2.82799915  0.40400365]\n",
            " [ 3.13099835  4.25700052]\n",
            " [ 0.09899755 -3.40339968]\n",
            " [-4.2000006  -3.29999863]\n",
            " [-0.50001309  0.20001381]\n",
            " [-2.69999894 -0.40000414]\n",
            " [-2.9999981  -4.30000052]\n",
            " [-0.09999768  3.3999997 ]\n",
            " [ 4.20000062  3.19999845]\n",
            " [ 0.40001275 -0.10001327]]\n",
            "[inf, 0.5773035947029819, 0.5773054844933923]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cB_IAVhLWhVg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ga4cWYwKWblE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RRVRLGbkWY1Z"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}